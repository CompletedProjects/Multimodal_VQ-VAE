{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "110120_Either_modality_missing_remove_patch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nerdk312/Multimodal_VQ-VAE/blob/master/110120_Either_modality_missing_remove_patch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP252uER8Mj4",
        "colab_type": "code",
        "outputId": "ccf08227-cd9e-49fc-c203-88af9a52bb2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEdPl_3i8i3z",
        "colab_type": "code",
        "outputId": "0886d30d-80d6-4293-8771-f1addcc351eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# Nawid - Updates the path to import from drive\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/vq-vae-2-master-Single_representation_V4')\n",
        "\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "from keras.preprocessing import image as image_utils\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from tensorboardcolab import TensorBoardColab\n",
        "from torch.utils.data import DataLoader\n",
        "import random\n",
        "\n",
        "# Nawid - Used to get the current time and date which I will use the save the data in a folder\n",
        "from datetime import datetime\n",
        "\n",
        "from vq_vae_2.examples.hierarchical_combined.model import make_vae\n",
        "target_size = (64,64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R73VF2pBwTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def common_images(RGB_dir,Thermal_dir):\n",
        "  RGB_image_list = os.listdir(RGB_dir)\n",
        "  Thermal_image_list = os.listdir(Thermal_dir)\n",
        "\n",
        "  truncated_RGB_image_list = [RGB_image_name.strip('.jpg') for RGB_image_name in RGB_image_list]\n",
        "  truncated_Thermal_image_list = [Thermal_image_name.strip('.jpeg') for Thermal_image_name in Thermal_image_list]\n",
        "\n",
        "  common_list = set(truncated_RGB_image_list).intersection(truncated_Thermal_image_list)\n",
        "  common_list = sorted(common_list) # Nawid - Sorts all the items in a list\n",
        "  return common_list\n",
        "\n",
        "RGB_inp_dir = '/content/gdrive/My Drive/RGB'\n",
        "Thermal_inp_dir = '/content/gdrive/My Drive/thermal_8_bit'\n",
        "train_list = common_images(RGB_inp_dir,Thermal_inp_dir) \n",
        "\n",
        "val_RGB_inp_dir = '/content/gdrive/My Drive/Val_RGB'\n",
        "val_Thermal_inp_dir = '/content/gdrive/My Drive/Val_thermal_8_bit'\n",
        "val_list = common_images(val_RGB_inp_dir,val_Thermal_inp_dir)\n",
        "\n",
        "def processing_saving_images(modality,quick_test=True,Train_required=False,Val_required=True):\n",
        "  all_images = []\n",
        "  val_all_images = []\n",
        "  \n",
        "  if modality == 'RGB_':\n",
        "    suffix = '.jpg'\n",
        "    channels = 3\n",
        "    inp_dir = '/content/gdrive/My Drive/RGB'\n",
        "    val_inp_dir = '/content/gdrive/My Drive/Val_RGB'\n",
        "  \n",
        "  elif modality == 'Thermal_':\n",
        "    suffix = '.jpeg'\n",
        "    channels = 1\n",
        "    inp_dir = '/content/gdrive/My Drive/thermal_8_bit'\n",
        "    val_inp_dir = '/content/gdrive/My Drive/Val_thermal_8_bit'\n",
        "  \n",
        "  else:\n",
        "    return('Incorrect Modality name')\n",
        "\n",
        "  if quick_test:\n",
        "    if Train_required:\n",
        "      for i, img_name in enumerate(train_list):\n",
        "        if i< 10:\n",
        "          fname = inp_dir + '/' + img_name + suffix\n",
        "          if modality == 'RGB_':\n",
        "            image = image_utils.load_img(fname).resize(target_size,Image.ANTIALIAS)\n",
        "          else:\n",
        "            image = image_utils.load_img(fname,color_mode='grayscale').resize(target_size,Image.ANTIALIAS)\n",
        "          image = np.array(image.getdata()).reshape(target_size[0], target_size[1], channels)\n",
        "          image = image.astype('float32')/255 \n",
        "          all_images.append(image)\n",
        "        else:\n",
        "          pass\n",
        "    else:\n",
        "      pass\n",
        "    \n",
        "    if Val_required:\n",
        "      for j, img_name in enumerate(val_list):\n",
        "        if j < 10:\n",
        "          fname = val_inp_dir + '/' + img_name + suffix\n",
        "          if modality == 'RGB_':\n",
        "            image = image_utils.load_img(fname).resize(target_size,Image.ANTIALIAS)\n",
        "          else:\n",
        "            image = image_utils.load_img(fname,color_mode='grayscale').resize(target_size,Image.ANTIALIAS)\n",
        "          \n",
        "          image = np.array(image.getdata()).reshape(target_size[0], target_size[1], channels)\n",
        "          image = image.astype('float32')/255 \n",
        "          val_all_images.append(image)\n",
        "        else: \n",
        "          pass \n",
        "    else:\n",
        "      pass\n",
        "\n",
        "  else:\n",
        "    if Train_required:\n",
        "      for i, img_name in enumerate(train_list):\n",
        "        fname = inp_dir + '/' + img_name + suffix\n",
        "        if modality == 'RGB_':\n",
        "          image = image_utils.load_img(fname).resize(target_size,Image.ANTIALIAS)\n",
        "        else:\n",
        "          image = image_utils.load_img(fname,color_mode='grayscale').resize(target_size,Image.ANTIALIAS)\n",
        "        image = np.array(image.getdata()).reshape(target_size[0], target_size[1],channels)\n",
        "        image = image.astype('float32')/255\n",
        "        all_images.append(image)\n",
        "        if not i%100:\n",
        "          print(i)\n",
        "        else: \n",
        "          pass\n",
        "    else:\n",
        "      pass\n",
        "  \n",
        "    if Val_required:\n",
        "      for j, img_name in enumerate(val_list):\n",
        "        fname = val_inp_dir + '/' + img_name + suffix\n",
        "        if modality == 'RGB_':\n",
        "          image = image_utils.load_img(fname).resize(target_size,Image.ANTIALIAS)\n",
        "        else:\n",
        "          image = image_utils.load_img(fname,color_mode='grayscale').resize(target_size,Image.ANTIALIAS)\n",
        "        image = np.array(image.getdata()).reshape(target_size[0], target_size[1],channels)\n",
        "        image = image.astype('float32')/255\n",
        "        val_all_images.append(image)\n",
        "        if not j%100:\n",
        "          print(j)\n",
        "        else: \n",
        "          pass\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "  if Train_required: \n",
        "    np.save(modality +str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy',all_images)\n",
        "\n",
        "  if Val_required:\n",
        "    np.save('Val_'+modality +str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy',val_all_images)\n",
        "\n",
        "\n",
        "rgb_modality = 'RGB_'\n",
        "thermal_modality = 'Thermal_'\n",
        "\n",
        "processing_saving_images(thermal_modality,quick_test=False,Train_required=False,Val_required=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsUjLwHf9FP9",
        "colab_type": "text"
      },
      "source": [
        "# Uploading from drive directly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kkaWdar9Ib-",
        "colab_type": "code",
        "outputId": "592bc1be-8ed9-4d0d-8584-2e1fc4bac2f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "upload_directly = True\n",
        "if upload_directly:\n",
        "  x_rgb = np.load('/content/gdrive/My Drive/RGB_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  val_x_rgb = np.load('/content/gdrive/My Drive/Val_RGB_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  x = np.load('/content/gdrive/My Drive/Thermal_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  val_x = np.load('/content/gdrive/My Drive/Val_Thermal_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "else:\n",
        "  x_rgb = np.load('/content/RGB_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  val_x_rgb = np.load('/content/Val_RGB_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  x = np.load('/content/Thermal_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  val_x = np.load('/content/Val_Thermal_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "\n",
        "#val_x = val_x[:len(val_x_rgb)] # Nawid - Make into the same size as the limiting case\n",
        "print(x_rgb.shape)\n",
        "print(val_x_rgb.shape)\n",
        "print(x.shape)\n",
        "print(val_x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8363, 64, 64, 3)\n",
            "(1257, 64, 64, 3)\n",
            "(8363, 64, 64, 1)\n",
            "(1257, 64, 64, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yft7Ami9Vbs",
        "colab_type": "text"
      },
      "source": [
        "# Model config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLXuKr8u9WZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "log_interval = 50\n",
        "rapid_evaluation = False\n",
        "eval_counter = 50\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
        "noisy_pixels = 200 # Nawid - Number of pixels to flip\n",
        "missing_value = -1 # Nawid - Value to choose to represent the missing modality\n",
        "#VAE_PATH_SAVE = 'vae.pt'\n",
        "#VAE_PATH = 'vae.pt'\n",
        "#VAE_PATH = '/content/gdrive/My Drive/vae_cycle1_training.pt'\n",
        "# Nawid - Used to ensure the results are reproducible - https://pytorch.org/docs/stable/notes/randomness.html\n",
        "\n",
        "\n",
        "reproducible = False\n",
        "seed_value = 0\n",
        "if reproducible:\n",
        "  torch.manual_seed(seed_value)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  np.random.seed(seed_value)\n",
        "\n",
        "#missing_threshold = 0.3\n",
        "\n",
        "save_data = False\n",
        "if save_data:\n",
        "  tb = TensorBoardColab() # Nawid - Creates a tensorboard link "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4333NUk15zou",
        "colab_type": "text"
      },
      "source": [
        "# Data loader functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsMoW1pHROZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def missing_modality_output(modal_input,defect):\n",
        "  target = modal_input.clone() # Nawid - The target is the input before it has been modified - Need to clone it otherwise the changes to the modal_input later on is carried through\n",
        "  if defect == 0: # Nawid - PATCH\n",
        "    modal_input[:,:,target_size[0]//2:target_size[0]//2 + 30, target_size[1]//2: target_size[1]//2 + 30] = missing_value\n",
        "  elif defect == 1: # Nawid - Need to add the flipped pixel at some point\n",
        "    height_list = [random.randint(0,target_size[0]-1) for i in range(noisy_pixels)]\n",
        "    width_list = [random.randint(0,target_size[1]-1) for i in range(noisy_pixels)]\n",
        "    modal_input[:,:,height_list,width_list] = missing_value\n",
        "\n",
        "  elif defect ==2: # Nawid - Missing modality\n",
        "    modal_input = modal_input.new_full((modal_input.size()),missing_value) #  Nawid- Overwrite modal input so that the modality is completely missing \n",
        "  return modal_input, target\n",
        "\n",
        "class ConcatDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, *datasets):\n",
        "        self.datasets = datasets\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return tuple(d[i] for d in self.datasets)\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(d) for d in self.datasets)\n",
        "\n",
        "def rgb_thermal_data_loader(input_rgb,input_thermal): # Nawid - Creates a dataloader object\n",
        "    return torch.utils.data.DataLoader(ConcatDataset(input_rgb,input_thermal),batch_size=BATCH_SIZE, shuffle = True)\n",
        "\n",
        "def rgb_thermal_load_images(input_rgb, input_thermal): # Nawid - Loads images\n",
        "    while True:\n",
        "        for (rgb_data,thermal_data) in rgb_thermal_data_loader(input_rgb,input_thermal):\n",
        "          #data = data.float()/255 # Nawid - Divides by 255 \n",
        "          rgb_data = rgb_data.permute(0, 3, 1, 2).contiguous() # Nawid - Changes into pytorch ordering\n",
        "          thermal_data = thermal_data.permute(0, 3, 1, 2).contiguous()\n",
        "          yield rgb_data, thermal_data\n",
        "\n",
        "# https://gist.github.com/MFreidank/821cc87b012c53fade03b0c7aba13958\n",
        "class InfiniteDataLoader(DataLoader): \n",
        "  def __init__(self,input_rgb,input_thermal, batch_size=BATCH_SIZE, shuffle=True):\n",
        "    super().__init__(ConcatDataset(input_rgb,input_thermal), batch_size=BATCH_SIZE, shuffle=True) # Nawid - Instantiates the dataloader subclass using a concatenated input\n",
        "\n",
        "    #Initialise an iterator over the dataset\n",
        "    self.dataset_iterator = super().__iter__()\n",
        "\n",
        "  def __iter__(self):\n",
        "    return self\n",
        "\n",
        "  def __next__(self,Missing= False, Missing_modality =None,Defect = None): # Nawid - Added the Missing term here\n",
        "    try:\n",
        "      batch = next(self.dataset_iterator)\n",
        "      \n",
        "    except StopIteration:\n",
        "      # Dataset exhausted, use a new fresh iterator\n",
        "      self.dataset_iterator = super().__iter__()\n",
        "      batch = next(self.dataset_iterator)\n",
        "\n",
        "    rgb_batch, thermal_batch = batch[0], batch[1] # Nawid- Obtains the different values in the batch\n",
        "    rgb_batch = rgb_batch.permute(0, 3, 1, 2).contiguous() # Nawid- Added this to change the channels - Change to pytorch ordering\n",
        "    thermal_batch = thermal_batch.permute(0, 3, 1, 2).contiguous()\n",
        "    \n",
        "    if Missing:\n",
        "      if Missing_modality == 'Thermal':\n",
        "        thermal_batch, target_modality = missing_modality_output(thermal_batch,Defect)\n",
        "      elif Missing_modality == 'RGB':\n",
        "        rgb_batch, target_modality = missing_modality_output(rgb_batch,Defect)\n",
        "      return rgb_batch.to(device), thermal_batch.to(device), target_modality.to(device)\n",
        "    else:\n",
        "      return rgb_batch.to(device), thermal_batch.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAGwcIu8I0c5",
        "colab_type": "text"
      },
      "source": [
        "# Setup for simulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fJN3v-AIywq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%d%m%Y_%H:%M:%S\")\n",
        "path = 'Data_'+dt_string\n",
        "os.mkdir(path)\n",
        "\n",
        "def training_phase(phase_number):\n",
        "  if phase ==0:\n",
        "    VAE_PATH = path + '/' +'vae.pt'\n",
        "    VAE_PATH_SAVE = path + '/' +'vae.pt'\n",
        "    missing = False\n",
        "    missing_modality = None\n",
        "  elif phase ==1:\n",
        "    VAE_PATH = '/content/gdrive/My Drive/vae_cycle1_training.pt'\n",
        "    VAE_PATH_SAVE = path + '/' +'vae.pt'\n",
        "    missing = True\n",
        "    missing_modality = 'Thermal'\n",
        "  elif phase ==2:\n",
        "    VAE_PATH = '/content/gdrive/My Drive/vae_cycle1_training.pt'\n",
        "    VAE_PATH_SAVE = path + '/' +'vae.pt'\n",
        "    missing =True\n",
        "    missing_modality = 'RGB'\n",
        "  elif phase ==3:\n",
        "    VAE_PATH = path + '/' +'vae.pt'\n",
        "    VAE_PATH_SAVE = path + '/' +'vae.pt'\n",
        "    missing = True\n",
        "    missing_modality = 'Thermal'\n",
        "  elif phase ==4:\n",
        "    VAE_PATH = path + '/' +'vae.pt'\n",
        "    VAE_PATH_SAVE = path + '/' +'vae.pt'\n",
        "    missing = True\n",
        "    missing_modality = 'RGB'\n",
        "  return VAE_PATH, VAE_PATH_SAVE, missing, missing_modality\n",
        "\n",
        "phase = 3\n",
        "# Nawid - Defects should be patches, changed pixels as well as fully missing modality\n",
        "defect = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDpfwkbJ6L04",
        "colab_type": "text"
      },
      "source": [
        "# Main - Training and reconstructions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUEtUcYSIwpK",
        "colab_type": "code",
        "outputId": "a9f0c552-bf97-436a-b99f-5705a525ad9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def main():\n",
        "  # Nawid - Conditions for the training\n",
        "  VAE_PATH, VAE_PATH_SAVE, missing, missing_modality = training_phase(phase)\n",
        "\n",
        "  model = make_vae()\n",
        "  if os.path.exists(VAE_PATH):\n",
        "    model.load_state_dict(torch.load(VAE_PATH, map_location='cpu'))\n",
        "  model.to(device)\n",
        "  optimizer = optim.Adam(model.parameters(),1e-4) \n",
        "  \n",
        "  # Nawid - Validation iterator\n",
        "  val_loader = InfiniteDataLoader(x_rgb,x)\n",
        "  val_iterator = iter(val_loader) \n",
        "\n",
        "  \n",
        "  #missing_threshold = 1.0 if missing is False else 0.0\n",
        "\n",
        "  i = 0\n",
        "  for x_rgb_batch, x_thermal_batch in rgb_thermal_load_images(x_rgb,x): # Nawid - Obtains the minibatch and the thermal target for the case when the modality is missing\n",
        "    x_rgb_batch = x_rgb_batch.to(device)\n",
        "    x_thermal_batch = x_thermal_batch.to(device)\n",
        "    \n",
        "    if missing: # Nawid - If missing, then need to input the missing modality as well as the target value\n",
        "      if missing_modality == \"Thermal\":\n",
        "        x_thermal_batch,target = missing_modality_output(x_thermal_batch,defect) # Nawid - Input the specific defect \n",
        "        terms = model(x_rgb_batch, x_thermal_batch,target_thermal = target)\n",
        "      elif missing_modality == \"RGB\":\n",
        "        x_rgb_batch, target = missing_modality_output(x_rgb_batch,defect)\n",
        "        terms = model(x_rgb_batch, x_thermal_batch,target_rgb = target)\n",
        "    else: # Nawid - If the modality is not missing, then only need to input the rgb and thermal images\n",
        "      terms = model(x_rgb_batch, x_thermal_batch)\n",
        "\n",
        "    '''\n",
        "    # Nawid -Sets the value for missing for the next iteration by checking if the random value is above a certain threshold\n",
        "    random_value = random.random()\n",
        "    if random_value > missing_threshold:\n",
        "      missing = True\n",
        "    else:\n",
        "      missing = False\n",
        "    '''\n",
        "\n",
        "    if rapid_evaluation:\n",
        "      print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    else:\n",
        "      if not i % eval_counter:\n",
        "        print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    \n",
        "    optimizer.zero_grad() #Nawid - I think this makes the gradient become zero\n",
        "    terms['loss'].backward() # Nawid - Backpropagates the total loss term ( which is related to all the different components)\n",
        "    optimizer.step() # Nawid- Updates using optimizer\n",
        "    model.revive_dead_entries()\n",
        "    i +=1\n",
        "    #missing_threshold -=0.01 \n",
        "\n",
        "    if i == 100:\n",
        "      for g in optimizer.param_groups:\n",
        "        g['lr'] = 1e-3\n",
        "\n",
        "    if not i % 200:\n",
        "      torch.save(model.state_dict(), VAE_PATH_SAVE)\n",
        "      \n",
        "      #save_reconstructions(x_rgb_batch, terms['reconstructions'][-1], x_thermal_batch,terms['reconstructions_thermal'][-1])\n",
        "      if missing: # Nawid-  Saves the reconstruction when there is or isn't a modality change.\n",
        "        if missing_modality == 'Thermal':\n",
        "          save_reconstructions(model, x_rgb_batch,x_thermal_batch,target_thermal=target)\n",
        "          val_rgb_batch,val_thermal_batch, val_target = val_iterator.__next__(Missing=missing,Missing_modality = missing_modality,Defect = defect)\n",
        "          save_reconstructions(model, val_rgb_batch,val_thermal_batch,target_thermal = val_target, name= 'Val')\n",
        "        elif missing_modality == 'RGB':\n",
        "          save_reconstructions(model, x_rgb_batch,x_thermal_batch, target_rgb = target)\n",
        "          val_rgb_batch,val_thermal_batch, val_target = val_iterator.__next__(Missing=missing, Missing_modality = missing_modality, Defect = defect)\n",
        "          save_reconstructions(model, val_rgb_batch,val_thermal_batch,target_rgb = val_target, name= 'Val')\n",
        "      else:\n",
        "        save_reconstructions(model,x_rgb_batch, x_thermal_batch)\n",
        "        '''\n",
        "        #val_rgb_batch,val_thermal_batch = next(val_iterator)\n",
        "        val_rgb_batch, val_thermal_batch = val_iterator.__next__(missing)\n",
        "        val_total_loss, val_reconstruction_loss = validation_loss(model,val_rgb_batch,val_thermal_batch) # Nawid - Calculates the loss in the validation set\n",
        "        save_reconstructions(model,val_rgb_batch, val_thermal_batch, name = 'Val') # Nawid - Need to specify as name as otherwise it would specify target thermal\n",
        "        '''\n",
        "      '''\n",
        "      # Nawid - Updates model only if the validation loss is less\n",
        "      if val_total_loss < minimum_val_total_loss:\n",
        "        previous_val_total_loss = val_total_loss\n",
        "        torch.save(model.state_dict(), VAE_PATH_SAVE)\n",
        "      '''\n",
        "      '''\n",
        "      val_rgb_batch,val_thermal_batch = next(val_iterator)      \n",
        "      if save_data:\n",
        "        val_total_loss, val_reconstruction_loss = validation_loss(model,val_rgb_batch,val_thermal_batch)\n",
        "        tensorboard_saving(i,terms['losses'][-1],val_reconstruction_loss, terms['loss'],val_total_loss)\n",
        "      else:\n",
        "        pass\n",
        "      save_reconstructions(model,val_rgb_batch, val_thermal_batch,'Val')\n",
        "      '''\n",
        "\n",
        "def tensorboard_saving(iteration,recon_loss_train, recon_loss_val, total_loss_train,total_loss_val):\n",
        "  tb.save_value('Reconstruction_loss','Train loss', iteration, recon_loss_train)\n",
        "  tb.save_value('Reconstruction_loss','Validation loss', iteration, recon_loss_val)\n",
        "      \n",
        "  tb.save_value('Total_loss','Train loss', iteration, total_loss_train)\n",
        "  tb.save_value('Total_loss','Validation loss', iteration, total_loss_val)\n",
        " \n",
        "  tb.flush_line('Reconstruction_loss')\n",
        "  tb.flush_line('Total_loss')\n",
        "\n",
        "def validation_loss(vae,val_rgb, val_thermal):\n",
        "  vae.eval() # Nawid - Sets it into evaluation mode ( so dropout and batchnorm have different behaviours)\n",
        "  with torch.no_grad(): # Nawid-  Turns off the autograd engine which speeds up computation\n",
        "    val_terms = vae(val_rgb,val_thermal)\n",
        "    total_loss, reconstruction_loss = val_terms['loss'], val_terms['losses'][-1]\n",
        "    vae.train()\n",
        "    return total_loss, reconstruction_loss\n",
        "\n",
        "def save_reconstructions(vae,rgb_images,thermal_images,target_rgb = None,target_thermal = None, name = 'Train'):\n",
        "  vae.eval()\n",
        "  with torch.no_grad():\n",
        "    recons, recons_thermal = vae.full_reconstructions(rgb_images,thermal_images)\n",
        "    recons = [torch.clamp(x, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x in recons] # Nawid - Clamps all the different elements in recons\n",
        "    recons_thermal = [torch.clamp(x_thermal, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x_thermal in recons_thermal] # Nawid - Clamps all the different elements in recons_thermal\n",
        "    \n",
        "    vae.train() # Nawid - This sets the nn.module into training mode\n",
        "    top_recons, real_recons = recons # Nawid - I believe the top_recons is the reconstruction using only the top latent map, whilst real_recons is using both the top latent map and the bottom latent map\n",
        "    target_rgb = rgb_images if target_rgb is None else target_rgb\n",
        "    target_rgb = target_rgb.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "    #rgb_images = rgb_images.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "    \n",
        "    rgb_images = rgb_images.permute(0,2,3,1).detach().cpu().numpy()\n",
        "\n",
        "\n",
        "    columns = np.concatenate([rgb_images, top_recons, real_recons, target_rgb], axis=-2)\n",
        "    columns = np.concatenate(columns, axis=0)\n",
        "    Image.fromarray((columns * 255).astype('uint8')).save(path+'/'+name +'_reconstructions_rgb.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "    top_recons_thermal,real_recons_thermal = recons_thermal\n",
        "    \n",
        "    target_thermal = thermal_images if target_thermal is None else target_thermal # Nawid- Sets the value for target_thermal to input_thermal if target_thermal is none. else it is the value that I input\n",
        "    target_thermal = target_thermal.permute(0,2,3,1).detach().cpu().numpy()\n",
        "    target_thermal = target_thermal.reshape(target_thermal.shape[0],target_thermal.shape[1],target_thermal.shape[2])\n",
        "    \n",
        "    thermal_images = thermal_images.permute(0,2,3,1).detach().cpu().numpy()\n",
        "    thermal_images = thermal_images.reshape(thermal_images.shape[0],thermal_images.shape[1],thermal_images.shape[2])\n",
        "\n",
        "    #thermal_images = thermal_images.permute(0,2,3,1).detach().cpu().numpy()\n",
        "    #thermal_images = thermal_images.reshape(thermal_images.shape[0],thermal_images.shape[1],thermal_images.shape[2])\n",
        "    #target_thermal = thermal_images if target_thermal is None else target_thermal # Nawid- Sets the value for target_thermal to input_thermal if target_thermal is none. else it is the value that I input\n",
        "    \n",
        "    top_recons_thermal = top_recons_thermal.reshape(top_recons_thermal.shape[0],top_recons_thermal.shape[1],top_recons_thermal.shape[2])\n",
        "    real_recons_thermal = real_recons_thermal.reshape(real_recons_thermal.shape[0],real_recons_thermal.shape[1],real_recons_thermal.shape[2])\n",
        "\n",
        "    columns_thermal = np.concatenate([thermal_images,top_recons_thermal, real_recons_thermal,target_thermal], axis=-1) # Nawid - I need to concatenate along -2 when using rgb and -1 when using grayscale and when using  When using grayscale images, to save the files using PIL, i need to make to remove the channel and so there is one less axis to examine\n",
        "    columns_thermal = np.concatenate(columns_thermal, axis=0)\n",
        "    Image.fromarray((columns_thermal * 255).astype('uint8')).save(path+'/'+ name +'_reconstructions_thermal.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "main()   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0: mse=0.647865 mse_top=0.053116\n",
            "step 50: mse=0.075802 mse_top=0.046344\n",
            "step 100: mse=0.061529 mse_top=0.047783\n",
            "step 150: mse=0.025856 mse_top=0.030313\n",
            "step 200: mse=0.108161 mse_top=0.649343\n",
            "step 250: mse=0.020951 mse_top=0.008305\n",
            "step 300: mse=0.015940 mse_top=0.005135\n",
            "step 350: mse=0.013751 mse_top=0.002709\n",
            "step 400: mse=0.010917 mse_top=0.002272\n",
            "step 450: mse=0.010650 mse_top=0.002116\n",
            "step 500: mse=0.008394 mse_top=0.001810\n",
            "step 550: mse=0.009577 mse_top=0.002033\n",
            "step 600: mse=0.009117 mse_top=0.002101\n",
            "step 650: mse=0.008931 mse_top=0.002272\n",
            "step 700: mse=0.008359 mse_top=0.002426\n",
            "step 750: mse=0.008789 mse_top=0.002744\n",
            "step 800: mse=0.007214 mse_top=0.002629\n",
            "step 850: mse=0.006939 mse_top=0.002562\n",
            "step 900: mse=0.006826 mse_top=0.002531\n",
            "step 950: mse=0.007505 mse_top=0.002992\n",
            "step 1000: mse=0.007612 mse_top=0.003270\n",
            "step 1050: mse=0.006559 mse_top=0.004531\n",
            "step 1100: mse=0.006660 mse_top=0.005463\n",
            "step 1150: mse=0.007966 mse_top=0.005315\n",
            "step 1200: mse=0.006153 mse_top=0.005471\n",
            "step 1250: mse=0.007735 mse_top=0.007452\n",
            "step 1300: mse=0.007079 mse_top=0.004736\n",
            "step 1350: mse=0.006587 mse_top=0.003992\n",
            "step 1400: mse=0.007070 mse_top=0.006437\n",
            "step 1450: mse=0.006076 mse_top=0.004873\n",
            "step 1500: mse=0.007410 mse_top=0.005359\n",
            "step 1550: mse=0.007639 mse_top=0.006162\n",
            "step 1600: mse=0.005868 mse_top=0.004907\n",
            "step 1650: mse=0.006139 mse_top=0.005151\n",
            "step 1700: mse=0.005891 mse_top=0.005603\n",
            "step 1750: mse=0.006463 mse_top=0.005841\n",
            "step 1800: mse=0.007032 mse_top=0.005947\n",
            "step 1850: mse=0.006495 mse_top=0.006331\n",
            "step 1900: mse=0.005856 mse_top=0.005667\n",
            "step 1950: mse=0.005335 mse_top=0.005588\n",
            "step 2000: mse=0.008266 mse_top=0.006385\n",
            "step 2050: mse=0.006134 mse_top=0.006403\n",
            "step 2100: mse=0.006091 mse_top=0.006187\n",
            "step 2150: mse=0.006654 mse_top=0.007117\n",
            "step 2200: mse=0.005764 mse_top=0.006769\n",
            "step 2250: mse=0.005942 mse_top=0.006844\n",
            "step 2300: mse=0.005747 mse_top=0.007777\n",
            "step 2350: mse=0.005009 mse_top=0.006651\n",
            "step 2400: mse=0.005649 mse_top=0.007762\n",
            "step 2450: mse=0.005963 mse_top=0.008216\n",
            "step 2500: mse=0.005424 mse_top=0.007788\n",
            "step 2550: mse=0.005054 mse_top=0.007686\n",
            "step 2600: mse=0.005523 mse_top=0.008520\n",
            "step 2650: mse=0.005580 mse_top=0.008085\n",
            "step 2700: mse=0.005775 mse_top=0.008791\n",
            "step 2750: mse=0.004734 mse_top=0.006961\n",
            "step 2800: mse=0.004799 mse_top=0.006920\n",
            "step 2850: mse=0.004924 mse_top=0.007886\n",
            "step 2900: mse=0.005007 mse_top=0.007777\n",
            "step 2950: mse=0.006034 mse_top=0.007527\n",
            "step 3000: mse=0.005456 mse_top=0.007493\n",
            "step 3050: mse=0.004666 mse_top=0.007247\n",
            "step 3100: mse=0.005638 mse_top=0.008886\n",
            "step 3150: mse=0.005237 mse_top=0.008623\n",
            "step 3200: mse=0.005485 mse_top=0.008547\n",
            "step 3250: mse=0.004854 mse_top=0.007778\n",
            "step 3300: mse=0.005674 mse_top=0.009022\n",
            "step 3350: mse=0.005294 mse_top=0.008854\n",
            "step 3400: mse=0.005296 mse_top=0.008953\n",
            "step 3450: mse=0.005779 mse_top=0.009578\n",
            "step 3500: mse=0.004996 mse_top=0.009204\n",
            "step 3550: mse=0.004666 mse_top=0.008165\n",
            "step 3600: mse=0.005022 mse_top=0.008982\n",
            "step 3650: mse=0.005750 mse_top=0.009496\n",
            "step 3700: mse=0.005331 mse_top=0.009736\n",
            "step 3750: mse=0.004861 mse_top=0.008344\n",
            "step 3800: mse=0.005202 mse_top=0.009639\n",
            "step 3850: mse=0.005869 mse_top=0.011132\n",
            "step 3900: mse=0.004539 mse_top=0.007659\n",
            "step 3950: mse=0.004594 mse_top=0.008338\n",
            "step 4000: mse=0.004746 mse_top=0.008346\n",
            "step 4050: mse=0.004976 mse_top=0.009389\n",
            "step 4100: mse=0.006124 mse_top=0.008905\n",
            "step 4150: mse=0.005019 mse_top=0.008913\n",
            "step 4200: mse=0.004720 mse_top=0.008938\n",
            "step 4250: mse=0.005098 mse_top=0.009763\n",
            "step 4300: mse=0.004596 mse_top=0.008602\n",
            "step 4350: mse=0.004694 mse_top=0.008785\n",
            "step 4400: mse=0.004412 mse_top=0.008551\n",
            "step 4450: mse=0.004914 mse_top=0.009798\n",
            "step 4500: mse=0.004547 mse_top=0.008918\n",
            "step 4550: mse=0.004959 mse_top=0.010026\n",
            "step 4600: mse=0.004763 mse_top=0.008129\n",
            "step 4650: mse=0.004508 mse_top=0.008433\n",
            "step 4700: mse=0.004695 mse_top=0.008717\n",
            "step 4750: mse=0.004616 mse_top=0.008504\n",
            "step 4800: mse=0.004886 mse_top=0.009769\n",
            "step 4850: mse=0.005084 mse_top=0.009762\n",
            "step 4900: mse=0.004796 mse_top=0.008513\n",
            "step 4950: mse=0.005453 mse_top=0.010043\n",
            "step 5000: mse=0.004400 mse_top=0.008695\n",
            "step 5050: mse=0.003811 mse_top=0.007446\n",
            "step 5100: mse=0.004796 mse_top=0.008922\n",
            "step 5150: mse=0.004612 mse_top=0.009625\n",
            "step 5200: mse=0.004494 mse_top=0.008756\n",
            "step 5250: mse=0.004857 mse_top=0.009512\n",
            "step 5300: mse=0.004205 mse_top=0.008472\n",
            "step 5350: mse=0.003787 mse_top=0.007750\n",
            "step 5400: mse=0.004913 mse_top=0.009698\n",
            "step 5450: mse=0.004721 mse_top=0.009782\n",
            "step 5500: mse=0.004713 mse_top=0.009525\n",
            "step 5550: mse=0.004809 mse_top=0.009567\n",
            "step 5600: mse=0.004248 mse_top=0.008675\n",
            "step 5650: mse=0.004024 mse_top=0.008341\n",
            "step 5700: mse=0.004758 mse_top=0.007683\n",
            "step 5750: mse=0.004457 mse_top=0.009276\n",
            "step 5800: mse=0.003913 mse_top=0.007987\n",
            "step 5850: mse=0.004301 mse_top=0.007726\n",
            "step 5900: mse=0.004271 mse_top=0.008530\n",
            "step 5950: mse=0.004120 mse_top=0.008682\n",
            "step 6000: mse=0.005130 mse_top=0.010854\n",
            "step 6050: mse=0.004487 mse_top=0.009416\n",
            "step 6100: mse=0.004671 mse_top=0.008814\n",
            "step 6150: mse=0.004078 mse_top=0.007639\n",
            "step 6200: mse=0.003749 mse_top=0.007512\n",
            "step 6250: mse=0.004019 mse_top=0.007845\n",
            "step 6300: mse=0.005279 mse_top=0.010598\n",
            "step 6350: mse=0.003898 mse_top=0.007991\n",
            "step 6400: mse=0.004010 mse_top=0.008117\n",
            "step 6450: mse=0.004155 mse_top=0.008730\n",
            "step 6500: mse=0.004028 mse_top=0.008556\n",
            "step 6550: mse=0.003983 mse_top=0.008237\n",
            "step 6600: mse=0.004131 mse_top=0.008388\n",
            "step 6650: mse=0.004187 mse_top=0.008303\n",
            "step 6700: mse=0.004392 mse_top=0.009191\n",
            "step 6750: mse=0.004811 mse_top=0.009484\n",
            "step 6800: mse=0.004459 mse_top=0.008754\n",
            "step 6850: mse=0.003928 mse_top=0.008105\n",
            "step 6900: mse=0.004639 mse_top=0.008989\n",
            "step 6950: mse=0.004421 mse_top=0.008338\n",
            "step 7000: mse=0.004271 mse_top=0.009027\n",
            "step 7050: mse=0.004484 mse_top=0.009496\n",
            "step 7100: mse=0.003869 mse_top=0.008052\n",
            "step 7150: mse=0.004326 mse_top=0.009488\n",
            "step 7200: mse=0.004371 mse_top=0.009270\n",
            "step 7250: mse=0.003962 mse_top=0.008465\n",
            "step 7300: mse=0.004275 mse_top=0.009057\n",
            "step 7350: mse=0.003894 mse_top=0.008091\n",
            "step 7400: mse=0.003943 mse_top=0.008328\n",
            "step 7450: mse=0.004716 mse_top=0.009552\n",
            "step 7500: mse=0.004145 mse_top=0.009194\n",
            "step 7550: mse=0.003676 mse_top=0.007956\n",
            "step 7600: mse=0.004193 mse_top=0.008290\n",
            "step 7650: mse=0.004405 mse_top=0.009119\n",
            "step 7700: mse=0.004061 mse_top=0.008798\n",
            "step 7750: mse=0.004191 mse_top=0.008617\n",
            "step 7800: mse=0.004758 mse_top=0.008702\n",
            "step 7850: mse=0.004158 mse_top=0.008492\n",
            "step 7900: mse=0.003966 mse_top=0.008382\n",
            "step 7950: mse=0.004215 mse_top=0.009133\n",
            "step 8000: mse=0.004189 mse_top=0.008607\n",
            "step 8050: mse=0.004206 mse_top=0.009252\n",
            "step 8100: mse=0.003495 mse_top=0.007332\n",
            "step 8150: mse=0.003667 mse_top=0.008004\n",
            "step 8200: mse=0.003398 mse_top=0.006819\n",
            "step 8250: mse=0.004557 mse_top=0.009906\n",
            "step 8300: mse=0.004402 mse_top=0.008846\n",
            "step 8350: mse=0.004021 mse_top=0.008779\n",
            "step 8400: mse=0.003983 mse_top=0.008705\n",
            "step 8450: mse=0.004234 mse_top=0.007678\n",
            "step 8500: mse=0.004390 mse_top=0.009363\n",
            "step 8550: mse=0.004084 mse_top=0.008415\n",
            "step 8600: mse=0.003607 mse_top=0.007667\n",
            "step 8650: mse=0.004278 mse_top=0.008709\n",
            "step 8700: mse=0.004376 mse_top=0.009534\n",
            "step 8750: mse=0.004470 mse_top=0.009499\n",
            "step 8800: mse=0.003986 mse_top=0.008788\n",
            "step 8850: mse=0.003945 mse_top=0.007972\n",
            "step 8900: mse=0.004041 mse_top=0.009001\n",
            "step 8950: mse=0.003771 mse_top=0.007962\n",
            "step 9000: mse=0.004112 mse_top=0.009423\n",
            "step 9050: mse=0.003857 mse_top=0.008392\n",
            "step 9100: mse=0.004169 mse_top=0.009116\n",
            "step 9150: mse=0.003648 mse_top=0.007656\n",
            "step 9200: mse=0.003998 mse_top=0.008803\n",
            "step 9250: mse=0.004411 mse_top=0.009227\n",
            "step 9300: mse=0.004801 mse_top=0.009174\n",
            "step 9350: mse=0.003578 mse_top=0.007667\n",
            "step 9400: mse=0.003798 mse_top=0.008440\n",
            "step 9450: mse=0.004132 mse_top=0.008428\n",
            "step 9500: mse=0.003964 mse_top=0.008584\n",
            "step 9550: mse=0.003753 mse_top=0.007703\n",
            "step 9600: mse=0.003784 mse_top=0.008146\n",
            "step 9650: mse=0.003549 mse_top=0.007836\n",
            "step 9700: mse=0.003900 mse_top=0.008512\n",
            "step 9750: mse=0.004006 mse_top=0.008323\n",
            "step 9800: mse=0.003910 mse_top=0.008388\n",
            "step 9850: mse=0.003238 mse_top=0.007072\n",
            "step 9900: mse=0.004183 mse_top=0.008497\n",
            "step 9950: mse=0.003979 mse_top=0.008338\n",
            "step 10000: mse=0.003877 mse_top=0.007959\n",
            "step 10050: mse=0.003746 mse_top=0.008114\n",
            "step 10100: mse=0.004351 mse_top=0.008733\n",
            "step 10150: mse=0.004443 mse_top=0.007451\n",
            "step 10200: mse=0.004132 mse_top=0.008658\n",
            "step 10250: mse=0.003896 mse_top=0.008229\n",
            "step 10300: mse=0.004052 mse_top=0.008995\n",
            "step 10350: mse=0.004406 mse_top=0.009308\n",
            "step 10400: mse=0.003395 mse_top=0.007445\n",
            "step 10450: mse=0.003490 mse_top=0.007572\n",
            "step 10500: mse=0.004143 mse_top=0.008559\n",
            "step 10550: mse=0.003216 mse_top=0.007128\n",
            "step 10600: mse=0.003898 mse_top=0.008016\n",
            "step 10650: mse=0.003828 mse_top=0.008616\n",
            "step 10700: mse=0.003471 mse_top=0.007704\n",
            "step 10750: mse=0.003941 mse_top=0.008010\n",
            "step 10800: mse=0.003949 mse_top=0.007848\n",
            "step 10850: mse=0.003818 mse_top=0.008650\n",
            "step 10900: mse=0.003732 mse_top=0.007721\n",
            "step 10950: mse=0.004026 mse_top=0.008048\n",
            "step 11000: mse=0.003885 mse_top=0.008093\n",
            "step 11050: mse=0.004020 mse_top=0.008737\n",
            "step 11100: mse=0.004024 mse_top=0.008108\n",
            "step 11150: mse=0.003391 mse_top=0.007086\n",
            "step 11200: mse=0.003866 mse_top=0.008095\n",
            "step 11250: mse=0.003784 mse_top=0.008116\n",
            "step 11300: mse=0.003571 mse_top=0.007157\n",
            "step 11350: mse=0.003538 mse_top=0.007141\n",
            "step 11400: mse=0.003632 mse_top=0.007944\n",
            "step 11450: mse=0.004046 mse_top=0.007521\n",
            "step 11500: mse=0.003147 mse_top=0.006449\n",
            "step 11550: mse=0.004212 mse_top=0.009113\n",
            "step 11600: mse=0.003448 mse_top=0.007900\n",
            "step 11650: mse=0.003419 mse_top=0.007261\n",
            "step 11700: mse=0.003661 mse_top=0.007572\n",
            "step 11750: mse=0.003688 mse_top=0.007850\n",
            "step 11800: mse=0.003511 mse_top=0.007389\n",
            "step 11850: mse=0.004117 mse_top=0.008421\n",
            "step 11900: mse=0.003464 mse_top=0.006827\n",
            "step 11950: mse=0.004414 mse_top=0.009346\n",
            "step 12000: mse=0.003733 mse_top=0.008298\n",
            "step 12050: mse=0.003763 mse_top=0.008038\n",
            "step 12100: mse=0.004007 mse_top=0.009075\n",
            "step 12150: mse=0.004331 mse_top=0.009070\n",
            "step 12200: mse=0.004206 mse_top=0.008936\n",
            "step 12250: mse=0.004001 mse_top=0.008413\n",
            "step 12300: mse=0.004109 mse_top=0.008484\n",
            "step 12350: mse=0.004048 mse_top=0.008329\n",
            "step 12400: mse=0.003727 mse_top=0.007844\n",
            "step 12450: mse=0.003532 mse_top=0.007665\n",
            "step 12500: mse=0.003778 mse_top=0.007769\n",
            "step 12550: mse=0.004196 mse_top=0.008329\n",
            "step 12600: mse=0.003468 mse_top=0.007565\n",
            "step 12650: mse=0.003570 mse_top=0.007819\n",
            "step 12700: mse=0.003662 mse_top=0.007656\n",
            "step 12750: mse=0.003615 mse_top=0.007548\n",
            "step 12800: mse=0.003836 mse_top=0.008339\n",
            "step 12850: mse=0.003660 mse_top=0.007381\n",
            "step 12900: mse=0.002884 mse_top=0.006008\n",
            "step 12950: mse=0.003475 mse_top=0.007118\n",
            "step 13000: mse=0.004033 mse_top=0.008570\n",
            "step 13050: mse=0.003972 mse_top=0.008488\n",
            "step 13100: mse=0.003959 mse_top=0.008012\n",
            "step 13150: mse=0.003485 mse_top=0.007110\n",
            "step 13200: mse=0.003875 mse_top=0.008066\n",
            "step 13250: mse=0.003864 mse_top=0.007498\n",
            "step 13300: mse=0.003654 mse_top=0.007758\n",
            "step 13350: mse=0.003430 mse_top=0.007346\n",
            "step 13400: mse=0.003809 mse_top=0.008115\n",
            "step 13450: mse=0.003747 mse_top=0.007239\n",
            "step 13500: mse=0.003525 mse_top=0.006967\n",
            "step 13550: mse=0.003740 mse_top=0.008077\n",
            "step 13600: mse=0.003880 mse_top=0.007968\n",
            "step 13650: mse=0.003697 mse_top=0.007767\n",
            "step 13700: mse=0.004070 mse_top=0.009326\n",
            "step 13750: mse=0.003036 mse_top=0.006082\n",
            "step 13800: mse=0.003121 mse_top=0.006844\n",
            "step 13850: mse=0.003557 mse_top=0.007514\n",
            "step 13900: mse=0.003598 mse_top=0.007471\n",
            "step 13950: mse=0.003358 mse_top=0.006764\n",
            "step 14000: mse=0.003917 mse_top=0.008143\n",
            "step 14050: mse=0.003318 mse_top=0.006861\n",
            "step 14100: mse=0.003604 mse_top=0.007390\n",
            "step 14150: mse=0.003635 mse_top=0.007774\n",
            "step 14200: mse=0.003747 mse_top=0.007284\n",
            "step 14250: mse=0.003573 mse_top=0.007779\n",
            "step 14300: mse=0.003666 mse_top=0.008025\n",
            "step 14350: mse=0.003923 mse_top=0.007800\n",
            "step 14400: mse=0.003781 mse_top=0.007536\n",
            "step 14450: mse=0.003837 mse_top=0.007669\n",
            "step 14500: mse=0.003651 mse_top=0.007815\n",
            "step 14550: mse=0.002919 mse_top=0.006315\n",
            "step 14600: mse=0.003582 mse_top=0.007280\n",
            "step 14650: mse=0.003869 mse_top=0.007848\n",
            "step 14700: mse=0.003687 mse_top=0.007827\n",
            "step 14750: mse=0.003239 mse_top=0.006882\n",
            "step 14800: mse=0.003350 mse_top=0.007645\n",
            "step 14850: mse=0.003093 mse_top=0.006640\n",
            "step 14900: mse=0.002972 mse_top=0.006250\n",
            "step 14950: mse=0.003408 mse_top=0.007001\n",
            "step 15000: mse=0.003287 mse_top=0.007006\n",
            "step 15050: mse=0.003868 mse_top=0.007531\n",
            "step 15100: mse=0.003748 mse_top=0.007209\n",
            "step 15150: mse=0.003785 mse_top=0.007978\n",
            "step 15200: mse=0.003048 mse_top=0.006793\n",
            "step 15250: mse=0.003189 mse_top=0.006504\n",
            "step 15300: mse=0.003668 mse_top=0.007709\n",
            "step 15350: mse=0.003121 mse_top=0.006803\n",
            "step 15400: mse=0.003342 mse_top=0.006822\n",
            "step 15450: mse=0.003564 mse_top=0.007705\n",
            "step 15500: mse=0.003692 mse_top=0.006941\n",
            "step 15550: mse=0.003695 mse_top=0.007994\n",
            "step 15600: mse=0.003490 mse_top=0.007308\n",
            "step 15650: mse=0.003819 mse_top=0.007385\n",
            "step 15700: mse=0.003711 mse_top=0.007700\n",
            "step 15750: mse=0.003252 mse_top=0.006997\n",
            "step 15800: mse=0.003706 mse_top=0.007162\n",
            "step 15850: mse=0.003224 mse_top=0.006871\n",
            "step 15900: mse=0.002732 mse_top=0.005646\n",
            "step 15950: mse=0.003179 mse_top=0.007272\n",
            "step 16000: mse=0.003936 mse_top=0.007675\n",
            "step 16050: mse=0.003303 mse_top=0.006870\n",
            "step 16100: mse=0.003373 mse_top=0.006984\n",
            "step 16150: mse=0.003449 mse_top=0.007492\n",
            "step 16200: mse=0.003663 mse_top=0.007590\n",
            "step 16250: mse=0.003364 mse_top=0.007137\n",
            "step 16300: mse=0.003320 mse_top=0.006855\n",
            "step 16350: mse=0.003398 mse_top=0.006252\n",
            "step 16400: mse=0.003328 mse_top=0.006599\n",
            "step 16450: mse=0.004271 mse_top=0.008569\n",
            "step 16500: mse=0.003546 mse_top=0.007072\n",
            "step 16550: mse=0.003292 mse_top=0.006868\n",
            "step 16600: mse=0.002955 mse_top=0.006212\n",
            "step 16650: mse=0.003341 mse_top=0.006717\n",
            "step 16700: mse=0.003292 mse_top=0.005927\n",
            "step 16750: mse=0.003244 mse_top=0.006652\n",
            "step 16800: mse=0.003364 mse_top=0.006918\n",
            "step 16850: mse=0.003646 mse_top=0.007647\n",
            "step 16900: mse=0.003947 mse_top=0.008171\n",
            "step 16950: mse=0.003553 mse_top=0.007082\n",
            "step 17000: mse=0.003196 mse_top=0.006500\n",
            "step 17050: mse=0.003512 mse_top=0.006980\n",
            "step 17100: mse=0.003367 mse_top=0.007177\n",
            "step 17150: mse=0.003125 mse_top=0.006269\n",
            "step 17200: mse=0.003505 mse_top=0.007075\n",
            "step 17250: mse=0.003366 mse_top=0.007115\n",
            "step 17300: mse=0.003135 mse_top=0.006717\n",
            "step 17350: mse=0.003712 mse_top=0.007420\n",
            "step 17400: mse=0.003295 mse_top=0.007113\n",
            "step 17450: mse=0.003246 mse_top=0.006231\n",
            "step 17500: mse=0.003551 mse_top=0.007452\n",
            "step 17550: mse=0.003180 mse_top=0.006496\n",
            "step 17600: mse=0.004092 mse_top=0.007735\n",
            "step 17650: mse=0.003031 mse_top=0.006860\n",
            "step 17700: mse=0.003314 mse_top=0.006555\n",
            "step 17750: mse=0.003063 mse_top=0.006416\n",
            "step 17800: mse=0.003184 mse_top=0.006720\n",
            "step 17850: mse=0.003209 mse_top=0.006357\n",
            "step 17900: mse=0.003661 mse_top=0.007712\n",
            "step 17950: mse=0.003316 mse_top=0.007365\n",
            "step 18000: mse=0.003376 mse_top=0.007319\n",
            "step 18050: mse=0.003326 mse_top=0.006852\n",
            "step 18100: mse=0.003707 mse_top=0.007932\n",
            "step 18150: mse=0.003665 mse_top=0.008061\n",
            "step 18200: mse=0.003317 mse_top=0.007045\n",
            "step 18250: mse=0.003905 mse_top=0.007852\n",
            "step 18300: mse=0.003411 mse_top=0.007147\n",
            "step 18350: mse=0.003422 mse_top=0.007087\n",
            "step 18400: mse=0.004140 mse_top=0.007385\n",
            "step 18450: mse=0.003908 mse_top=0.008199\n",
            "step 18500: mse=0.003070 mse_top=0.006410\n",
            "step 18550: mse=0.002855 mse_top=0.005937\n",
            "step 18600: mse=0.003724 mse_top=0.007034\n",
            "step 18650: mse=0.002713 mse_top=0.005627\n",
            "step 18700: mse=0.003442 mse_top=0.006935\n",
            "step 18750: mse=0.003071 mse_top=0.006184\n",
            "step 18800: mse=0.003683 mse_top=0.007600\n",
            "step 18850: mse=0.003579 mse_top=0.007513\n",
            "step 18900: mse=0.003554 mse_top=0.006965\n",
            "step 18950: mse=0.003643 mse_top=0.007136\n",
            "step 19000: mse=0.003316 mse_top=0.006972\n",
            "step 19050: mse=0.004174 mse_top=0.008506\n",
            "step 19100: mse=0.003138 mse_top=0.006693\n",
            "step 19150: mse=0.003068 mse_top=0.006180\n",
            "step 19200: mse=0.003251 mse_top=0.006396\n",
            "step 19250: mse=0.003613 mse_top=0.007970\n",
            "step 19300: mse=0.003158 mse_top=0.006737\n",
            "step 19350: mse=0.003544 mse_top=0.006927\n",
            "step 19400: mse=0.003372 mse_top=0.007214\n",
            "step 19450: mse=0.003097 mse_top=0.006010\n",
            "step 19500: mse=0.003392 mse_top=0.007373\n",
            "step 19550: mse=0.003386 mse_top=0.007145\n",
            "step 19600: mse=0.003546 mse_top=0.006754\n",
            "step 19650: mse=0.003586 mse_top=0.007350\n",
            "step 19700: mse=0.003512 mse_top=0.007004\n",
            "step 19750: mse=0.003798 mse_top=0.007028\n",
            "step 19800: mse=0.003009 mse_top=0.006632\n",
            "step 19850: mse=0.003759 mse_top=0.008232\n",
            "step 19900: mse=0.003737 mse_top=0.007155\n",
            "step 19950: mse=0.003295 mse_top=0.006520\n",
            "step 20000: mse=0.003985 mse_top=0.008358\n",
            "step 20050: mse=0.003162 mse_top=0.006390\n",
            "step 20100: mse=0.003298 mse_top=0.006608\n",
            "step 20150: mse=0.003477 mse_top=0.006688\n",
            "step 20200: mse=0.003091 mse_top=0.006622\n",
            "step 20250: mse=0.003290 mse_top=0.007038\n",
            "step 20300: mse=0.003511 mse_top=0.007306\n",
            "step 20350: mse=0.003357 mse_top=0.006967\n",
            "step 20400: mse=0.003192 mse_top=0.006857\n",
            "step 20450: mse=0.002817 mse_top=0.006302\n",
            "step 20500: mse=0.003207 mse_top=0.007115\n",
            "step 20550: mse=0.003223 mse_top=0.006917\n",
            "step 20600: mse=0.003400 mse_top=0.007077\n",
            "step 20650: mse=0.003186 mse_top=0.006741\n",
            "step 20700: mse=0.003356 mse_top=0.006970\n",
            "step 20750: mse=0.003460 mse_top=0.007577\n",
            "step 20800: mse=0.003218 mse_top=0.007047\n",
            "step 20850: mse=0.003355 mse_top=0.007290\n",
            "step 20900: mse=0.003463 mse_top=0.007126\n",
            "step 20950: mse=0.003311 mse_top=0.007267\n",
            "step 21000: mse=0.003273 mse_top=0.006752\n",
            "step 21050: mse=0.003641 mse_top=0.006665\n",
            "step 21100: mse=0.003337 mse_top=0.006904\n",
            "step 21150: mse=0.003373 mse_top=0.006677\n",
            "step 21200: mse=0.003043 mse_top=0.006794\n",
            "step 21250: mse=0.003621 mse_top=0.007575\n",
            "step 21300: mse=0.003594 mse_top=0.007333\n",
            "step 21350: mse=0.003485 mse_top=0.007028\n",
            "step 21400: mse=0.003707 mse_top=0.007323\n",
            "step 21450: mse=0.003403 mse_top=0.007269\n",
            "step 21500: mse=0.003090 mse_top=0.006229\n",
            "step 21550: mse=0.003136 mse_top=0.006734\n",
            "step 21600: mse=0.003113 mse_top=0.006648\n",
            "step 21650: mse=0.003629 mse_top=0.007338\n",
            "step 21700: mse=0.003711 mse_top=0.007580\n",
            "step 21750: mse=0.003345 mse_top=0.006867\n",
            "step 21800: mse=0.003224 mse_top=0.006872\n",
            "step 21850: mse=0.003664 mse_top=0.007063\n",
            "step 21900: mse=0.003494 mse_top=0.007567\n",
            "step 21950: mse=0.003162 mse_top=0.006806\n",
            "step 22000: mse=0.003344 mse_top=0.006869\n",
            "step 22050: mse=0.003250 mse_top=0.006466\n",
            "step 22100: mse=0.003322 mse_top=0.007076\n",
            "step 22150: mse=0.003563 mse_top=0.007714\n",
            "step 22200: mse=0.003249 mse_top=0.006294\n",
            "step 22250: mse=0.003505 mse_top=0.007476\n",
            "step 22300: mse=0.003169 mse_top=0.006271\n",
            "step 22350: mse=0.003045 mse_top=0.006665\n",
            "step 22400: mse=0.003257 mse_top=0.006932\n",
            "step 22450: mse=0.003214 mse_top=0.006353\n",
            "step 22500: mse=0.003279 mse_top=0.006723\n",
            "step 22550: mse=0.003101 mse_top=0.005954\n",
            "step 22600: mse=0.003418 mse_top=0.006984\n",
            "step 22650: mse=0.002653 mse_top=0.005824\n",
            "step 22700: mse=0.003209 mse_top=0.006453\n",
            "step 22750: mse=0.003261 mse_top=0.007170\n",
            "step 22800: mse=0.003071 mse_top=0.006126\n",
            "step 22850: mse=0.003492 mse_top=0.007643\n",
            "step 22900: mse=0.003164 mse_top=0.006558\n",
            "step 22950: mse=0.003191 mse_top=0.007032\n",
            "step 23000: mse=0.003615 mse_top=0.007180\n",
            "step 23050: mse=0.003255 mse_top=0.007286\n",
            "step 23100: mse=0.003257 mse_top=0.006636\n",
            "step 23150: mse=0.003109 mse_top=0.006272\n",
            "step 23200: mse=0.003197 mse_top=0.006258\n",
            "step 23250: mse=0.003434 mse_top=0.007190\n",
            "step 23300: mse=0.003249 mse_top=0.006874\n",
            "step 23350: mse=0.003159 mse_top=0.006639\n",
            "step 23400: mse=0.003716 mse_top=0.008071\n",
            "step 23450: mse=0.003002 mse_top=0.006496\n",
            "step 23500: mse=0.003615 mse_top=0.007520\n",
            "step 23550: mse=0.003534 mse_top=0.007528\n",
            "step 23600: mse=0.003267 mse_top=0.006953\n",
            "step 23650: mse=0.003581 mse_top=0.007509\n",
            "step 23700: mse=0.003247 mse_top=0.007000\n",
            "step 23750: mse=0.003675 mse_top=0.007904\n",
            "step 23800: mse=0.003385 mse_top=0.006969\n",
            "step 23850: mse=0.003878 mse_top=0.008192\n",
            "step 23900: mse=0.003755 mse_top=0.007770\n",
            "step 23950: mse=0.003475 mse_top=0.007204\n",
            "step 24000: mse=0.003363 mse_top=0.007305\n",
            "step 24050: mse=0.003183 mse_top=0.006605\n",
            "step 24100: mse=0.003205 mse_top=0.007063\n",
            "step 24150: mse=0.003387 mse_top=0.006618\n",
            "step 24200: mse=0.003437 mse_top=0.007304\n",
            "step 24250: mse=0.002886 mse_top=0.005957\n",
            "step 24300: mse=0.003302 mse_top=0.007222\n",
            "step 24350: mse=0.003132 mse_top=0.006406\n",
            "step 24400: mse=0.002929 mse_top=0.005795\n",
            "step 24450: mse=0.003448 mse_top=0.007367\n",
            "step 24500: mse=0.002862 mse_top=0.006128\n",
            "step 24550: mse=0.003159 mse_top=0.006290\n",
            "step 24600: mse=0.003308 mse_top=0.007537\n",
            "step 24650: mse=0.003141 mse_top=0.006409\n",
            "step 24700: mse=0.003080 mse_top=0.006376\n",
            "step 24750: mse=0.003366 mse_top=0.007238\n",
            "step 24800: mse=0.003383 mse_top=0.007089\n",
            "step 24850: mse=0.003328 mse_top=0.007186\n",
            "step 24900: mse=0.003173 mse_top=0.006316\n",
            "step 24950: mse=0.003310 mse_top=0.007425\n",
            "step 25000: mse=0.003387 mse_top=0.007923\n",
            "step 25050: mse=0.003526 mse_top=0.007195\n",
            "step 25100: mse=0.003040 mse_top=0.005989\n",
            "step 25150: mse=0.003468 mse_top=0.007353\n",
            "step 25200: mse=0.003217 mse_top=0.006848\n",
            "step 25250: mse=0.003242 mse_top=0.006784\n",
            "step 25300: mse=0.003038 mse_top=0.006178\n",
            "step 25350: mse=0.002894 mse_top=0.006319\n",
            "step 25400: mse=0.003161 mse_top=0.006622\n",
            "step 25450: mse=0.003659 mse_top=0.007213\n",
            "step 25500: mse=0.003068 mse_top=0.006651\n",
            "step 25550: mse=0.003658 mse_top=0.007906\n",
            "step 25600: mse=0.003603 mse_top=0.007439\n",
            "step 25650: mse=0.003311 mse_top=0.006858\n",
            "step 25700: mse=0.003104 mse_top=0.006369\n",
            "step 25750: mse=0.003618 mse_top=0.007251\n",
            "step 25800: mse=0.003513 mse_top=0.007247\n",
            "step 25850: mse=0.003285 mse_top=0.006987\n",
            "step 25900: mse=0.003430 mse_top=0.006876\n",
            "step 25950: mse=0.003643 mse_top=0.007864\n",
            "step 26000: mse=0.003236 mse_top=0.006903\n",
            "step 26050: mse=0.003445 mse_top=0.007126\n",
            "step 26100: mse=0.003243 mse_top=0.006914\n",
            "step 26150: mse=0.003166 mse_top=0.006390\n",
            "step 26200: mse=0.003435 mse_top=0.007368\n",
            "step 26250: mse=0.003223 mse_top=0.006835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2f856240b70a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns_thermal\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_reconstructions_thermal.png'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Nawid - Changes the valeus back to 255 and integers and save the reconstructions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-2f856240b70a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmissing_modality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Thermal\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx_thermal_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissing_modality_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_thermal_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdefect\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Nawid - Input the specific defect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mterms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_rgb_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_thermal_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_thermal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mmissing_modality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx_rgb_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissing_modality_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_rgb_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdefect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/My Drive/vq-vae-2-master-Single_representation_V4/vq_vae_2/vq_vae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, inputs_thermal, target_rgb, target_thermal, commitment)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Nawid- The target is the encoding one ahead of the current target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                         \u001b[0mrecon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m                         \u001b[0mreconstructions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                         \u001b[0mreconstructions_thermal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/My Drive/vq-vae-2-master-Single_representation_V4/vq_vae_2/vq_vae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidual1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidual2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt4XakmprLAC",
        "colab_type": "text"
      },
      "source": [
        "# Saving the zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhrDzcaEnYtv",
        "colab_type": "code",
        "outputId": "f793bf7a-c9b6-408e-df5e-9f937c735e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Nawid- This allows me to write comments into the file\n",
        "f= open(path +'/'+\"info.txt\",\"w+\")\n",
        "comments = input(\"Learning rate, pretrained or not etc: \") # Nawid - Enables me to input information\n",
        "f.write(comments)\n",
        "f.close()\n",
        "\n",
        "full_path = path + \".zip\"\n",
        "!zip -r $full_path /content/$path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate, pretrained or not etc: Initial learning rate was 1e-4 but it changed to 1e-3 after 100 iterations. pretrained and it trained on missing thermal and then missing rgb - Data did look like overfitting was occuring\n",
            "  adding: content/Data_08012020_10:48:31/ (stored 0%)\n",
            "  adding: content/Data_08012020_10:48:31/Train_reconstructions_rgb.png (deflated 0%)\n",
            "  adding: content/Data_08012020_10:48:31/info.txt (deflated 31%)\n",
            "  adding: content/Data_08012020_10:48:31/vae.pt (deflated 7%)\n",
            "  adding: content/Data_08012020_10:48:31/Val_reconstructions_thermal.png (deflated 0%)\n",
            "  adding: content/Data_08012020_10:48:31/Train_reconstructions_thermal.png (deflated 0%)\n",
            "  adding: content/Data_08012020_10:48:31/Val_reconstructions_rgb.png (deflated 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUJZKVyWvvWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/\" + path+\".zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcQ9l8ylWKWZ",
        "colab_type": "text"
      },
      "source": [
        "# Delete directory if need to retest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4U0Pwk9WOY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "shutil.rmtree(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YPCJUNlTul7E"
      },
      "source": [
        "# Original code - For when the images of the thermal and the RGB data was different"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C69DYwuhhCur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r  file.zip /content/Data_06012020_10:48:28\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9K14q_tjld1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r Data_06012020_10:48:28.zip /content/Data_06012020_10:48:28\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/Data_06012020_10:48:28.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4R-754PW9mu",
        "colab_type": "code",
        "outputId": "b3182d07-2527-4e3b-f4f8-7ca980c546a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "import os\n",
        "path = 'Data_folder'\n",
        "os.mkdir(path)\n",
        "'''\n",
        "import os\n",
        "from datetime import datetime\n",
        "# datetime object containing current date and time\n",
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%d%m%Y_%H:%M:%S\")\n",
        "path = 'Data_folder_'\n",
        "os.mkdir(path+dt_string)\n",
        "'''\n",
        "print(\"now =\", now)\n",
        "# dd/mm/YY H:M:S\n",
        "\n",
        "print(\"date and time =\", dt_string)\t\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(\"now =\", now)\\n# dd/mm/YY H:M:S\\n\\nprint(\"date and time =\", dt_string)\\t\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAOZ3-nTYZXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "  model = make_vae()\n",
        "  if os.path.exists(VAE_PATH):\n",
        "    model.load_state_dict(torch.load(VAE_PATH, map_location='cpu'))\n",
        "  model.to(device)\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  \n",
        "  # Nawid -Define the iterators for the validation data\n",
        "\n",
        "  i = 0\n",
        "  val_loader = InfiniteDataLoader(x_rgb,x)\n",
        "  val_iterator = iter(val_loader) \n",
        "\n",
        "  \n",
        "\n",
        "  for x_rgb_batch, x_thermal_batch in rgb_thermal_load_images(x_rgb,x):\n",
        "    x_rgb_batch = x_rgb_batch.to(device)\n",
        "    x_thermal_batch = x_thermal_batch.to(device)\n",
        "    terms = model(x_rgb_batch, x_thermal_batch)\n",
        "    \n",
        "    if rapid_evaluation:\n",
        "      print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    else:\n",
        "      if not i % eval_counter:\n",
        "        print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    \n",
        "    optimizer.zero_grad() #Nawid - I think this makes the gradient become zero\n",
        "    terms['loss'].backward() # Nawid - Backpropagates the total loss term ( which is related to all the different components)\n",
        "    optimizer.step() # Nawid- Updates using optimizer\n",
        "    model.revive_dead_entries()\n",
        "    i +=1\n",
        "    \n",
        "    if not i % 50:\n",
        "      torch.save(model.state_dict(), VAE_PATH)\n",
        "      #save_reconstructions(x_rgb_batch, terms['reconstructions'][-1], x_thermal_batch,terms['reconstructions_thermal'][-1])\n",
        "      save_reconstructions(model,x_rgb_batch, x_thermal_batch) # Nawid - saves the reconstruction\n",
        "\n",
        "      val_rgb_batch,val_thermal_batch = next(val_iterator)\n",
        "      \n",
        "      if save_data:\n",
        "        val_total_loss, val_reconstruction_loss = validation_loss(model,val_rgb_batch,val_thermal_batch)\n",
        "        tensorboard_saving(i,terms['losses'][-1],val_reconstruction_loss, terms['loss'],val_total_loss)\n",
        "      else:\n",
        "        pass\n",
        "      save_reconstructions(model,val_rgb_batch, val_thermal_batch,'Val')\n",
        "\n",
        "\n",
        "def tensorboard_saving(iteration,recon_loss_train, recon_loss_val, total_loss_train,total_loss_val):\n",
        "  tb.save_value('Reconstruction_loss','Train loss', iteration, recon_loss_train)\n",
        "  tb.save_value('Reconstruction_loss','Validation loss', iteration, recon_loss_val)\n",
        "      \n",
        "  tb.save_value('Total_loss','Train loss', iteration, total_loss_train)\n",
        "  tb.save_value('Total_loss','Validation loss', iteration, total_loss_val)\n",
        " \n",
        "  tb.flush_line('Reconstruction_loss')\n",
        "  tb.flush_line('Total_loss')\n",
        "\n",
        "\n",
        "def validation_loss(vae,val_rgb, val_thermal):\n",
        "  vae.eval() # Nawid - Sets it into evaluation mode ( so dropout and batchnorm have different behaviours)\n",
        "  with torch.no_grad(): # Nawid-  Turns off the autograd engine which speeds up computation\n",
        "    val_terms = vae(val_rgb,val_thermal)\n",
        "    total_loss, reconstruction_loss = val_terms['loss'], val_terms['losses'][-1]\n",
        "    vae.train()\n",
        "    return total_loss, reconstruction_loss\n",
        "\n",
        "\n",
        "def save_reconstructions(vae,rgb_images, thermal_images,name = 'Train'):\n",
        "  vae.eval()\n",
        "  with torch.no_grad():\n",
        "    recons, recons_thermal = vae.full_reconstructions(rgb_images,thermal_images)\n",
        "    recons = [torch.clamp(x, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x in recons] # Nawid - Clamps all the different elements in recons\n",
        "    recons_thermal = [torch.clamp(x_thermal, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x_thermal in recons_thermal] # Nawid - Clamps all the different elements in recons_thermal\n",
        "    \n",
        "    vae.train() # Nawid - This sets the nn.module into training mode\n",
        "    top_recons, real_recons = recons # Nawid - I believe the top_recons is the reconstruction using only the top latent map, whilst real_recons is using both the top latent map and the bottom latent map\n",
        "    rgb_images = rgb_images.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "    columns = np.concatenate([top_recons, real_recons, rgb_images], axis=-2)\n",
        "    columns = np.concatenate(columns, axis=0)\n",
        "    Image.fromarray((columns * 255).astype('uint8')).save(name +'_reconstructions_rgb.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "    top_recons_thermal,real_recons_thermal = recons_thermal\n",
        "    thermal_images = thermal_images.permute(0,2,3,1).detach().cpu().numpy()\n",
        "    thermal_images = thermal_images.reshape(thermal_images.shape[0],thermal_images.shape[1],thermal_images.shape[2])\n",
        "\n",
        "    top_recons_thermal = top_recons_thermal.reshape(top_recons_thermal.shape[0],top_recons_thermal.shape[1],top_recons_thermal.shape[2])\n",
        "    real_recons_thermal = real_recons_thermal.reshape(real_recons_thermal.shape[0],real_recons_thermal.shape[1],real_recons_thermal.shape[2])\n",
        "\n",
        "    columns_thermal = np.concatenate([top_recons_thermal, real_recons_thermal,thermal_images], axis=-1) # Nawid - I need to concatenate along -2 when using rgb and -1 when using grayscale and when using  When using grayscale images, to save the files using PIL, i need to make to remove the channel and so there is one less axis to examine\n",
        "    columns_thermal = np.concatenate(columns_thermal, axis=0)\n",
        "    Image.fromarray((columns_thermal * 255).astype('uint8')).save(name +'_reconstructions_thermal.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s6ivYJFBuj7S",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "  model = make_vae()\n",
        "  if os.path.exists(VAE_PATH):\n",
        "    model.load_state_dict(torch.load(VAE_PATH, map_location='cpu'))\n",
        "  model.to(device)\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  \n",
        "  # Nawid -Define the iterators for the validation data\n",
        "  val_rgb_loader = InfiniteDataLoader(val_x_rgb)\n",
        "  val_rgb_iterator = iter(val_rgb_loader)\n",
        "\n",
        "  val_thermal_loader = InfiniteDataLoader(val_x)\n",
        "  val_thermal_iterator = iter(val_thermal_loader)\n",
        "\n",
        "  i = 0\n",
        "  for x_rgb_batch, x_thermal_batch in zip(load_images(x_rgb), load_images(x)):\n",
        "    x_rgb_batch= x_rgb_batch.to(device)\n",
        "    x_thermal_batch =  x_thermal_batch.to(device)\n",
        "    terms = model(x_rgb_batch, x_thermal_batch)\n",
        "    \n",
        "    if rapid_evaluation:\n",
        "      print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    else:\n",
        "      if not i % eval_counter:\n",
        "        print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    \n",
        "    optimizer.zero_grad() #Nawid - I think this makes the gradient become zero\n",
        "    terms['loss'].backward() # Nawid - Backpropagates the total loss term ( which is related to all the different components)\n",
        "    optimizer.step() # Nawid- Updates using optimizer\n",
        "    model.revive_dead_entries()\n",
        "    i +=1\n",
        "    if not i % 50:\n",
        "      torch.save(model.state_dict(), VAE_PATH)\n",
        "      #save_reconstructions(x_rgb_batch, terms['reconstructions'][-1], x_thermal_batch,terms['reconstructions_thermal'][-1])\n",
        "      save_reconstructions(model,x_rgb_batch, x_thermal_batch) # Nawid - saves the reconstruction\n",
        "\n",
        "      val_rgb_batch = next(val_rgb_iterator)\n",
        "      val_thermal_batch = next(val_thermal_iterator)\n",
        "      val_total_loss, val_reconstruction_loss = validation_loss(model,val_rgb_batch,val_thermal_batch)\n",
        "      \n",
        "      tensorboard_saving(i,terms['losses'][-1],val_reconstruction_loss, terms['loss'],val_total_loss)\n",
        "      save_reconstructions(model,val_rgb_batch, val_thermal_batch,'Val')\n",
        "\n",
        "      '''\n",
        "      tb.save_value('Reconstruction_loss','Train loss', i, terms['losses'][-1])\n",
        "      tb.save_value('Reconstruction_loss','Validation loss', i, val_reconstruction_loss)\n",
        "      \n",
        "      tb.save_value('Total_loss','Train loss', i, terms['loss'])\n",
        "      tb.save_value('Total_loss','Validation loss', i, val_total_loss)\n",
        "      tb.flush_line('Reconstruction_loss')\n",
        "      tb.flush_line('Total_loss')\n",
        "      '''\n",
        "      \n",
        "\n",
        "def tensorboard_saving(iteration,recon_loss_train, recon_loss_val, total_loss_train,total_loss_val):\n",
        "  tb.save_value('Reconstruction_loss','Train loss', iteration, recon_loss_train)\n",
        "  tb.save_value('Reconstruction_loss','Validation loss', iteration, recon_loss_val)\n",
        "      \n",
        "  tb.save_value('Total_loss','Train loss', iteration, total_loss_train)\n",
        "  tb.save_value('Total_loss','Validation loss', iteration, total_loss_val)\n",
        " \n",
        "  tb.flush_line('Reconstruction_loss')\n",
        "  tb.flush_line('Total_loss')\n",
        "\n",
        "\n",
        "def validation_loss(vae,val_rgb, val_thermal):\n",
        "  vae.eval() # Nawid - Sets it into evaluation mode ( so dropout and batchnorm have different behaviours)\n",
        "  with torch.no_grad(): # Nawid-  Turns off the autograd engine which speeds up computation\n",
        "    val_terms = vae(val_rgb,val_thermal)\n",
        "    total_loss, reconstruction_loss = val_terms['loss'], val_terms['losses'][-1]\n",
        "    return total_loss, reconstruction_loss\n",
        "\n",
        "\n",
        "def save_reconstructions(vae,rgb_images, thermal_images,name = 'Train'):\n",
        "  vae.eval()\n",
        "  with torch.no_grad():\n",
        "    recons, recons_thermal = vae.full_reconstructions(rgb_images,thermal_images)\n",
        "    recons = [torch.clamp(x, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x in recons] # Nawid - Clamps all the different elements in recons\n",
        "    recons_thermal = [torch.clamp(x_thermal, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x_thermal in recons_thermal] # Nawid - Clamps all the different elements in recons_thermal\n",
        "    \n",
        "    vae.train() # Nawid - This sets the nn.module into training mode\n",
        "    top_recons, real_recons = recons # Nawid - I believe the top_recons is the reconstruction using only the top latent map, whilst real_recons is using both the top latent map and the bottom latent map\n",
        "    rgb_images = rgb_images.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "    columns = np.concatenate([top_recons, real_recons, rgb_images], axis=-2)\n",
        "    columns = np.concatenate(columns, axis=0)\n",
        "    Image.fromarray((columns * 255).astype('uint8')).save(name +'_reconstructions_rgb.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "    top_recons_thermal,real_recons_thermal = recons_thermal\n",
        "    thermal_images = thermal_images.permute(0,2,3,1).detach().cpu().numpy()\n",
        "    thermal_images = thermal_images.reshape(thermal_images.shape[0],thermal_images.shape[1],thermal_images.shape[2])\n",
        "\n",
        "    top_recons_thermal = top_recons_thermal.reshape(top_recons_thermal.shape[0],top_recons_thermal.shape[1],top_recons_thermal.shape[2])\n",
        "    real_recons_thermal = real_recons_thermal.reshape(real_recons_thermal.shape[0],real_recons_thermal.shape[1],real_recons_thermal.shape[2])\n",
        "\n",
        "    columns_thermal = np.concatenate([top_recons_thermal, real_recons_thermal,thermal_images], axis=-1) # Nawid - I need to concatenate along -2 when using rgb and -1 when using grayscale and when using  When using grayscale images, to save the files using PIL, i need to make to remove the channel and so there is one less axis to examine\n",
        "    columns_thermal = np.concatenate(columns_thermal, axis=0)\n",
        "    Image.fromarray((columns_thermal * 255).astype('uint8')).save(name +'_reconstructions_thermal.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z8n9DfbZujVk",
        "colab": {}
      },
      "source": [
        "def load_images(input_x): # Nawid - Loads images\n",
        "    while True:\n",
        "        for data in create_data_loader(input_x):\n",
        "          #data = data.float()/255 # Nawid - Divides by 255 \n",
        "          data = data.permute(0, 3, 1, 2).contiguous() # Nawid - Changes into pytorch ordering\n",
        "          yield data\n",
        "       \n",
        "def create_data_loader(input_x): # Nawid - Creates a dataloader object\n",
        "    return torch.utils.data.DataLoader(input_x, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# https://gist.github.com/MFreidank/821cc87b012c53fade03b0c7aba13958\n",
        "class InfiniteDataLoader(DataLoader): \n",
        "  def __init__(self,input_x, batch_size=BATCH_SIZE, shuffle=True):\n",
        "    super().__init__(input_x, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    #Initialise an iterator over the dataset\n",
        "    self.dataset_iterator = super().__iter__()\n",
        "\n",
        "  def __iter__(self):\n",
        "    return self\n",
        "\n",
        "  def __next__(self):\n",
        "    try:\n",
        "      batch = next(self.dataset_iterator)\n",
        "\n",
        "    except StopIteration:\n",
        "      # Dataset exhausted, use a new fresh iterator\n",
        "      self.dataset_iterator = super().__iter__()\n",
        "      batch = next(self.dataset_iterator)\n",
        "    batch = batch.permute(0, 3, 1, 2).contiguous() # Nawid- Added this to change the channels\n",
        "    return batch.to(device) # Nawid - Add to the device directly\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga5XUpRnQn5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rgb_thermal_load_images_patch(input_rgb, input_thermal): # Nawid - Loads images\n",
        "    while True:\n",
        "        for (rgb_data,thermal_data) in rgb_thermal_data_loader(input_rgb,input_thermal):\n",
        "          #data = data.float()/255 # Nawid - Divides by 255 \n",
        "          rgb_data = rgb_data.permute(0, 3, 1, 2).contiguous() # Nawid - Changes into pytorch ordering\n",
        "          rgb_data[:,:,target_size[0]//2:target_size[0]//2 + 10, target_size[1]//2: target_size[1]//2 + 10] = 1\n",
        "          #rgb_data[0,0,0:64,0:64] = 1\n",
        "          print(rgb_data[0,0])\n",
        "#          print(rgb_data[0,0,0:10,0:10])\n",
        "          thermal_data = thermal_data.permute(0, 3, 1, 2).contiguous()\n",
        "          yield rgb_data, thermal_data\n",
        "\n",
        "x_rgb_patch = x_rgb[0:100]\n",
        "x_thermal_patch = x[0:100]\n",
        "\n",
        "target_size[0]//2\n",
        "target_size[1]//2 \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def missing_modality_patch(modal_input): # Nawid - Modal output related to changing a single patch of the image \n",
        "  target = modal_input\n",
        "  modal_input.new_full((modal_input.size()),-1)\n",
        "  #modal_input[:,:,:,:] = -1\n",
        "  #modal_input[:,:,target_size[0]//2:target_size[0]//2 + 10, target_size[1]//2: target_size[1]//2 + 10] = -1\n",
        "  return modal_input, target\n",
        "\n",
        "single_data_point = x_rgb[0:2]\n",
        "missing_patch, target = missing_modality_patch(single_data_point)\n",
        "print(missing_patch)\n",
        "\n",
        "'''\n",
        "height_start = random.randint(0, target_size[0])\n",
        "height_end = random.randint(height_start, target_size[0]) \n",
        "width_start = random.randint(0,target_size[1])\n",
        "width_end = random.randint(width_start, target_size[1])\n",
        "print(height_start,height_end)\n",
        "'''\n",
        "\n",
        "'''\n",
        "for x_rgb_batch, x_thermal_batch in rgb_thermal_load_images_patch(x_rgb,x):\n",
        "  x_rgb_batch\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Tv38KYGTjsU",
        "colab": {}
      },
      "source": [
        "#height_list = random.sample(range(1, target_size[0]), 60)\n",
        "#width_list = random.sample(range(1, target_size[0]), 60)\n",
        "\n",
        "height_list = [random.randint(0,target_size[0]-1) for i in range(100)]\n",
        "width_list = [random.randint(0,target_size[0]-1) for i in range(100)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugPokZqvnwYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l_height = [random.randint(0,target_size[0]-1) for i in range(100)]\n",
        "#print(l_height)\n",
        "values = list(range(0, target_size[0]))\n",
        "\n",
        "\n",
        "\n",
        "x = np.load('/content/gdrive/My Drive/Thermal_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "single_data_point = x[0:1]\n",
        "low_value_list = [x for x in single_data_point > 1]\n",
        "print(low_value_list)\n",
        "#for i in single_data_point:\n",
        "   \n",
        "\n",
        "\n",
        "#single_data_point[:,[1,2,3],[0,1,2],:] = -10\n",
        "#print(single_data_point[:,[1,2,3],[2],:])\n",
        "#print(single_data_point[:,0:4,0:4:])\n",
        "\n",
        "\n",
        "#print(single_data_point[:,1,1,:])\n",
        "#print(single_data_point)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkFgOlMnvdKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l_height = [random.randint(0,target_size[0]-1) for i in range(64)]\n",
        "#print(l_height)\n",
        "\n",
        "values = list(range(0, target_size[0]))\n",
        "\n",
        "single_data_point = x_rgb[0:2]\n",
        "\n",
        "single_data_point[:,[1,2,3],[1,1,1],:] = 1\n",
        "\n",
        "print(single_data_point[:,1:3,1:3,:])\n",
        "#print(single_data_point)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}