{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "060120_Hierarchical_Joint_modality_single_representation_V5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nerdk312/Multimodal_VQ-VAE/blob/master/060120_Hierarchical_Joint_modality_single_representation_V5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP252uER8Mj4",
        "colab_type": "code",
        "outputId": "240cb71b-02f2-4807-cda0-45124fde7c89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEdPl_3i8i3z",
        "colab_type": "code",
        "outputId": "e8f38fee-048e-45ab-bdec-271c9e5f31d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# Nawid - Updates the path to import from drive\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/vq-vae-2-master-Single_representation_V3')\n",
        "\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "from keras.preprocessing import image as image_utils\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from tensorboardcolab import TensorBoardColab\n",
        "from torch.utils.data import DataLoader\n",
        "import random\n",
        "\n",
        "from vq_vae_2.examples.hierarchical_combined.model import make_vae\n",
        "target_size = (64,64)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R73VF2pBwTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def common_images(RGB_dir,Thermal_dir):\n",
        "  RGB_image_list = os.listdir(RGB_dir)\n",
        "  Thermal_image_list = os.listdir(Thermal_dir)\n",
        "\n",
        "  truncated_RGB_image_list = [RGB_image_name.strip('.jpg') for RGB_image_name in RGB_image_list]\n",
        "  truncated_Thermal_image_list = [Thermal_image_name.strip('.jpeg') for Thermal_image_name in Thermal_image_list]\n",
        "\n",
        "  common_list = set(truncated_RGB_image_list).intersection(truncated_Thermal_image_list)\n",
        "  common_list = sorted(common_list) # Nawid - Sorts all the items in a list\n",
        "  return common_list\n",
        "\n",
        "RGB_inp_dir = '/content/gdrive/My Drive/RGB'\n",
        "Thermal_inp_dir = '/content/gdrive/My Drive/thermal_8_bit'\n",
        "train_list = common_images(RGB_inp_dir,Thermal_inp_dir) \n",
        "\n",
        "val_RGB_inp_dir = '/content/gdrive/My Drive/Val_RGB'\n",
        "val_Thermal_inp_dir = '/content/gdrive/My Drive/Val_thermal_8_bit'\n",
        "val_list = common_images(val_RGB_inp_dir,val_Thermal_inp_dir)\n",
        "\n",
        "def processing_saving_images(modality,quick_test=True,Train_required=False,Val_required=True):\n",
        "  all_images = []\n",
        "  val_all_images = []\n",
        "  \n",
        "  if modality == 'RGB_':\n",
        "    suffix = '.jpg'\n",
        "    channels = 3\n",
        "    inp_dir = '/content/gdrive/My Drive/RGB'\n",
        "    val_inp_dir = '/content/gdrive/My Drive/Val_RGB'\n",
        "  \n",
        "  elif modality == 'Thermal_':\n",
        "    suffix = '.jpeg'\n",
        "    channels = 1\n",
        "    inp_dir = '/content/gdrive/My Drive/thermal_8_bit'\n",
        "    val_inp_dir = '/content/gdrive/My Drive/Val_thermal_8_bit'\n",
        "  \n",
        "  else:\n",
        "    return('Incorrect Modality name')\n",
        "\n",
        "  if quick_test:\n",
        "    if Train_required:\n",
        "      for i, img_name in enumerate(train_list):\n",
        "        if i< 10:\n",
        "          fname = inp_dir + '/' + img_name + suffix\n",
        "          if modality == 'RGB_':\n",
        "            image = image_utils.load_img(fname).resize(target_size,Image.ANTIALIAS)\n",
        "          else:\n",
        "            image = image_utils.load_img(fname,color_mode='grayscale').resize(target_size,Image.ANTIALIAS)\n",
        "          image = np.array(image.getdata()).reshape(target_size[0], target_size[1], channels)\n",
        "          image = image.astype('float32')/255 \n",
        "          all_images.append(image)\n",
        "        else:\n",
        "          pass\n",
        "    else:\n",
        "      pass\n",
        "    \n",
        "    if Val_required:\n",
        "      for j, img_name in enumerate(val_list):\n",
        "        if j < 10:\n",
        "          fname = val_inp_dir + '/' + img_name + suffix\n",
        "          if modality == 'RGB_':\n",
        "            image = image_utils.load_img(fname).resize(target_size,Image.ANTIALIAS)\n",
        "          else:\n",
        "            image = image_utils.load_img(fname,color_mode='grayscale').resize(target_size,Image.ANTIALIAS)\n",
        "          \n",
        "          image = np.array(image.getdata()).reshape(target_size[0], target_size[1], channels)\n",
        "          image = image.astype('float32')/255 \n",
        "          val_all_images.append(image)\n",
        "        else: \n",
        "          pass \n",
        "    else:\n",
        "      pass\n",
        "\n",
        "  else:\n",
        "    if Train_required:\n",
        "      for i, img_name in enumerate(train_list):\n",
        "        fname = inp_dir + '/' + img_name + suffix\n",
        "        if modality == 'RGB_':\n",
        "          image = image_utils.load_img(fname).resize(target_size,Image.ANTIALIAS)\n",
        "        else:\n",
        "          image = image_utils.load_img(fname,color_mode='grayscale').resize(target_size,Image.ANTIALIAS)\n",
        "        image = np.array(image.getdata()).reshape(target_size[0], target_size[1],channels)\n",
        "        image = image.astype('float32')/255\n",
        "        all_images.append(image)\n",
        "        if not i%100:\n",
        "          print(i)\n",
        "        else: \n",
        "          pass\n",
        "    else:\n",
        "      pass\n",
        "  \n",
        "    if Val_required:\n",
        "      for j, img_name in enumerate(val_list):\n",
        "        fname = val_inp_dir + '/' + img_name + suffix\n",
        "        if modality == 'RGB_':\n",
        "          image = image_utils.load_img(fname).resize(target_size,Image.ANTIALIAS)\n",
        "        else:\n",
        "          image = image_utils.load_img(fname,color_mode='grayscale').resize(target_size,Image.ANTIALIAS)\n",
        "        image = np.array(image.getdata()).reshape(target_size[0], target_size[1],channels)\n",
        "        image = image.astype('float32')/255\n",
        "        val_all_images.append(image)\n",
        "        if not j%100:\n",
        "          print(j)\n",
        "        else: \n",
        "          pass\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "  if Train_required: \n",
        "    np.save(modality +str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy',all_images)\n",
        "\n",
        "  if Val_required:\n",
        "    np.save('Val_'+modality +str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy',val_all_images)\n",
        "\n",
        "\n",
        "rgb_modality = 'RGB_'\n",
        "thermal_modality = 'Thermal_'\n",
        "\n",
        "processing_saving_images(thermal_modality,quick_test=False,Train_required=False,Val_required=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsUjLwHf9FP9",
        "colab_type": "text"
      },
      "source": [
        "# Uploading from drive directly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kkaWdar9Ib-",
        "colab_type": "code",
        "outputId": "b19961a2-2aa8-4bca-a42d-fedb5e8c0a49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "upload_directly = True\n",
        "if upload_directly:\n",
        "  x_rgb = np.load('/content/gdrive/My Drive/RGB_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  val_x_rgb = np.load('/content/gdrive/My Drive/Val_RGB_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  x = np.load('/content/gdrive/My Drive/Thermal_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  val_x = np.load('/content/gdrive/My Drive/Val_Thermal_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "else:\n",
        "  x_rgb = np.load('/content/RGB_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  val_x_rgb = np.load('/content/Val_RGB_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  x = np.load('/content/Thermal_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  val_x = np.load('/content/Val_Thermal_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "\n",
        "#val_x = val_x[:len(val_x_rgb)] # Nawid - Make into the same size as the limiting case\n",
        "print(x_rgb.shape)\n",
        "print(val_x_rgb.shape)\n",
        "print(x.shape)\n",
        "print(val_x.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8363, 64, 64, 3)\n",
            "(1257, 64, 64, 3)\n",
            "(8363, 64, 64, 1)\n",
            "(1257, 64, 64, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yft7Ami9Vbs",
        "colab_type": "text"
      },
      "source": [
        "# Model config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLXuKr8u9WZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "log_interval = 50\n",
        "rapid_evaluation = False\n",
        "eval_counter = 50\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
        "VAE_PATH_SAVE = 'vae.pt'\n",
        "#VAE_PATH = 'vae.pt'\n",
        "VAE_PATH = '/content/gdrive/My Drive/vae_cycle1_training.pt'\n",
        "# Nawid - Used to ensure the results are reproducible - https://pytorch.org/docs/stable/notes/randomness.html\n",
        "\n",
        "reproducible = False\n",
        "seed_value = 0\n",
        "if reproducible:\n",
        "  torch.manual_seed(seed_value)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  np.random.seed(seed_value)\n",
        "\n",
        "missing_threshold = 0.3\n",
        "\n",
        "save_data = False\n",
        "if save_data:\n",
        "  tb = TensorBoardColab() # Nawid - Creates a tensorboard link "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4333NUk15zou",
        "colab_type": "text"
      },
      "source": [
        "# Data loader functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsMoW1pHROZN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2f3e279f-97ad-4630-8949-0bfc6d049534"
      },
      "source": [
        "class ConcatDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, *datasets):\n",
        "        self.datasets = datasets\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return tuple(d[i] for d in self.datasets)\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(d) for d in self.datasets)\n",
        "\n",
        "def rgb_thermal_data_loader(input_rgb,input_thermal): # Nawid - Creates a dataloader object\n",
        "    return torch.utils.data.DataLoader(ConcatDataset(input_rgb,input_thermal),batch_size=BATCH_SIZE, shuffle = True)\n",
        "\n",
        "def rgb_thermal_load_images(input_rgb, input_thermal, Missing = False): # Nawid - Loads images\n",
        "    while True:\n",
        "        for (rgb_data,thermal_data) in rgb_thermal_data_loader(input_rgb,input_thermal):\n",
        "          #data = data.float()/255 # Nawid - Divides by 255 \n",
        "          rgb_data = rgb_data.permute(0, 3, 1, 2).contiguous() # Nawid - Changes into pytorch ordering\n",
        "          thermal_data = thermal_data.permute(0, 3, 1, 2).contiguous()\n",
        "          if Missing:\n",
        "            thermal_target = thermal_data\n",
        "            thermal_data = thermal_data.new_full((thermal_data.size()),-1) # Nawid - Missing thermal data\n",
        "            yield rgb_data, thermal_data, thermal_target # Nawid - outputs the rgb data, thermal data which is missing and the original thermal data(target)\n",
        "          else:\n",
        "            yield rgb_data, thermal_data, 0 # Nawid - Put zero as a placeholder value \n",
        "\n",
        "'''  \n",
        "# https://gist.github.com/MFreidank/821cc87b012c53fade03b0c7aba13958\n",
        "class InfiniteDataLoader(DataLoader): \n",
        "  def __init__(self,input_rgb,input_thermal, batch_size=BATCH_SIZE, shuffle=True):\n",
        "    super().__init__(ConcatDataset(input_rgb,input_thermal), batch_size=BATCH_SIZE, shuffle=True) # Nawid - Instantiates the dataloader subclass using a concatenated input\n",
        "    \n",
        "    #Initialise an iterator over the dataset\n",
        "    self.dataset_iterator = super().__iter__()\n",
        "\n",
        "  def __iter__(self):\n",
        "    return self\n",
        "\n",
        "  def __next__(self):\n",
        "    try:\n",
        "      batch = next(self.dataset_iterator)\n",
        "      \n",
        "    except StopIteration:\n",
        "      # Dataset exhausted, use a new fresh iterator\n",
        "      self.dataset_iterator = super().__iter__()\n",
        "      batch = next(self.dataset_iterator)\n",
        "\n",
        "    rgb_batch, thermal_batch = batch[0], batch[1] # Nawid- Obtains the different values in the batch\n",
        "    rgb_batch = rgb_batch.permute(0, 3, 1, 2).contiguous() # Nawid- Added this to change the channels\n",
        "    thermal_batch = thermal_batch.permute(0, 3, 1, 2).contiguous()\n",
        "    \n",
        "    return rgb_batch.to(device), thermal_batch.to(device)\n",
        "'''"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  \\n# https://gist.github.com/MFreidank/821cc87b012c53fade03b0c7aba13958\\nclass InfiniteDataLoader(DataLoader): \\n  def __init__(self,input_rgb,input_thermal, batch_size=BATCH_SIZE, shuffle=True):\\n    super().__init__(ConcatDataset(input_rgb,input_thermal), batch_size=BATCH_SIZE, shuffle=True) # Nawid - Instantiates the dataloader subclass using a concatenated input\\n    \\n    #Initialise an iterator over the dataset\\n    self.dataset_iterator = super().__iter__()\\n\\n  def __iter__(self):\\n    return self\\n\\n  def __next__(self):\\n    try:\\n      batch = next(self.dataset_iterator)\\n      \\n    except StopIteration:\\n      # Dataset exhausted, use a new fresh iterator\\n      self.dataset_iterator = super().__iter__()\\n      batch = next(self.dataset_iterator)\\n\\n    rgb_batch, thermal_batch = batch[0], batch[1] # Nawid- Obtains the different values in the batch\\n    rgb_batch = rgb_batch.permute(0, 3, 1, 2).contiguous() # Nawid- Added this to change the channels\\n    thermal_batch = thermal_batch.permute(0, 3, 1, 2).contiguous()\\n    \\n    return rgb_batch.to(device), thermal_batch.to(device)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bETeoMfQizDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://gist.github.com/MFreidank/821cc87b012c53fade03b0c7aba13958\n",
        "class InfiniteDataLoader(DataLoader): \n",
        "  def __init__(self,input_rgb,input_thermal, batch_size=BATCH_SIZE, shuffle=True):\n",
        "    super().__init__(ConcatDataset(input_rgb,input_thermal), batch_size=BATCH_SIZE, shuffle=True) # Nawid - Instantiates the dataloader subclass using a concatenated input\n",
        "\n",
        "    #Initialise an iterator over the dataset\n",
        "    self.dataset_iterator = super().__iter__()\n",
        "\n",
        "  def __iter__(self):\n",
        "    return self\n",
        "\n",
        "  def __next__(self,Missing= False): # Nawid - Added the Missing term here\n",
        "    try:\n",
        "      batch = next(self.dataset_iterator)\n",
        "      \n",
        "    except StopIteration:\n",
        "      # Dataset exhausted, use a new fresh iterator\n",
        "      self.dataset_iterator = super().__iter__()\n",
        "      batch = next(self.dataset_iterator)\n",
        "\n",
        "    rgb_batch, thermal_batch = batch[0], batch[1] # Nawid- Obtains the different values in the batch\n",
        "    rgb_batch = rgb_batch.permute(0, 3, 1, 2).contiguous() # Nawid- Added this to change the channels\n",
        "    thermal_batch = thermal_batch.permute(0, 3, 1, 2).contiguous()\n",
        "    \n",
        "    if Missing:  \n",
        "      thermal_target = thermal_batch\n",
        "      thermal_batch = thermal_batch.new_full((thermal_batch.size()),-1) # Nawid - Missing thermal data\n",
        "      return rgb_batch.to(device), thermal_batch.to(device), thermal_target.to(device) # Nawid - outputs the rgb data, thermal data which is missing and the original thermal data(target)\n",
        "    else:\n",
        "      return rgb_batch.to(device), thermal_batch.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDpfwkbJ6L04",
        "colab_type": "text"
      },
      "source": [
        "# Main - Training and reconstructions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUEtUcYSIwpK",
        "colab_type": "code",
        "outputId": "121e67a6-3169-4968-9312-ccce7164745b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def main():\n",
        "  model = make_vae()\n",
        "  if os.path.exists(VAE_PATH):\n",
        "    model.load_state_dict(torch.load(VAE_PATH, map_location='cpu'))\n",
        "  model.to(device)\n",
        "  optimizer = optim.Adam(model.parameters()) \n",
        "  \n",
        "  # Nawid - Validation iterator\n",
        "  val_loader = InfiniteDataLoader(x_rgb,x)\n",
        "  val_iterator = iter(val_loader) \n",
        "\n",
        "  # Nawid - Initial condition for the iterator\n",
        "  missing = True # Nawid - Initially set to true\n",
        "  missing_threshold = 0.0\n",
        "\n",
        "  i = 0\n",
        "  for x_rgb_batch, x_thermal_batch, x_thermal_target in rgb_thermal_load_images(x_rgb,x,missing): # Nawid - Obtains the minibatch and the thermal target for the case when the modality is missing\n",
        "    x_rgb_batch = x_rgb_batch.to(device)\n",
        "    x_thermal_batch = x_thermal_batch.to(device)\n",
        "    if missing: # Nawid - If missing, then need to input the missing modality as well as the target value\n",
        "      x_thermal_target = x_thermal_target.to(device)\n",
        "      terms = model(x_rgb_batch, x_thermal_batch,x_thermal_target)\n",
        "    else: # Nawid - If the modality is not missing, then only need to input the rgb and thermal images\n",
        "      terms = model(x_rgb_batch, x_thermal_batch)\n",
        "\n",
        "    # Nawid -Sets the value for missing for the next iteration by checking if the random value is above a certain threshold\n",
        "    random_value = random.random()\n",
        "    if random_value > missing_threshold:\n",
        "      missing = True\n",
        "    else:\n",
        "      missing = False\n",
        "    \n",
        "    if rapid_evaluation:\n",
        "      print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    else:\n",
        "      if not i % eval_counter:\n",
        "        print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    \n",
        "    optimizer.zero_grad() #Nawid - I think this makes the gradient become zero\n",
        "    terms['loss'].backward() # Nawid - Backpropagates the total loss term ( which is related to all the different components)\n",
        "    optimizer.step() # Nawid- Updates using optimizer\n",
        "    model.revive_dead_entries()\n",
        "    i +=1\n",
        "    \n",
        "    if not i % 50:\n",
        "      torch.save(model.state_dict(), VAE_PATH_SAVE)\n",
        "      #save_reconstructions(x_rgb_batch, terms['reconstructions'][-1], x_thermal_batch,terms['reconstructions_thermal'][-1])\n",
        "      if missing: # Nawid-  Saves the reconstruction when there is or isn't a modality change.\n",
        "        save_reconstructions(model,x_rgb_batch, x_thermal_batch,x_thermal_target) # Nawid - saves the reconstruction\n",
        "        #val_rgb_batch,val_thermal_batch, val_thermal_target = next(val_iterator,Missing=missing) \n",
        "        val_rgb_batch, val_thermal_batch, val_thermal_target = val_iterator.__next__(missing) # Nawid - Need to call the method like this rather than using the other method\n",
        "        save_reconstructions(model,val_rgb_batch, val_thermal_batch,val_thermal_target, name = 'Val') # Nawid -  Reconstruction for the validation set.\n",
        "      else:\n",
        "        save_reconstructions(model,x_rgb_batch, x_thermal_batch)\n",
        "        #val_rgb_batch,val_thermal_batch = next(val_iterator)\n",
        "        val_rgb_batch, val_thermal_batch = val_iterator.__next__(missing)\n",
        "\n",
        "        val_total_loss, val_reconstruction_loss = validation_loss(model,val_rgb_batch,val_thermal_batch) # Nawid - Calculates the loss in the validation set\n",
        "        '''\n",
        "        # Nawid - Updates model only if the validation loss is less\n",
        "        if val_total_loss < minimum_val_total_loss:\n",
        "          previous_val_total_loss = val_total_loss\n",
        "          torch.save(model.state_dict(), VAE_PATH_SAVE)\n",
        "        '''\n",
        "\n",
        "        save_reconstructions(model,val_rgb_batch, val_thermal_batch, name = 'Val') # Nawid - Need to specify as name as otherwise it would specify target thermal\n",
        "        \n",
        "      '''\n",
        "      val_rgb_batch,val_thermal_batch = next(val_iterator)      \n",
        "      if save_data:\n",
        "        val_total_loss, val_reconstruction_loss = validation_loss(model,val_rgb_batch,val_thermal_batch)\n",
        "        tensorboard_saving(i,terms['losses'][-1],val_reconstruction_loss, terms['loss'],val_total_loss)\n",
        "      else:\n",
        "        pass\n",
        "      save_reconstructions(model,val_rgb_batch, val_thermal_batch,'Val')\n",
        "      '''\n",
        "\n",
        "def tensorboard_saving(iteration,recon_loss_train, recon_loss_val, total_loss_train,total_loss_val):\n",
        "  tb.save_value('Reconstruction_loss','Train loss', iteration, recon_loss_train)\n",
        "  tb.save_value('Reconstruction_loss','Validation loss', iteration, recon_loss_val)\n",
        "      \n",
        "  tb.save_value('Total_loss','Train loss', iteration, total_loss_train)\n",
        "  tb.save_value('Total_loss','Validation loss', iteration, total_loss_val)\n",
        " \n",
        "  tb.flush_line('Reconstruction_loss')\n",
        "  tb.flush_line('Total_loss')\n",
        "\n",
        "def validation_loss(vae,val_rgb, val_thermal):\n",
        "  vae.eval() # Nawid - Sets it into evaluation mode ( so dropout and batchnorm have different behaviours)\n",
        "  with torch.no_grad(): # Nawid-  Turns off the autograd engine which speeds up computation\n",
        "    val_terms = vae(val_rgb,val_thermal)\n",
        "    total_loss, reconstruction_loss = val_terms['loss'], val_terms['losses'][-1]\n",
        "    vae.train()\n",
        "    return total_loss, reconstruction_loss\n",
        "\n",
        "def save_reconstructions(vae,rgb_images,thermal_images,target_thermal = None, name = 'Train'):\n",
        "  vae.eval()\n",
        "  with torch.no_grad():\n",
        "    recons, recons_thermal = vae.full_reconstructions(rgb_images,thermal_images)\n",
        "    recons = [torch.clamp(x, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x in recons] # Nawid - Clamps all the different elements in recons\n",
        "    recons_thermal = [torch.clamp(x_thermal, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x_thermal in recons_thermal] # Nawid - Clamps all the different elements in recons_thermal\n",
        "    \n",
        "    vae.train() # Nawid - This sets the nn.module into training mode\n",
        "    top_recons, real_recons = recons # Nawid - I believe the top_recons is the reconstruction using only the top latent map, whilst real_recons is using both the top latent map and the bottom latent map\n",
        "    rgb_images = rgb_images.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "    columns = np.concatenate([top_recons, real_recons, rgb_images], axis=-2)\n",
        "    columns = np.concatenate(columns, axis=0)\n",
        "    Image.fromarray((columns * 255).astype('uint8')).save(name +'_reconstructions_rgb.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "    top_recons_thermal,real_recons_thermal = recons_thermal\n",
        "    \n",
        "    target_thermal = thermal_images if target_thermal is None else target_thermal # Nawid- Sets the value for target_thermal to input_thermal if target_thermal is none. else it is the value that I input\n",
        "    target_thermal = target_thermal.permute(0,2,3,1).detach().cpu().numpy()\n",
        "    target_thermal = target_thermal.reshape(target_thermal.shape[0],target_thermal.shape[1],target_thermal.shape[2])\n",
        "    \n",
        "    #thermal_images = thermal_images.permute(0,2,3,1).detach().cpu().numpy()\n",
        "    #thermal_images = thermal_images.reshape(thermal_images.shape[0],thermal_images.shape[1],thermal_images.shape[2])\n",
        "    #target_thermal = thermal_images if target_thermal is None else target_thermal # Nawid- Sets the value for target_thermal to input_thermal if target_thermal is none. else it is the value that I input\n",
        "    \n",
        "    top_recons_thermal = top_recons_thermal.reshape(top_recons_thermal.shape[0],top_recons_thermal.shape[1],top_recons_thermal.shape[2])\n",
        "    real_recons_thermal = real_recons_thermal.reshape(real_recons_thermal.shape[0],real_recons_thermal.shape[1],real_recons_thermal.shape[2])\n",
        "\n",
        "    columns_thermal = np.concatenate([top_recons_thermal, real_recons_thermal,target_thermal], axis=-1) # Nawid - I need to concatenate along -2 when using rgb and -1 when using grayscale and when using  When using grayscale images, to save the files using PIL, i need to make to remove the channel and so there is one less axis to examine\n",
        "    columns_thermal = np.concatenate(columns_thermal, axis=0)\n",
        "    Image.fromarray((columns_thermal * 255).astype('uint8')).save(name +'_reconstructions_thermal.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "main()   "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 8300: mse=0.007644 mse_top=0.002337\n",
            "step 8350: mse=0.007589 mse_top=0.002083\n",
            "step 8400: mse=0.008057 mse_top=0.002024\n",
            "step 8450: mse=0.007289 mse_top=0.002118\n",
            "step 8500: mse=0.007887 mse_top=0.001979\n",
            "step 8550: mse=0.008866 mse_top=0.002307\n",
            "step 8600: mse=0.007814 mse_top=0.002585\n",
            "step 8650: mse=0.007743 mse_top=0.002189\n",
            "step 8700: mse=0.007320 mse_top=0.002203\n",
            "step 8750: mse=0.008055 mse_top=0.002410\n",
            "step 8800: mse=0.007281 mse_top=0.002062\n",
            "step 8850: mse=0.007219 mse_top=0.002163\n",
            "step 8900: mse=0.007293 mse_top=0.002336\n",
            "step 8950: mse=0.007071 mse_top=0.002138\n",
            "step 9000: mse=0.006684 mse_top=0.001809\n",
            "step 9050: mse=0.007723 mse_top=0.002079\n",
            "step 9100: mse=0.006981 mse_top=0.001976\n",
            "step 9150: mse=0.007395 mse_top=0.002162\n",
            "step 9200: mse=0.007567 mse_top=0.002570\n",
            "step 9250: mse=0.008054 mse_top=0.002243\n",
            "step 9300: mse=0.007661 mse_top=0.002131\n",
            "step 9350: mse=0.006852 mse_top=0.002147\n",
            "step 9400: mse=0.007352 mse_top=0.002239\n",
            "step 9450: mse=0.006806 mse_top=0.002000\n",
            "step 9500: mse=0.006061 mse_top=0.002082\n",
            "step 9550: mse=0.006811 mse_top=0.002182\n",
            "step 9600: mse=0.006483 mse_top=0.002395\n",
            "step 9650: mse=0.007739 mse_top=0.002550\n",
            "step 9700: mse=0.007478 mse_top=0.002486\n",
            "step 9750: mse=0.007438 mse_top=0.002319\n",
            "step 9800: mse=0.006339 mse_top=0.002071\n",
            "step 9850: mse=0.007137 mse_top=0.001977\n",
            "step 9900: mse=0.007578 mse_top=0.002322\n",
            "step 9950: mse=0.008269 mse_top=0.002638\n",
            "step 10000: mse=0.007506 mse_top=0.002478\n",
            "step 10050: mse=0.006885 mse_top=0.002653\n",
            "step 10100: mse=0.007089 mse_top=0.002552\n",
            "step 10150: mse=0.008396 mse_top=0.002526\n",
            "step 10200: mse=0.008359 mse_top=0.002213\n",
            "step 10250: mse=0.007259 mse_top=0.002464\n",
            "step 10300: mse=0.006506 mse_top=0.002329\n",
            "step 10350: mse=0.006684 mse_top=0.002689\n",
            "step 10400: mse=0.007024 mse_top=0.002171\n",
            "step 10450: mse=0.007437 mse_top=0.002391\n",
            "step 10500: mse=0.008222 mse_top=0.002905\n",
            "step 10550: mse=0.006819 mse_top=0.002362\n",
            "step 10600: mse=0.006273 mse_top=0.002621\n",
            "step 10650: mse=0.006129 mse_top=0.002175\n",
            "step 10700: mse=0.006746 mse_top=0.002113\n",
            "step 10750: mse=0.006792 mse_top=0.002339\n",
            "step 10800: mse=0.005844 mse_top=0.002370\n",
            "step 10850: mse=0.007643 mse_top=0.002438\n",
            "step 10900: mse=0.006936 mse_top=0.002458\n",
            "step 10950: mse=0.008115 mse_top=0.002602\n",
            "step 11000: mse=0.006545 mse_top=0.002658\n",
            "step 11050: mse=0.006490 mse_top=0.002547\n",
            "step 11100: mse=0.006785 mse_top=0.002548\n",
            "step 11150: mse=0.007611 mse_top=0.002411\n",
            "step 11200: mse=0.006690 mse_top=0.002300\n",
            "step 11250: mse=0.007567 mse_top=0.002372\n",
            "step 11300: mse=0.007460 mse_top=0.002474\n",
            "step 11350: mse=0.007024 mse_top=0.002504\n",
            "step 11400: mse=0.007976 mse_top=0.002561\n",
            "step 11450: mse=0.007260 mse_top=0.002656\n",
            "step 11500: mse=0.007119 mse_top=0.002633\n",
            "step 11550: mse=0.006999 mse_top=0.002246\n",
            "step 11600: mse=0.005858 mse_top=0.002653\n",
            "step 11650: mse=0.006765 mse_top=0.002489\n",
            "step 11700: mse=0.006450 mse_top=0.002417\n",
            "step 11750: mse=0.007191 mse_top=0.002617\n",
            "step 11800: mse=0.006544 mse_top=0.002400\n",
            "step 11850: mse=0.006444 mse_top=0.002340\n",
            "step 11900: mse=0.006875 mse_top=0.002542\n",
            "step 11950: mse=0.006783 mse_top=0.002364\n",
            "step 12000: mse=0.007842 mse_top=0.002492\n",
            "step 12050: mse=0.008155 mse_top=0.002892\n",
            "step 12100: mse=0.007333 mse_top=0.002587\n",
            "step 12150: mse=0.005523 mse_top=0.002200\n",
            "step 12200: mse=0.006892 mse_top=0.002405\n",
            "step 12250: mse=0.005958 mse_top=0.002440\n",
            "step 12300: mse=0.006970 mse_top=0.002595\n",
            "step 12350: mse=0.007585 mse_top=0.002324\n",
            "step 12400: mse=0.007468 mse_top=0.002785\n",
            "step 12450: mse=0.007138 mse_top=0.002731\n",
            "step 12500: mse=0.007437 mse_top=0.002819\n",
            "step 12550: mse=0.007221 mse_top=0.002714\n",
            "step 12600: mse=0.006170 mse_top=0.002415\n",
            "step 12650: mse=0.007222 mse_top=0.003036\n",
            "step 12700: mse=0.006814 mse_top=0.002657\n",
            "step 12750: mse=0.005986 mse_top=0.002734\n",
            "step 12800: mse=0.007709 mse_top=0.002813\n",
            "step 12850: mse=0.006470 mse_top=0.002749\n",
            "step 12900: mse=0.006348 mse_top=0.002774\n",
            "step 12950: mse=0.006216 mse_top=0.002582\n",
            "step 13000: mse=0.006963 mse_top=0.002372\n",
            "step 13050: mse=0.007851 mse_top=0.002821\n",
            "step 13100: mse=0.006590 mse_top=0.002697\n",
            "step 13150: mse=0.007449 mse_top=0.002404\n",
            "step 13200: mse=0.006308 mse_top=0.002658\n",
            "step 13250: mse=0.006893 mse_top=0.002820\n",
            "step 13300: mse=0.006390 mse_top=0.002425\n",
            "step 13350: mse=0.007174 mse_top=0.002832\n",
            "step 13400: mse=0.006426 mse_top=0.002727\n",
            "step 13450: mse=0.006802 mse_top=0.002370\n",
            "step 13500: mse=0.007477 mse_top=0.002735\n",
            "step 13550: mse=0.006415 mse_top=0.002621\n",
            "step 13600: mse=0.006700 mse_top=0.002729\n",
            "step 13650: mse=0.006175 mse_top=0.002278\n",
            "step 13700: mse=0.007350 mse_top=0.002755\n",
            "step 13750: mse=0.006533 mse_top=0.002832\n",
            "step 13800: mse=0.006048 mse_top=0.002413\n",
            "step 13850: mse=0.006817 mse_top=0.002664\n",
            "step 13900: mse=0.006266 mse_top=0.002567\n",
            "step 13950: mse=0.006623 mse_top=0.002672\n",
            "step 14000: mse=0.006069 mse_top=0.003058\n",
            "step 14050: mse=0.007534 mse_top=0.002847\n",
            "step 14100: mse=0.005645 mse_top=0.002436\n",
            "step 14150: mse=0.007560 mse_top=0.002619\n",
            "step 14200: mse=0.006475 mse_top=0.002908\n",
            "step 14250: mse=0.006563 mse_top=0.002724\n",
            "step 14300: mse=0.006029 mse_top=0.002720\n",
            "step 14350: mse=0.005401 mse_top=0.002452\n",
            "step 14400: mse=0.006409 mse_top=0.002874\n",
            "step 14450: mse=0.006954 mse_top=0.002830\n",
            "step 14500: mse=0.006173 mse_top=0.002765\n",
            "step 14550: mse=0.007017 mse_top=0.003355\n",
            "step 14600: mse=0.005739 mse_top=0.002481\n",
            "step 14650: mse=0.006352 mse_top=0.002632\n",
            "step 14700: mse=0.006622 mse_top=0.002764\n",
            "step 14750: mse=0.006142 mse_top=0.002569\n",
            "step 14800: mse=0.006374 mse_top=0.002898\n",
            "step 14850: mse=0.007118 mse_top=0.003099\n",
            "step 14900: mse=0.006076 mse_top=0.002940\n",
            "step 14950: mse=0.007154 mse_top=0.002956\n",
            "step 15000: mse=0.007017 mse_top=0.002926\n",
            "step 15050: mse=0.007480 mse_top=0.002926\n",
            "step 15100: mse=0.006667 mse_top=0.002805\n",
            "step 15150: mse=0.006109 mse_top=0.002623\n",
            "step 15200: mse=0.006500 mse_top=0.002615\n",
            "step 15250: mse=0.005540 mse_top=0.002679\n",
            "step 15300: mse=0.006100 mse_top=0.003144\n",
            "step 15350: mse=0.006036 mse_top=0.002989\n",
            "step 15400: mse=0.006072 mse_top=0.003050\n",
            "step 15450: mse=0.007258 mse_top=0.003377\n",
            "step 15500: mse=0.006375 mse_top=0.002776\n",
            "step 15550: mse=0.006045 mse_top=0.003193\n",
            "step 15600: mse=0.007627 mse_top=0.003300\n",
            "step 15650: mse=0.006489 mse_top=0.002589\n",
            "step 15700: mse=0.007034 mse_top=0.003228\n",
            "step 15750: mse=0.006806 mse_top=0.003052\n",
            "step 15800: mse=0.007209 mse_top=0.003256\n",
            "step 15850: mse=0.007074 mse_top=0.002729\n",
            "step 15900: mse=0.005638 mse_top=0.002901\n",
            "step 15950: mse=0.005967 mse_top=0.002647\n",
            "step 16000: mse=0.006057 mse_top=0.003052\n",
            "step 16050: mse=0.005617 mse_top=0.002824\n",
            "step 16100: mse=0.006225 mse_top=0.002841\n",
            "step 16150: mse=0.006397 mse_top=0.002786\n",
            "step 16200: mse=0.007174 mse_top=0.003293\n",
            "step 16250: mse=0.007665 mse_top=0.003588\n",
            "step 16300: mse=0.006889 mse_top=0.003294\n",
            "step 16350: mse=0.006611 mse_top=0.003304\n",
            "step 16400: mse=0.006865 mse_top=0.003009\n",
            "step 16450: mse=0.006368 mse_top=0.002948\n",
            "step 16500: mse=0.005662 mse_top=0.002470\n",
            "step 16550: mse=0.005831 mse_top=0.002940\n",
            "step 16600: mse=0.005771 mse_top=0.003015\n",
            "step 16650: mse=0.006625 mse_top=0.003670\n",
            "step 16700: mse=0.006526 mse_top=0.003150\n",
            "step 16750: mse=0.006976 mse_top=0.003161\n",
            "step 16800: mse=0.006048 mse_top=0.003171\n",
            "step 16850: mse=0.005741 mse_top=0.002960\n",
            "step 16900: mse=0.006618 mse_top=0.003315\n",
            "step 16950: mse=0.006122 mse_top=0.002831\n",
            "step 17000: mse=0.007228 mse_top=0.002806\n",
            "step 17050: mse=0.005631 mse_top=0.002662\n",
            "step 17100: mse=0.006226 mse_top=0.002777\n",
            "step 17150: mse=0.005886 mse_top=0.003039\n",
            "step 17200: mse=0.006593 mse_top=0.002645\n",
            "step 17250: mse=0.006107 mse_top=0.002929\n",
            "step 17300: mse=0.005498 mse_top=0.002713\n",
            "step 17350: mse=0.006419 mse_top=0.002943\n",
            "step 17400: mse=0.005499 mse_top=0.002944\n",
            "step 17450: mse=0.005058 mse_top=0.002624\n",
            "step 17500: mse=0.006090 mse_top=0.003168\n",
            "step 17550: mse=0.006602 mse_top=0.003036\n",
            "step 17600: mse=0.006461 mse_top=0.002987\n",
            "step 17650: mse=0.005826 mse_top=0.002984\n",
            "step 17700: mse=0.005979 mse_top=0.002933\n",
            "step 17750: mse=0.006736 mse_top=0.003047\n",
            "step 17800: mse=0.005041 mse_top=0.002523\n",
            "step 17850: mse=0.006415 mse_top=0.003153\n",
            "step 17900: mse=0.006445 mse_top=0.003252\n",
            "step 17950: mse=0.005682 mse_top=0.003004\n",
            "step 18000: mse=0.006340 mse_top=0.003445\n",
            "step 18050: mse=0.006077 mse_top=0.003430\n",
            "step 18100: mse=0.004968 mse_top=0.002679\n",
            "step 18150: mse=0.006770 mse_top=0.003220\n",
            "step 18200: mse=0.005388 mse_top=0.003160\n",
            "step 18250: mse=0.006013 mse_top=0.003443\n",
            "step 18300: mse=0.005811 mse_top=0.002629\n",
            "step 18350: mse=0.005540 mse_top=0.002916\n",
            "step 18400: mse=0.006206 mse_top=0.003397\n",
            "step 18450: mse=0.007425 mse_top=0.003446\n",
            "step 18500: mse=0.005253 mse_top=0.002917\n",
            "step 18550: mse=0.005544 mse_top=0.002797\n",
            "step 18600: mse=0.005864 mse_top=0.002937\n",
            "step 18650: mse=0.005994 mse_top=0.003085\n",
            "step 18700: mse=0.006000 mse_top=0.003228\n",
            "step 18750: mse=0.005420 mse_top=0.003133\n",
            "step 18800: mse=0.005547 mse_top=0.003222\n",
            "step 18850: mse=0.006824 mse_top=0.003381\n",
            "step 18900: mse=0.006772 mse_top=0.003244\n",
            "step 18950: mse=0.005662 mse_top=0.003183\n",
            "step 19000: mse=0.006530 mse_top=0.003657\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1dba01507688>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns_thermal\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_reconstructions_thermal.png'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Nawid - Changes the valeus back to 255 and integers and save the reconstructions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-1dba01507688>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Nawid - I think this makes the gradient become zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mterms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Nawid - Backpropagates the total loss term ( which is related to all the different components)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Nawid- Updates using optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrevive_dead_entries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YPCJUNlTul7E"
      },
      "source": [
        "# Original code - For when the images of the thermal and the RGB data was different"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAOZ3-nTYZXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "  model = make_vae()\n",
        "  if os.path.exists(VAE_PATH):\n",
        "    model.load_state_dict(torch.load(VAE_PATH, map_location='cpu'))\n",
        "  model.to(device)\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  \n",
        "  # Nawid -Define the iterators for the validation data\n",
        "\n",
        "  i = 0\n",
        "  val_loader = InfiniteDataLoader(x_rgb,x)\n",
        "  val_iterator = iter(val_loader) \n",
        "\n",
        "  \n",
        "\n",
        "  for x_rgb_batch, x_thermal_batch in rgb_thermal_load_images(x_rgb,x):\n",
        "    x_rgb_batch = x_rgb_batch.to(device)\n",
        "    x_thermal_batch = x_thermal_batch.to(device)\n",
        "    terms = model(x_rgb_batch, x_thermal_batch)\n",
        "    \n",
        "    if rapid_evaluation:\n",
        "      print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    else:\n",
        "      if not i % eval_counter:\n",
        "        print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    \n",
        "    optimizer.zero_grad() #Nawid - I think this makes the gradient become zero\n",
        "    terms['loss'].backward() # Nawid - Backpropagates the total loss term ( which is related to all the different components)\n",
        "    optimizer.step() # Nawid- Updates using optimizer\n",
        "    model.revive_dead_entries()\n",
        "    i +=1\n",
        "    \n",
        "    if not i % 50:\n",
        "      torch.save(model.state_dict(), VAE_PATH)\n",
        "      #save_reconstructions(x_rgb_batch, terms['reconstructions'][-1], x_thermal_batch,terms['reconstructions_thermal'][-1])\n",
        "      save_reconstructions(model,x_rgb_batch, x_thermal_batch) # Nawid - saves the reconstruction\n",
        "\n",
        "      val_rgb_batch,val_thermal_batch = next(val_iterator)\n",
        "      \n",
        "      if save_data:\n",
        "        val_total_loss, val_reconstruction_loss = validation_loss(model,val_rgb_batch,val_thermal_batch)\n",
        "        tensorboard_saving(i,terms['losses'][-1],val_reconstruction_loss, terms['loss'],val_total_loss)\n",
        "      else:\n",
        "        pass\n",
        "      save_reconstructions(model,val_rgb_batch, val_thermal_batch,'Val')\n",
        "\n",
        "\n",
        "def tensorboard_saving(iteration,recon_loss_train, recon_loss_val, total_loss_train,total_loss_val):\n",
        "  tb.save_value('Reconstruction_loss','Train loss', iteration, recon_loss_train)\n",
        "  tb.save_value('Reconstruction_loss','Validation loss', iteration, recon_loss_val)\n",
        "      \n",
        "  tb.save_value('Total_loss','Train loss', iteration, total_loss_train)\n",
        "  tb.save_value('Total_loss','Validation loss', iteration, total_loss_val)\n",
        " \n",
        "  tb.flush_line('Reconstruction_loss')\n",
        "  tb.flush_line('Total_loss')\n",
        "\n",
        "\n",
        "def validation_loss(vae,val_rgb, val_thermal):\n",
        "  vae.eval() # Nawid - Sets it into evaluation mode ( so dropout and batchnorm have different behaviours)\n",
        "  with torch.no_grad(): # Nawid-  Turns off the autograd engine which speeds up computation\n",
        "    val_terms = vae(val_rgb,val_thermal)\n",
        "    total_loss, reconstruction_loss = val_terms['loss'], val_terms['losses'][-1]\n",
        "    vae.train()\n",
        "    return total_loss, reconstruction_loss\n",
        "\n",
        "\n",
        "def save_reconstructions(vae,rgb_images, thermal_images,name = 'Train'):\n",
        "  vae.eval()\n",
        "  with torch.no_grad():\n",
        "    recons, recons_thermal = vae.full_reconstructions(rgb_images,thermal_images)\n",
        "    recons = [torch.clamp(x, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x in recons] # Nawid - Clamps all the different elements in recons\n",
        "    recons_thermal = [torch.clamp(x_thermal, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x_thermal in recons_thermal] # Nawid - Clamps all the different elements in recons_thermal\n",
        "    \n",
        "    vae.train() # Nawid - This sets the nn.module into training mode\n",
        "    top_recons, real_recons = recons # Nawid - I believe the top_recons is the reconstruction using only the top latent map, whilst real_recons is using both the top latent map and the bottom latent map\n",
        "    rgb_images = rgb_images.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "    columns = np.concatenate([top_recons, real_recons, rgb_images], axis=-2)\n",
        "    columns = np.concatenate(columns, axis=0)\n",
        "    Image.fromarray((columns * 255).astype('uint8')).save(name +'_reconstructions_rgb.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "    top_recons_thermal,real_recons_thermal = recons_thermal\n",
        "    thermal_images = thermal_images.permute(0,2,3,1).detach().cpu().numpy()\n",
        "    thermal_images = thermal_images.reshape(thermal_images.shape[0],thermal_images.shape[1],thermal_images.shape[2])\n",
        "\n",
        "    top_recons_thermal = top_recons_thermal.reshape(top_recons_thermal.shape[0],top_recons_thermal.shape[1],top_recons_thermal.shape[2])\n",
        "    real_recons_thermal = real_recons_thermal.reshape(real_recons_thermal.shape[0],real_recons_thermal.shape[1],real_recons_thermal.shape[2])\n",
        "\n",
        "    columns_thermal = np.concatenate([top_recons_thermal, real_recons_thermal,thermal_images], axis=-1) # Nawid - I need to concatenate along -2 when using rgb and -1 when using grayscale and when using  When using grayscale images, to save the files using PIL, i need to make to remove the channel and so there is one less axis to examine\n",
        "    columns_thermal = np.concatenate(columns_thermal, axis=0)\n",
        "    Image.fromarray((columns_thermal * 255).astype('uint8')).save(name +'_reconstructions_thermal.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s6ivYJFBuj7S",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "  model = make_vae()\n",
        "  if os.path.exists(VAE_PATH):\n",
        "    model.load_state_dict(torch.load(VAE_PATH, map_location='cpu'))\n",
        "  model.to(device)\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  \n",
        "  # Nawid -Define the iterators for the validation data\n",
        "  val_rgb_loader = InfiniteDataLoader(val_x_rgb)\n",
        "  val_rgb_iterator = iter(val_rgb_loader)\n",
        "\n",
        "  val_thermal_loader = InfiniteDataLoader(val_x)\n",
        "  val_thermal_iterator = iter(val_thermal_loader)\n",
        "\n",
        "  i = 0\n",
        "  for x_rgb_batch, x_thermal_batch in zip(load_images(x_rgb), load_images(x)):\n",
        "    x_rgb_batch= x_rgb_batch.to(device)\n",
        "    x_thermal_batch =  x_thermal_batch.to(device)\n",
        "    terms = model(x_rgb_batch, x_thermal_batch)\n",
        "    \n",
        "    if rapid_evaluation:\n",
        "      print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    else:\n",
        "      if not i % eval_counter:\n",
        "        print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    \n",
        "    optimizer.zero_grad() #Nawid - I think this makes the gradient become zero\n",
        "    terms['loss'].backward() # Nawid - Backpropagates the total loss term ( which is related to all the different components)\n",
        "    optimizer.step() # Nawid- Updates using optimizer\n",
        "    model.revive_dead_entries()\n",
        "    i +=1\n",
        "    if not i % 50:\n",
        "      torch.save(model.state_dict(), VAE_PATH)\n",
        "      #save_reconstructions(x_rgb_batch, terms['reconstructions'][-1], x_thermal_batch,terms['reconstructions_thermal'][-1])\n",
        "      save_reconstructions(model,x_rgb_batch, x_thermal_batch) # Nawid - saves the reconstruction\n",
        "\n",
        "      val_rgb_batch = next(val_rgb_iterator)\n",
        "      val_thermal_batch = next(val_thermal_iterator)\n",
        "      val_total_loss, val_reconstruction_loss = validation_loss(model,val_rgb_batch,val_thermal_batch)\n",
        "      \n",
        "      tensorboard_saving(i,terms['losses'][-1],val_reconstruction_loss, terms['loss'],val_total_loss)\n",
        "      save_reconstructions(model,val_rgb_batch, val_thermal_batch,'Val')\n",
        "\n",
        "      '''\n",
        "      tb.save_value('Reconstruction_loss','Train loss', i, terms['losses'][-1])\n",
        "      tb.save_value('Reconstruction_loss','Validation loss', i, val_reconstruction_loss)\n",
        "      \n",
        "      tb.save_value('Total_loss','Train loss', i, terms['loss'])\n",
        "      tb.save_value('Total_loss','Validation loss', i, val_total_loss)\n",
        "      tb.flush_line('Reconstruction_loss')\n",
        "      tb.flush_line('Total_loss')\n",
        "      '''\n",
        "      \n",
        "\n",
        "def tensorboard_saving(iteration,recon_loss_train, recon_loss_val, total_loss_train,total_loss_val):\n",
        "  tb.save_value('Reconstruction_loss','Train loss', iteration, recon_loss_train)\n",
        "  tb.save_value('Reconstruction_loss','Validation loss', iteration, recon_loss_val)\n",
        "      \n",
        "  tb.save_value('Total_loss','Train loss', iteration, total_loss_train)\n",
        "  tb.save_value('Total_loss','Validation loss', iteration, total_loss_val)\n",
        " \n",
        "  tb.flush_line('Reconstruction_loss')\n",
        "  tb.flush_line('Total_loss')\n",
        "\n",
        "\n",
        "def validation_loss(vae,val_rgb, val_thermal):\n",
        "  vae.eval() # Nawid - Sets it into evaluation mode ( so dropout and batchnorm have different behaviours)\n",
        "  with torch.no_grad(): # Nawid-  Turns off the autograd engine which speeds up computation\n",
        "    val_terms = vae(val_rgb,val_thermal)\n",
        "    total_loss, reconstruction_loss = val_terms['loss'], val_terms['losses'][-1]\n",
        "    return total_loss, reconstruction_loss\n",
        "\n",
        "\n",
        "def save_reconstructions(vae,rgb_images, thermal_images,name = 'Train'):\n",
        "  vae.eval()\n",
        "  with torch.no_grad():\n",
        "    recons, recons_thermal = vae.full_reconstructions(rgb_images,thermal_images)\n",
        "    recons = [torch.clamp(x, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x in recons] # Nawid - Clamps all the different elements in recons\n",
        "    recons_thermal = [torch.clamp(x_thermal, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x_thermal in recons_thermal] # Nawid - Clamps all the different elements in recons_thermal\n",
        "    \n",
        "    vae.train() # Nawid - This sets the nn.module into training mode\n",
        "    top_recons, real_recons = recons # Nawid - I believe the top_recons is the reconstruction using only the top latent map, whilst real_recons is using both the top latent map and the bottom latent map\n",
        "    rgb_images = rgb_images.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "    columns = np.concatenate([top_recons, real_recons, rgb_images], axis=-2)\n",
        "    columns = np.concatenate(columns, axis=0)\n",
        "    Image.fromarray((columns * 255).astype('uint8')).save(name +'_reconstructions_rgb.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "    top_recons_thermal,real_recons_thermal = recons_thermal\n",
        "    thermal_images = thermal_images.permute(0,2,3,1).detach().cpu().numpy()\n",
        "    thermal_images = thermal_images.reshape(thermal_images.shape[0],thermal_images.shape[1],thermal_images.shape[2])\n",
        "\n",
        "    top_recons_thermal = top_recons_thermal.reshape(top_recons_thermal.shape[0],top_recons_thermal.shape[1],top_recons_thermal.shape[2])\n",
        "    real_recons_thermal = real_recons_thermal.reshape(real_recons_thermal.shape[0],real_recons_thermal.shape[1],real_recons_thermal.shape[2])\n",
        "\n",
        "    columns_thermal = np.concatenate([top_recons_thermal, real_recons_thermal,thermal_images], axis=-1) # Nawid - I need to concatenate along -2 when using rgb and -1 when using grayscale and when using  When using grayscale images, to save the files using PIL, i need to make to remove the channel and so there is one less axis to examine\n",
        "    columns_thermal = np.concatenate(columns_thermal, axis=0)\n",
        "    Image.fromarray((columns_thermal * 255).astype('uint8')).save(name +'_reconstructions_thermal.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z8n9DfbZujVk",
        "colab": {}
      },
      "source": [
        "def load_images(input_x): # Nawid - Loads images\n",
        "    while True:\n",
        "        for data in create_data_loader(input_x):\n",
        "          #data = data.float()/255 # Nawid - Divides by 255 \n",
        "          data = data.permute(0, 3, 1, 2).contiguous() # Nawid - Changes into pytorch ordering\n",
        "          yield data\n",
        "       \n",
        "def create_data_loader(input_x): # Nawid - Creates a dataloader object\n",
        "    return torch.utils.data.DataLoader(input_x, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# https://gist.github.com/MFreidank/821cc87b012c53fade03b0c7aba13958\n",
        "class InfiniteDataLoader(DataLoader): \n",
        "  def __init__(self,input_x, batch_size=BATCH_SIZE, shuffle=True):\n",
        "    super().__init__(input_x, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    #Initialise an iterator over the dataset\n",
        "    self.dataset_iterator = super().__iter__()\n",
        "\n",
        "  def __iter__(self):\n",
        "    return self\n",
        "\n",
        "  def __next__(self):\n",
        "    try:\n",
        "      batch = next(self.dataset_iterator)\n",
        "\n",
        "    except StopIteration:\n",
        "      # Dataset exhausted, use a new fresh iterator\n",
        "      self.dataset_iterator = super().__iter__()\n",
        "      batch = next(self.dataset_iterator)\n",
        "    batch = batch.permute(0, 3, 1, 2).contiguous() # Nawid- Added this to change the channels\n",
        "    return batch.to(device) # Nawid - Add to the device directly\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}