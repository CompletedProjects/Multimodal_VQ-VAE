{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hierarchical_layers_Updated_decoder_261219.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nerdk312/Multimodal_VQ-VAE/blob/master/Hierarchical_layers_Updated_decoder_261219.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91lXa8c5oRR7",
        "colab_type": "text"
      },
      "source": [
        "First, we'll mount Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXzGWJivmz60",
        "colab_type": "code",
        "outputId": "60320785-5c8b-4aed-ce0e-2c70082cb079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wku8sXE0oXP9",
        "colab_type": "text"
      },
      "source": [
        "I happen to have an existing `.py` file in Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdULhsaToPi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /content/gdrive/My\\ Drive/vq-vae-2-master_joint_modality/vq_vae_2/examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIrBoOh-od6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat '/content/gdrive/My Drive/vq-vae-2-master/vq_vae_2/vq_vae.py'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6Mf8Ojmojmc",
        "colab_type": "text"
      },
      "source": [
        "We'll need to update our path to import from Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psH0aLrvoh78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/vq-vae-2-master_multi_modality')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZRgYw_Noz5E",
        "colab_type": "text"
      },
      "source": [
        "Now we can import the library and use the function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMFs4loUoxBK",
        "colab_type": "code",
        "outputId": "7135ff1c-81f3-4b75-ac79-a2adc544b8c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "from keras.preprocessing import image as image_utils\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "\n",
        "from vq_vae_2.examples.Two_layers_combined.model import make_vq_vae\n",
        "target_size = (128,128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aYZg2EEUQD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp_dir = '/content/gdrive/My Drive/thermal_8_bit'\n",
        "image_list = os.listdir(inp_dir)\n",
        "all_images = []\n",
        "\n",
        "rgb_inp_dir = '/content/gdrive/My Drive/RGB'\n",
        "rgb_image_list = os.listdir(rgb_inp_dir)\n",
        "all_rgb_images = []\n",
        "\n",
        "quick_test = False\n",
        "desired_examples = 8300\n",
        "if quick_test:\n",
        "  for i, img_name in enumerate(image_list):\n",
        "    if i< 10:\n",
        "      fname = inp_dir + '/' + img_name\n",
        "      image = image_utils.load_img(fname, color_mode='grayscale').resize(target_size,Image.ANTIALIAS)\n",
        "      image = np.array(image.getdata()).reshape(target_size[0], target_size[1],1)\n",
        "      image = image.astype('float32')/255\n",
        "      all_images.append(image)\n",
        "      \n",
        "    \n",
        "  for j, img_name in enumerate(rgb_image_list):\n",
        "    if j < 10:\n",
        "      fname = rgb_inp_dir + '/' + img_name\n",
        "      image = image_utils.load_img(fname).resize(target_size,Image.ANTIALIAS)\n",
        "      image = np.array(image.getdata()).reshape(target_size[0], target_size[1],3)\n",
        "      image = image.astype('float32')/255\n",
        "      all_rgb_images.append(image)\n",
        "      \n",
        "    else:\n",
        "      pass\n",
        "else:\n",
        "  \n",
        "  for i, img_name in enumerate(image_list):\n",
        "    if i < desired_examples:\n",
        "      fname = inp_dir + '/' + img_name\n",
        "      image = image_utils.load_img(fname, color_mode='grayscale').resize(target_size,Image.ANTIALIAS)\n",
        "      image = np.array(image.getdata()).reshape(target_size[0], target_size[1],1)\n",
        "      image = image.astype('float32')/255\n",
        "      all_images.append(image)\n",
        "      if not i%100:\n",
        "        print(i)\n",
        "    else: \n",
        "      pass\n",
        "  \n",
        "  for j, img_name in enumerate(rgb_image_list):\n",
        "    if j < desired_examples:\n",
        "      fname = rgb_inp_dir + '/' + img_name\n",
        "      image = image_utils.load_img(fname).resize(target_size,Image.ANTIALIAS)\n",
        "      image = np.array(image.getdata()).reshape(target_size[0], target_size[1],3)\n",
        "      image = image.astype('float32')/255\n",
        "      all_rgb_images.append(image)\n",
        "      if not j%100: # Nawid  -indicates how far through it is in the process\n",
        "        print(j)\n",
        "    else:\n",
        "      pass\n",
        "  \n",
        "np.save('Thermal_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy',all_images)\n",
        "np.save('RGB_' +str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy',all_rgb_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjrCvV01jTku",
        "colab_type": "text"
      },
      "source": [
        "# UPLOADING FROM DRIVE DIRECTLY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og5BUQFzrkcL",
        "colab_type": "code",
        "outputId": "2a7b6007-0952-4660-cc08-49dad715c63b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "upload_directly = True\n",
        "if upload_directly:\n",
        "  x_rgb = np.load('/content/gdrive/My Drive/RGB_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  x = np.load('/content/gdrive/My Drive/Thermal_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "else:\n",
        "  x_rgb = np.load('/content/RGB_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  x = np.load('/content/Thermal_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "\n",
        "print(x_rgb.shape)\n",
        "print(x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8350, 128, 128, 3)\n",
            "(8350, 128, 128, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flh5hJGRFvjC",
        "colab_type": "text"
      },
      "source": [
        "Making predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFOgjEpcNkkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "def load_images(input_x): # Nawid - Loads images\n",
        "    while True:\n",
        "        for data in create_data_loader(input_x):\n",
        "          #data = data.float()/255 # Nawid - Divides by 255 \n",
        "          data = data.permute(0, 3, 1, 2).contiguous() # Nawid - Changes into pytorch ordering\n",
        "          yield data\n",
        "       \n",
        "def create_data_loader(input_x): # Nawid - Creates a dataloader object\n",
        "    return torch.utils.data.DataLoader(input_x, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "\n",
        "device = torch.device('cuda')\n",
        "VAE_PATH = 'vae.pt'\n",
        "\n",
        "def main():\n",
        "  model = make_vq_vae()\n",
        "  if os.path.exists(VAE_PATH):\n",
        "    model.load_state_dict(torch.load(VAE_PATH, map_location='cpu'))\n",
        "  model.to(device)\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  i = 0\n",
        "  for x_rgb_batch, x_thermal_batch in zip(load_images(x_rgb), load_images(x)):\n",
        "    x_rgb_batch= x_rgb_batch.to(device)\n",
        "    x_thermal_batch =  x_thermal_batch.to(device)\n",
        "    terms = model(x_rgb_batch, x_thermal_batch)\n",
        "    #print('step %d: mse=%f mse_top=%f mse_top_thermal=%f' %\n",
        "    #      (i, terms['losses'][-1].item(), terms['losses'][0].item(),terms['losses_thermal'][0].item()))\n",
        "    \n",
        "    if not i % 50:\n",
        "      print('step %d: mse=%f mse_top=%f mse_top_thermal=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item(),terms['losses_thermal'][0].item()))\n",
        "    \n",
        "    optimizer.zero_grad() #Nawid - I think this makes the gradient become zero\n",
        "    terms['loss'].backward() # Nawid - Backpropagates the total loss term ( which is related to all the different components)\n",
        "    optimizer.step() # Nawid- Updates using optimizer\n",
        "    model.revive_dead_entries()\n",
        "    i +=1\n",
        "    if not i % 100:\n",
        "      torch.save(model.state_dict(), VAE_PATH)\n",
        "      save_reconstructions(model,x_rgb_batch, x_thermal_batch) # Nawid - saves the reconstruction\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_reconstructions(vae,rgb_images, thermal_images):\n",
        "  vae.eval()\n",
        "  with torch.no_grad():\n",
        "    #output, output_thermal = vae.full_reconstructions(rgb_images,thermal_images)\n",
        "    #top_output, real_output = output\n",
        "    #print(\"reconstruction output shape:\",top_output.shape)\n",
        "    recons,recons_thermal = vae.full_reconstructions(rgb_images,thermal_images)\n",
        "    recons = [torch.clamp(x, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x in recons] # Nawid - Clamps all the different elements in recons \n",
        "    recons_thermal = [torch.clamp(x_thermal, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x_thermal in recons_thermal] # Nawid - Clamps all the different elements in recons_thermal\n",
        "    #top_output, real_output = output\n",
        "    #top_output_thermal, real_output_thermal = output_thermal\n",
        "    #print('top_output shape:',top_output.shape)\n",
        "    #print('real_output shape:',real_output.shape)\n",
        "    #print('top_output_thermal shape:',top_output_thermal.shape)\n",
        "    #print('real_output_thermal shape:',real_output_thermal.shape)\n",
        "\n",
        "    #for x_rgb, x_thermal in vae.full_reconstructions(rgb_images,thermal_images):\n",
        "      #print(\"Here is both input shapes\",x_rgb.shape)\n",
        "      #print(\"Here is x_thermal shape\",x_thermal.shape)\n",
        "      #print(x_thermal)\n",
        "      #recons = [torch.clamp(x_rgb, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()]\n",
        "      #recons_thermal = [torch.clamp(x_thermal, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()]\n",
        "    #recons,recons_thermal = [torch.clamp(x, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  #for x_rgb,x_thermal in vae.full_reconstructions(rgb_images,thermal_images)] # Nawid - performs the full_reconstructions of the image from using the top latent map, as well as the top level latent map combined with the lower level latent map.\n",
        "    vae.train() # Nawid - This sets the nn.module into training mode\n",
        "    top_recons, real_recons = recons # Nawid - I believe the top_recons is the reconstruction using only the top latent map, whilst real_recons is using both the top latent map and the bottom latent map\n",
        "    rgb_images = rgb_images.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "    columns = np.concatenate([top_recons, real_recons, rgb_images], axis=-2)\n",
        "    columns = np.concatenate(columns, axis=0)\n",
        "    Image.fromarray((columns * 255).astype('uint8')).save('reconstructions_rgb.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "\n",
        "    top_recons_thermal,real_recons_thermal = recons_thermal\n",
        "    thermal_images = thermal_images.permute(0,2,3,1).detach().cpu().numpy()\n",
        "    thermal_images = thermal_images.reshape(thermal_images.shape[0],thermal_images.shape[1],thermal_images.shape[2])\n",
        "\n",
        "    top_recons_thermal = top_recons_thermal.reshape(top_recons_thermal.shape[0],top_recons_thermal.shape[1],top_recons_thermal.shape[2])\n",
        "    real_recons_thermal = real_recons_thermal.reshape(real_recons_thermal.shape[0],real_recons_thermal.shape[1],real_recons_thermal.shape[2])\n",
        "\n",
        "    columns_thermal = np.concatenate([top_recons_thermal, real_recons_thermal,thermal_images], axis=-1) # Nawid - I need to concatenate along -2 when using rgb and -1 when using grayscale and when using  When using grayscale images, to save the files using PIL, i need to make to remove the channel and so there is one less axis to examine\n",
        "    columns_thermal = np.concatenate(columns_thermal, axis=0)\n",
        "    Image.fromarray((columns_thermal * 255).astype('uint8')).save('reconstructions_thermal.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "    \n",
        "main()\n",
        "\n",
        "'''\n",
        "def save_reconstructions(x_rgb_batch, x_thermal_batch,decoded_rgb, decoded_thermal):\n",
        "  x_rgb_batch = x_rgb_batch.permute(0,2,3,1).detach().cpu().numpy()\n",
        "  x_thermal_batch = x_thermal_batch.permute(0,2,3,1).detach().cpu().numpy()\n",
        "  decoded_rgb = decoded_rgb.permute(0,2,3,1).detach().cpu().numpy()\n",
        "  decoded_thermal = decoded_thermal.permute(0,2,3,1).detach().cpu().numpy()\n",
        "  \n",
        "  columns = np.concatenate([decoded_rgb, x_rgb_batch], axis=-2) # Nawid - I need to concatenate along -2 when using rgb and -1 when using grayscale and when using  When using grayscale images, to save the files using PIL, i need to make to remove the channel and so there is one less axis to examine\n",
        "  columns = np.concatenate(columns, axis=0)\n",
        "  Image.fromarray((columns * 255).astype('uint8')).save('reconstructions_rgb.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "  \n",
        "  x_thermal_batch = x_thermal_batch.reshape(x_thermal_batch.shape[0],x_thermal_batch.shape[1],x_thermal_batch.shape[2]) # Nawid - For grayscale images, need to remove the channel in order to save data in a PIL forma\n",
        "  decoded_thermal = decoded_thermal.reshape(decoded_thermal.shape[0],decoded_thermal.shape[1],decoded_thermal.shape[2])\n",
        "\n",
        "  columns_thermal = np.concatenate([decoded_thermal, x_thermal_batch], axis=-1) # Nawid - I need to concatenate along -2 when using rgb and -1 when using grayscale and when using  When using grayscale images, to save the files using PIL, i need to make to remove the channel and so there is one less axis to examine\n",
        "  columns_thermal = np.concatenate(columns_thermal, axis=0)\n",
        "  Image.fromarray((columns_thermal * 255).astype('uint8')).save('reconstructions_thermal.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "'''\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}