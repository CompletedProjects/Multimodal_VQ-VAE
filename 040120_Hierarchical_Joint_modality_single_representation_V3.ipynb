{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "040120_Hierarchical_Joint_modality_single_representation_V3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nerdk312/Multimodal_VQ-VAE/blob/master/040120_Hierarchical_Joint_modality_single_representation_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP252uER8Mj4",
        "colab_type": "code",
        "outputId": "a0225575-25ca-4c6e-965b-cdeae194423a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEdPl_3i8i3z",
        "colab_type": "code",
        "outputId": "c17963c7-09d6-49e7-b9b8-d40e5fd9b9a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# Nawid - Updates the path to import from drive\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/vq-vae-2-master-Single_representation_V2')\n",
        "\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "from keras.preprocessing import image as image_utils\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from tensorboardcolab import TensorBoardColab\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from vq_vae_2.examples.hierarchical_combined.model import make_vae\n",
        "target_size = (64,64)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R73VF2pBwTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def common_images(RGB_dir,Thermal_dir):\n",
        "  RGB_image_list = os.listdir(RGB_dir)\n",
        "  Thermal_image_list = os.listdir(Thermal_dir)\n",
        "\n",
        "  truncated_RGB_image_list = [RGB_image_name.strip('.jpg') for RGB_image_name in RGB_image_list]\n",
        "  truncated_Thermal_image_list = [Thermal_image_name.strip('.jpeg') for Thermal_image_name in Thermal_image_list]\n",
        "\n",
        "  common_list = set(truncated_RGB_image_list).intersection(truncated_Thermal_image_list)\n",
        "  common_list = sorted(common_list) # Nawid - Sorts all the items in a list\n",
        "  return common_list\n",
        "\n",
        "RGB_inp_dir = '/content/gdrive/My Drive/RGB'\n",
        "Thermal_inp_dir = '/content/gdrive/My Drive/thermal_8_bit'\n",
        "train_list = common_images(RGB_inp_dir,Thermal_inp_dir) \n",
        "\n",
        "val_RGB_inp_dir = '/content/gdrive/My Drive/Val_RGB'\n",
        "val_Thermal_inp_dir = '/content/gdrive/My Drive/Val_thermal_8_bit'\n",
        "val_list = common_images(val_RGB_inp_dir,val_Thermal_inp_dir)\n",
        "\n",
        "def processing_saving_images(modality,quick_test=True,Train_required=False,Val_required=True):\n",
        "  all_images = []\n",
        "  val_all_images = []\n",
        "  \n",
        "  if modality == 'RGB_':\n",
        "    suffix = '.jpg'\n",
        "    channels = 3\n",
        "    inp_dir = '/content/gdrive/My Drive/RGB'\n",
        "    val_inp_dir = '/content/gdrive/My Drive/Val_RGB'\n",
        "  \n",
        "  elif modality == 'Thermal_':\n",
        "    suffix = '.jpeg'\n",
        "    channels = 1\n",
        "    inp_dir = '/content/gdrive/My Drive/thermal_8_bit'\n",
        "    val_inp_dir = '/content/gdrive/My Drive/Val_thermal_8_bit'\n",
        "  \n",
        "  else:\n",
        "    return('Incorrect Modality name')\n",
        "\n",
        "  if quick_test:\n",
        "    if Train_required:\n",
        "      for i, img_name in enumerate(train_list):\n",
        "        if i< 10:\n",
        "          fname = inp_dir + '/' + img_name + suffix\n",
        "          if modality == 'RGB_':\n",
        "            image = image_utils.load_img(fname).resize(target_size,Image.ANTIALIAS)\n",
        "          else:\n",
        "            image = image_utils.load_img(fname,color_mode='grayscale').resize(target_size,Image.ANTIALIAS)\n",
        "          image = np.array(image.getdata()).reshape(target_size[0], target_size[1], channels)\n",
        "          image = image.astype('float32')/255 \n",
        "          all_images.append(image)\n",
        "        else:\n",
        "          pass\n",
        "    else:\n",
        "      pass\n",
        "    \n",
        "    if Val_required:\n",
        "      for j, img_name in enumerate(val_list):\n",
        "        if j < 10:\n",
        "          fname = val_inp_dir + '/' + img_name + suffix\n",
        "          if modality == 'RGB_':\n",
        "            image = image_utils.load_img(fname).resize(target_size,Image.ANTIALIAS)\n",
        "          else:\n",
        "            image = image_utils.load_img(fname,color_mode='grayscale').resize(target_size,Image.ANTIALIAS)\n",
        "          \n",
        "          image = np.array(image.getdata()).reshape(target_size[0], target_size[1], channels)\n",
        "          image = image.astype('float32')/255 \n",
        "          val_all_images.append(image)\n",
        "        else: \n",
        "          pass \n",
        "    else:\n",
        "      pass\n",
        "\n",
        "  else:\n",
        "    if Train_required:\n",
        "      for i, img_name in enumerate(train_list):\n",
        "        fname = inp_dir + '/' + img_name + suffix\n",
        "        if modality == 'RGB_':\n",
        "          image = image_utils.load_img(fname).resize(target_size,Image.ANTIALIAS)\n",
        "        else:\n",
        "          image = image_utils.load_img(fname,color_mode='grayscale').resize(target_size,Image.ANTIALIAS)\n",
        "        image = np.array(image.getdata()).reshape(target_size[0], target_size[1],channels)\n",
        "        image = image.astype('float32')/255\n",
        "        all_images.append(image)\n",
        "        if not i%100:\n",
        "          print(i)\n",
        "        else: \n",
        "          pass\n",
        "    else:\n",
        "      pass\n",
        "  \n",
        "    if Val_required:\n",
        "      for j, img_name in enumerate(val_list):\n",
        "        fname = val_inp_dir + '/' + img_name + suffix\n",
        "        if modality == 'RGB_':\n",
        "          image = image_utils.load_img(fname).resize(target_size,Image.ANTIALIAS)\n",
        "        else:\n",
        "          image = image_utils.load_img(fname,color_mode='grayscale').resize(target_size,Image.ANTIALIAS)\n",
        "        image = np.array(image.getdata()).reshape(target_size[0], target_size[1],channels)\n",
        "        image = image.astype('float32')/255\n",
        "        val_all_images.append(image)\n",
        "        if not j%100:\n",
        "          print(j)\n",
        "        else: \n",
        "          pass\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "  if Train_required: \n",
        "    np.save(modality +str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy',all_images)\n",
        "\n",
        "  if Val_required:\n",
        "    np.save('Val_'+modality +str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy',val_all_images)\n",
        "\n",
        "\n",
        "rgb_modality = 'RGB_'\n",
        "thermal_modality = 'Thermal_'\n",
        "\n",
        "processing_saving_images(thermal_modality,quick_test=False,Train_required=False,Val_required=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsUjLwHf9FP9",
        "colab_type": "text"
      },
      "source": [
        "# Uploading from drive directly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kkaWdar9Ib-",
        "colab_type": "code",
        "outputId": "07ed6971-b37c-448a-c850-6e88d09c213a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "upload_directly = True\n",
        "if upload_directly:\n",
        "  x_rgb = np.load('/content/gdrive/My Drive/RGB_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  val_x_rgb = np.load('/content/gdrive/My Drive/Val_RGB_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  x = np.load('/content/gdrive/My Drive/Thermal_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  val_x = np.load('/content/gdrive/My Drive/Val_Thermal_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "else:\n",
        "  x_rgb = np.load('/content/RGB_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  val_x_rgb = np.load('/content/Val_RGB_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  x = np.load('/content/Thermal_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  val_x = np.load('/content/Val_Thermal_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "\n",
        "#val_x = val_x[:len(val_x_rgb)] # Nawid - Make into the same size as the limiting case\n",
        "print(x_rgb.shape)\n",
        "print(val_x_rgb.shape)\n",
        "print(x.shape)\n",
        "print(val_x.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8363, 64, 64, 3)\n",
            "(1257, 64, 64, 3)\n",
            "(8363, 64, 64, 1)\n",
            "(1257, 64, 64, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yft7Ami9Vbs",
        "colab_type": "text"
      },
      "source": [
        "# Model config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLXuKr8u9WZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "log_interval = 50\n",
        "rapid_evaluation = False\n",
        "eval_counter = 50\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
        "VAE_PATH = 'vae.pt'\n",
        "\n",
        "# Nawid - Used to ensure the results are reproducible - https://pytorch.org/docs/stable/notes/randomness.html\n",
        "\n",
        "reproducible = False\n",
        "seed_value = 0\n",
        "if reproducible:\n",
        "  torch.manual_seed(seed_value)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  np.random.seed(seed_value)\n",
        "\n",
        "\n",
        "save_data = False\n",
        "if save_data:\n",
        "  tb = TensorBoardColab() # Nawid - Creates a tensorboard link "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4333NUk15zou",
        "colab_type": "text"
      },
      "source": [
        "# Data loader functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsMoW1pHROZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConcatDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, *datasets):\n",
        "        self.datasets = datasets\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return tuple(d[i] for d in self.datasets)\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(d) for d in self.datasets)\n",
        "\n",
        "def rgb_thermal_data_loader(input_rgb,input_thermal): # Nawid - Creates a dataloader object\n",
        "    return torch.utils.data.DataLoader(ConcatDataset(input_rgb,input_thermal),batch_size=BATCH_SIZE, shuffle = True)\n",
        "\n",
        "def rgb_thermal_load_images(input_rgb, input_thermal): # Nawid - Loads images\n",
        "    while True:\n",
        "        for (rgb_data,thermal_data) in rgb_thermal_data_loader(input_rgb,input_thermal):\n",
        "          #data = data.float()/255 # Nawid - Divides by 255 \n",
        "          rgb_data = rgb_data.permute(0, 3, 1, 2).contiguous() # Nawid - Changes into pytorch ordering\n",
        "          thermal_data = thermal_data.permute(0, 3, 1, 2).contiguous()\n",
        "          yield rgb_data, thermal_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rc70Y0D2jL3j",
        "colab": {}
      },
      "source": [
        "# https://gist.github.com/MFreidank/821cc87b012c53fade03b0c7aba13958\n",
        "class InfiniteDataLoader(DataLoader): \n",
        "  def __init__(self,input_rgb,input_thermal, batch_size=BATCH_SIZE, shuffle=True):\n",
        "    super().__init__(ConcatDataset(input_rgb,input_thermal), batch_size=BATCH_SIZE, shuffle=True) # Nawid - Instantiates the dataloader subclass using a concatenated input\n",
        "    \n",
        "    #Initialise an iterator over the dataset\n",
        "    self.dataset_iterator = super().__iter__()\n",
        "\n",
        "  def __iter__(self):\n",
        "    return self\n",
        "\n",
        "  def __next__(self):\n",
        "    try:\n",
        "      batch = next(self.dataset_iterator)\n",
        "\n",
        "    except StopIteration:\n",
        "      # Dataset exhausted, use a new fresh iterator\n",
        "      self.dataset_iterator = super().__iter__()\n",
        "      batch = next(self.dataset_iterator)\n",
        "\n",
        "    rgb_batch, thermal_batch = batch[0], batch[1] # Nawid- Obtains the different values in the batch\n",
        "    rgb_batch = rgb_batch.permute(0, 3, 1, 2).contiguous() # Nawid- Added this to change the channels\n",
        "    thermal_batch = thermal_batch.permute(0, 3, 1, 2).contiguous()\n",
        "    \n",
        "    return rgb_batch.to(device), thermal_batch.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDpfwkbJ6L04",
        "colab_type": "text"
      },
      "source": [
        "# Main - Training and reconstructions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAOZ3-nTYZXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "  model = make_vae()\n",
        "  if os.path.exists(VAE_PATH):\n",
        "    model.load_state_dict(torch.load(VAE_PATH, map_location='cpu'))\n",
        "  model.to(device)\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  \n",
        "  # Nawid -Define the iterators for the validation data\n",
        "\n",
        "  i = 0\n",
        "  val_loader = InfiniteDataLoader(x_rgb,x)\n",
        "  val_iterator = iter(val_loader) \n",
        "  \n",
        "  for x_rgb_batch, x_thermal_batch in rgb_thermal_load_images(x_rgb,x):\n",
        "    x_rgb_batch = x_rgb_batch.to(device)\n",
        "    x_thermal_batch = x_thermal_batch.to(device)\n",
        "    terms = model(x_rgb_batch, x_thermal_batch)\n",
        "    \n",
        "    if rapid_evaluation:\n",
        "      print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    else:\n",
        "      if not i % eval_counter:\n",
        "        print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    \n",
        "    optimizer.zero_grad() #Nawid - I think this makes the gradient become zero\n",
        "    terms['loss'].backward() # Nawid - Backpropagates the total loss term ( which is related to all the different components)\n",
        "    optimizer.step() # Nawid- Updates using optimizer\n",
        "    model.revive_dead_entries()\n",
        "    i +=1\n",
        "    \n",
        "    if not i % 50:\n",
        "      torch.save(model.state_dict(), VAE_PATH)\n",
        "      #save_reconstructions(x_rgb_batch, terms['reconstructions'][-1], x_thermal_batch,terms['reconstructions_thermal'][-1])\n",
        "      save_reconstructions(model,x_rgb_batch, x_thermal_batch) # Nawid - saves the reconstruction\n",
        "\n",
        "      val_rgb_batch,val_thermal_batch = next(val_iterator)\n",
        "      \n",
        "      if save_data:\n",
        "        val_total_loss, val_reconstruction_loss = validation_loss(model,val_rgb_batch,val_thermal_batch)\n",
        "        tensorboard_saving(i,terms['losses'][-1],val_reconstruction_loss, terms['loss'],val_total_loss)\n",
        "      else:\n",
        "        pass\n",
        "      save_reconstructions(model,val_rgb_batch, val_thermal_batch,'Val')\n",
        "\n",
        "\n",
        "def tensorboard_saving(iteration,recon_loss_train, recon_loss_val, total_loss_train,total_loss_val):\n",
        "  tb.save_value('Reconstruction_loss','Train loss', iteration, recon_loss_train)\n",
        "  tb.save_value('Reconstruction_loss','Validation loss', iteration, recon_loss_val)\n",
        "      \n",
        "  tb.save_value('Total_loss','Train loss', iteration, total_loss_train)\n",
        "  tb.save_value('Total_loss','Validation loss', iteration, total_loss_val)\n",
        " \n",
        "  tb.flush_line('Reconstruction_loss')\n",
        "  tb.flush_line('Total_loss')\n",
        "\n",
        "\n",
        "def validation_loss(vae,val_rgb, val_thermal):\n",
        "  vae.eval() # Nawid - Sets it into evaluation mode ( so dropout and batchnorm have different behaviours)\n",
        "  with torch.no_grad(): # Nawid-  Turns off the autograd engine which speeds up computation\n",
        "    val_terms = vae(val_rgb,val_thermal)\n",
        "    total_loss, reconstruction_loss = val_terms['loss'], val_terms['losses'][-1]\n",
        "    vae.train()\n",
        "    return total_loss, reconstruction_loss\n",
        "\n",
        "\n",
        "def save_reconstructions(vae,rgb_images, thermal_images,name = 'Train'):\n",
        "  vae.eval()\n",
        "  with torch.no_grad():\n",
        "    recons, recons_thermal = vae.full_reconstructions(rgb_images,thermal_images)\n",
        "    recons = [torch.clamp(x, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x in recons] # Nawid - Clamps all the different elements in recons\n",
        "    recons_thermal = [torch.clamp(x_thermal, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x_thermal in recons_thermal] # Nawid - Clamps all the different elements in recons_thermal\n",
        "    \n",
        "    vae.train() # Nawid - This sets the nn.module into training mode\n",
        "    top_recons, real_recons = recons # Nawid - I believe the top_recons is the reconstruction using only the top latent map, whilst real_recons is using both the top latent map and the bottom latent map\n",
        "    rgb_images = rgb_images.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "    columns = np.concatenate([top_recons, real_recons, rgb_images], axis=-2)\n",
        "    columns = np.concatenate(columns, axis=0)\n",
        "    Image.fromarray((columns * 255).astype('uint8')).save(name +'_reconstructions_rgb.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "    top_recons_thermal,real_recons_thermal = recons_thermal\n",
        "    thermal_images = thermal_images.permute(0,2,3,1).detach().cpu().numpy()\n",
        "    thermal_images = thermal_images.reshape(thermal_images.shape[0],thermal_images.shape[1],thermal_images.shape[2])\n",
        "\n",
        "    top_recons_thermal = top_recons_thermal.reshape(top_recons_thermal.shape[0],top_recons_thermal.shape[1],top_recons_thermal.shape[2])\n",
        "    real_recons_thermal = real_recons_thermal.reshape(real_recons_thermal.shape[0],real_recons_thermal.shape[1],real_recons_thermal.shape[2])\n",
        "\n",
        "    columns_thermal = np.concatenate([top_recons_thermal, real_recons_thermal,thermal_images], axis=-1) # Nawid - I need to concatenate along -2 when using rgb and -1 when using grayscale and when using  When using grayscale images, to save the files using PIL, i need to make to remove the channel and so there is one less axis to examine\n",
        "    columns_thermal = np.concatenate(columns_thermal, axis=0)\n",
        "    Image.fromarray((columns_thermal * 255).astype('uint8')).save(name +'_reconstructions_thermal.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LSkbpHZYgoH",
        "colab_type": "text"
      },
      "source": [
        "Original code - For when the images of the thermal and the RGB data was different"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZc11X2V9Yx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "  model = make_vae()\n",
        "  if os.path.exists(VAE_PATH):\n",
        "    model.load_state_dict(torch.load(VAE_PATH, map_location='cpu'))\n",
        "  model.to(device)\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  \n",
        "  # Nawid -Define the iterators for the validation data\n",
        "  val_rgb_loader = InfiniteDataLoader(val_x_rgb)\n",
        "  val_rgb_iterator = iter(val_rgb_loader)\n",
        "\n",
        "  val_thermal_loader = InfiniteDataLoader(val_x)\n",
        "  val_thermal_iterator = iter(val_thermal_loader)\n",
        "\n",
        "  i = 0\n",
        "  for x_rgb_batch, x_thermal_batch in zip(load_images(x_rgb), load_images(x)):\n",
        "    x_rgb_batch= x_rgb_batch.to(device)\n",
        "    x_thermal_batch =  x_thermal_batch.to(device)\n",
        "    terms = model(x_rgb_batch, x_thermal_batch)\n",
        "    \n",
        "    if rapid_evaluation:\n",
        "      print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    else:\n",
        "      if not i % eval_counter:\n",
        "        print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    \n",
        "    optimizer.zero_grad() #Nawid - I think this makes the gradient become zero\n",
        "    terms['loss'].backward() # Nawid - Backpropagates the total loss term ( which is related to all the different components)\n",
        "    optimizer.step() # Nawid- Updates using optimizer\n",
        "    model.revive_dead_entries()\n",
        "    i +=1\n",
        "    if not i % 50:\n",
        "      torch.save(model.state_dict(), VAE_PATH)\n",
        "      #save_reconstructions(x_rgb_batch, terms['reconstructions'][-1], x_thermal_batch,terms['reconstructions_thermal'][-1])\n",
        "      save_reconstructions(model,x_rgb_batch, x_thermal_batch) # Nawid - saves the reconstruction\n",
        "\n",
        "      val_rgb_batch = next(val_rgb_iterator)\n",
        "      val_thermal_batch = next(val_thermal_iterator)\n",
        "      val_total_loss, val_reconstruction_loss = validation_loss(model,val_rgb_batch,val_thermal_batch)\n",
        "      \n",
        "      tensorboard_saving(i,terms['losses'][-1],val_reconstruction_loss, terms['loss'],val_total_loss)\n",
        "      save_reconstructions(model,val_rgb_batch, val_thermal_batch,'Val')\n",
        "\n",
        "      '''\n",
        "      tb.save_value('Reconstruction_loss','Train loss', i, terms['losses'][-1])\n",
        "      tb.save_value('Reconstruction_loss','Validation loss', i, val_reconstruction_loss)\n",
        "      \n",
        "      tb.save_value('Total_loss','Train loss', i, terms['loss'])\n",
        "      tb.save_value('Total_loss','Validation loss', i, val_total_loss)\n",
        "      tb.flush_line('Reconstruction_loss')\n",
        "      tb.flush_line('Total_loss')\n",
        "      '''\n",
        "      \n",
        "\n",
        "def tensorboard_saving(iteration,recon_loss_train, recon_loss_val, total_loss_train,total_loss_val):\n",
        "  tb.save_value('Reconstruction_loss','Train loss', iteration, recon_loss_train)\n",
        "  tb.save_value('Reconstruction_loss','Validation loss', iteration, recon_loss_val)\n",
        "      \n",
        "  tb.save_value('Total_loss','Train loss', iteration, total_loss_train)\n",
        "  tb.save_value('Total_loss','Validation loss', iteration, total_loss_val)\n",
        " \n",
        "  tb.flush_line('Reconstruction_loss')\n",
        "  tb.flush_line('Total_loss')\n",
        "\n",
        "\n",
        "def validation_loss(vae,val_rgb, val_thermal):\n",
        "  vae.eval() # Nawid - Sets it into evaluation mode ( so dropout and batchnorm have different behaviours)\n",
        "  with torch.no_grad(): # Nawid-  Turns off the autograd engine which speeds up computation\n",
        "    val_terms = vae(val_rgb,val_thermal)\n",
        "    total_loss, reconstruction_loss = val_terms['loss'], val_terms['losses'][-1]\n",
        "    return total_loss, reconstruction_loss\n",
        "\n",
        "\n",
        "def save_reconstructions(vae,rgb_images, thermal_images,name = 'Train'):\n",
        "  vae.eval()\n",
        "  with torch.no_grad():\n",
        "    recons, recons_thermal = vae.full_reconstructions(rgb_images,thermal_images)\n",
        "    recons = [torch.clamp(x, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x in recons] # Nawid - Clamps all the different elements in recons\n",
        "    recons_thermal = [torch.clamp(x_thermal, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x_thermal in recons_thermal] # Nawid - Clamps all the different elements in recons_thermal\n",
        "    \n",
        "    vae.train() # Nawid - This sets the nn.module into training mode\n",
        "    top_recons, real_recons = recons # Nawid - I believe the top_recons is the reconstruction using only the top latent map, whilst real_recons is using both the top latent map and the bottom latent map\n",
        "    rgb_images = rgb_images.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "    columns = np.concatenate([top_recons, real_recons, rgb_images], axis=-2)\n",
        "    columns = np.concatenate(columns, axis=0)\n",
        "    Image.fromarray((columns * 255).astype('uint8')).save(name +'_reconstructions_rgb.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "    top_recons_thermal,real_recons_thermal = recons_thermal\n",
        "    thermal_images = thermal_images.permute(0,2,3,1).detach().cpu().numpy()\n",
        "    thermal_images = thermal_images.reshape(thermal_images.shape[0],thermal_images.shape[1],thermal_images.shape[2])\n",
        "\n",
        "    top_recons_thermal = top_recons_thermal.reshape(top_recons_thermal.shape[0],top_recons_thermal.shape[1],top_recons_thermal.shape[2])\n",
        "    real_recons_thermal = real_recons_thermal.reshape(real_recons_thermal.shape[0],real_recons_thermal.shape[1],real_recons_thermal.shape[2])\n",
        "\n",
        "    columns_thermal = np.concatenate([top_recons_thermal, real_recons_thermal,thermal_images], axis=-1) # Nawid - I need to concatenate along -2 when using rgb and -1 when using grayscale and when using  When using grayscale images, to save the files using PIL, i need to make to remove the channel and so there is one less axis to examine\n",
        "    columns_thermal = np.concatenate(columns_thermal, axis=0)\n",
        "    Image.fromarray((columns_thermal * 255).astype('uint8')).save(name +'_reconstructions_thermal.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNn1Ag_g5y6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_images(input_x): # Nawid - Loads images\n",
        "    while True:\n",
        "        for data in create_data_loader(input_x):\n",
        "          #data = data.float()/255 # Nawid - Divides by 255 \n",
        "          data = data.permute(0, 3, 1, 2).contiguous() # Nawid - Changes into pytorch ordering\n",
        "          yield data\n",
        "       \n",
        "def create_data_loader(input_x): # Nawid - Creates a dataloader object\n",
        "    return torch.utils.data.DataLoader(input_x, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# https://gist.github.com/MFreidank/821cc87b012c53fade03b0c7aba13958\n",
        "class InfiniteDataLoader(DataLoader): \n",
        "  def __init__(self,input_x, batch_size=BATCH_SIZE, shuffle=True):\n",
        "    super().__init__(input_x, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    #Initialise an iterator over the dataset\n",
        "    self.dataset_iterator = super().__iter__()\n",
        "\n",
        "  def __iter__(self):\n",
        "    return self\n",
        "\n",
        "  def __next__(self):\n",
        "    try:\n",
        "      batch = next(self.dataset_iterator)\n",
        "\n",
        "    except StopIteration:\n",
        "      # Dataset exhausted, use a new fresh iterator\n",
        "      self.dataset_iterator = super().__iter__()\n",
        "      batch = next(self.dataset_iterator)\n",
        "    batch = batch.permute(0, 3, 1, 2).contiguous() # Nawid- Added this to change the channels\n",
        "    return batch.to(device) # Nawid - Add to the device directly\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}