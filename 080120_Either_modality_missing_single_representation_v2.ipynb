{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "080120_Either_modality_missing_single_representation_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nerdk312/Multimodal_VQ-VAE/blob/master/080120_Either_modality_missing_single_representation_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP252uER8Mj4",
        "colab_type": "code",
        "outputId": "8468b61d-fd78-4ac1-9597-2e8902ed0a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEdPl_3i8i3z",
        "colab_type": "code",
        "outputId": "e322169d-8c5b-40bc-f72e-4e87cedacdf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# Nawid - Updates the path to import from drive\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/vq-vae-2-master-Single_representation_V4')\n",
        "\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "from keras.preprocessing import image as image_utils\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from tensorboardcolab import TensorBoardColab\n",
        "from torch.utils.data import DataLoader\n",
        "import random\n",
        "\n",
        "# Nawid - Used to get the current time and date which I will use the save the data in a folder\n",
        "from datetime import datetime\n",
        "\n",
        "from vq_vae_2.examples.hierarchical_combined.model import make_vae\n",
        "target_size = (64,64)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R73VF2pBwTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def common_images(RGB_dir,Thermal_dir):\n",
        "  RGB_image_list = os.listdir(RGB_dir)\n",
        "  Thermal_image_list = os.listdir(Thermal_dir)\n",
        "\n",
        "  truncated_RGB_image_list = [RGB_image_name.strip('.jpg') for RGB_image_name in RGB_image_list]\n",
        "  truncated_Thermal_image_list = [Thermal_image_name.strip('.jpeg') for Thermal_image_name in Thermal_image_list]\n",
        "\n",
        "  common_list = set(truncated_RGB_image_list).intersection(truncated_Thermal_image_list)\n",
        "  common_list = sorted(common_list) # Nawid - Sorts all the items in a list\n",
        "  return common_list\n",
        "\n",
        "RGB_inp_dir = '/content/gdrive/My Drive/RGB'\n",
        "Thermal_inp_dir = '/content/gdrive/My Drive/thermal_8_bit'\n",
        "train_list = common_images(RGB_inp_dir,Thermal_inp_dir) \n",
        "\n",
        "val_RGB_inp_dir = '/content/gdrive/My Drive/Val_RGB'\n",
        "val_Thermal_inp_dir = '/content/gdrive/My Drive/Val_thermal_8_bit'\n",
        "val_list = common_images(val_RGB_inp_dir,val_Thermal_inp_dir)\n",
        "\n",
        "def processing_saving_images(modality,quick_test=True,Train_required=False,Val_required=True):\n",
        "  all_images = []\n",
        "  val_all_images = []\n",
        "  \n",
        "  if modality == 'RGB_':\n",
        "    suffix = '.jpg'\n",
        "    channels = 3\n",
        "    inp_dir = '/content/gdrive/My Drive/RGB'\n",
        "    val_inp_dir = '/content/gdrive/My Drive/Val_RGB'\n",
        "  \n",
        "  elif modality == 'Thermal_':\n",
        "    suffix = '.jpeg'\n",
        "    channels = 1\n",
        "    inp_dir = '/content/gdrive/My Drive/thermal_8_bit'\n",
        "    val_inp_dir = '/content/gdrive/My Drive/Val_thermal_8_bit'\n",
        "  \n",
        "  else:\n",
        "    return('Incorrect Modality name')\n",
        "\n",
        "  if quick_test:\n",
        "    if Train_required:\n",
        "      for i, img_name in enumerate(train_list):\n",
        "        if i< 10:\n",
        "          fname = inp_dir + '/' + img_name + suffix\n",
        "          if modality == 'RGB_':\n",
        "            image = image_utils.load_img(fname).resize(target_size,Image.ANTIALIAS)\n",
        "          else:\n",
        "            image = image_utils.load_img(fname,color_mode='grayscale').resize(target_size,Image.ANTIALIAS)\n",
        "          image = np.array(image.getdata()).reshape(target_size[0], target_size[1], channels)\n",
        "          image = image.astype('float32')/255 \n",
        "          all_images.append(image)\n",
        "        else:\n",
        "          pass\n",
        "    else:\n",
        "      pass\n",
        "    \n",
        "    if Val_required:\n",
        "      for j, img_name in enumerate(val_list):\n",
        "        if j < 10:\n",
        "          fname = val_inp_dir + '/' + img_name + suffix\n",
        "          if modality == 'RGB_':\n",
        "            image = image_utils.load_img(fname).resize(target_size,Image.ANTIALIAS)\n",
        "          else:\n",
        "            image = image_utils.load_img(fname,color_mode='grayscale').resize(target_size,Image.ANTIALIAS)\n",
        "          \n",
        "          image = np.array(image.getdata()).reshape(target_size[0], target_size[1], channels)\n",
        "          image = image.astype('float32')/255 \n",
        "          val_all_images.append(image)\n",
        "        else: \n",
        "          pass \n",
        "    else:\n",
        "      pass\n",
        "\n",
        "  else:\n",
        "    if Train_required:\n",
        "      for i, img_name in enumerate(train_list):\n",
        "        fname = inp_dir + '/' + img_name + suffix\n",
        "        if modality == 'RGB_':\n",
        "          image = image_utils.load_img(fname).resize(target_size,Image.ANTIALIAS)\n",
        "        else:\n",
        "          image = image_utils.load_img(fname,color_mode='grayscale').resize(target_size,Image.ANTIALIAS)\n",
        "        image = np.array(image.getdata()).reshape(target_size[0], target_size[1],channels)\n",
        "        image = image.astype('float32')/255\n",
        "        all_images.append(image)\n",
        "        if not i%100:\n",
        "          print(i)\n",
        "        else: \n",
        "          pass\n",
        "    else:\n",
        "      pass\n",
        "  \n",
        "    if Val_required:\n",
        "      for j, img_name in enumerate(val_list):\n",
        "        fname = val_inp_dir + '/' + img_name + suffix\n",
        "        if modality == 'RGB_':\n",
        "          image = image_utils.load_img(fname).resize(target_size,Image.ANTIALIAS)\n",
        "        else:\n",
        "          image = image_utils.load_img(fname,color_mode='grayscale').resize(target_size,Image.ANTIALIAS)\n",
        "        image = np.array(image.getdata()).reshape(target_size[0], target_size[1],channels)\n",
        "        image = image.astype('float32')/255\n",
        "        val_all_images.append(image)\n",
        "        if not j%100:\n",
        "          print(j)\n",
        "        else: \n",
        "          pass\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "  if Train_required: \n",
        "    np.save(modality +str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy',all_images)\n",
        "\n",
        "  if Val_required:\n",
        "    np.save('Val_'+modality +str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy',val_all_images)\n",
        "\n",
        "\n",
        "rgb_modality = 'RGB_'\n",
        "thermal_modality = 'Thermal_'\n",
        "\n",
        "processing_saving_images(thermal_modality,quick_test=False,Train_required=False,Val_required=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsUjLwHf9FP9",
        "colab_type": "text"
      },
      "source": [
        "# Uploading from drive directly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kkaWdar9Ib-",
        "colab_type": "code",
        "outputId": "ff19d620-b5c8-4c42-87c1-4a39fa9cfe90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "upload_directly = True\n",
        "if upload_directly:\n",
        "  x_rgb = np.load('/content/gdrive/My Drive/RGB_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  val_x_rgb = np.load('/content/gdrive/My Drive/Val_RGB_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  x = np.load('/content/gdrive/My Drive/Thermal_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  val_x = np.load('/content/gdrive/My Drive/Val_Thermal_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "else:\n",
        "  x_rgb = np.load('/content/RGB_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  val_x_rgb = np.load('/content/Val_RGB_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  x = np.load('/content/Thermal_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "  val_x = np.load('/content/Val_Thermal_'+str(target_size[0]) + 'x' + str(target_size[1]) + '_images.npy')\n",
        "\n",
        "#val_x = val_x[:len(val_x_rgb)] # Nawid - Make into the same size as the limiting case\n",
        "print(x_rgb.shape)\n",
        "print(val_x_rgb.shape)\n",
        "print(x.shape)\n",
        "print(val_x.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8363, 64, 64, 3)\n",
            "(1257, 64, 64, 3)\n",
            "(8363, 64, 64, 1)\n",
            "(1257, 64, 64, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yft7Ami9Vbs",
        "colab_type": "text"
      },
      "source": [
        "# Model config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLXuKr8u9WZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "log_interval = 50\n",
        "rapid_evaluation = False\n",
        "eval_counter = 50\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
        "#VAE_PATH_SAVE = 'vae.pt'\n",
        "#VAE_PATH = 'vae.pt'\n",
        "#VAE_PATH = '/content/gdrive/My Drive/vae_cycle1_training.pt'\n",
        "# Nawid - Used to ensure the results are reproducible - https://pytorch.org/docs/stable/notes/randomness.html\n",
        "\n",
        "reproducible = False\n",
        "seed_value = 0\n",
        "if reproducible:\n",
        "  torch.manual_seed(seed_value)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  np.random.seed(seed_value)\n",
        "\n",
        "#missing_threshold = 0.3\n",
        "\n",
        "save_data = False\n",
        "if save_data:\n",
        "  tb = TensorBoardColab() # Nawid - Creates a tensorboard link "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4333NUk15zou",
        "colab_type": "text"
      },
      "source": [
        "# Data loader functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsMoW1pHROZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConcatDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, *datasets):\n",
        "        self.datasets = datasets\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return tuple(d[i] for d in self.datasets)\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(d) for d in self.datasets)\n",
        "\n",
        "def rgb_thermal_data_loader(input_rgb,input_thermal): # Nawid - Creates a dataloader object\n",
        "    return torch.utils.data.DataLoader(ConcatDataset(input_rgb,input_thermal),batch_size=BATCH_SIZE, shuffle = True)\n",
        "\n",
        "def rgb_thermal_load_images(input_rgb, input_thermal): # Nawid - Loads images\n",
        "    while True:\n",
        "        for (rgb_data,thermal_data) in rgb_thermal_data_loader(input_rgb,input_thermal):\n",
        "          #data = data.float()/255 # Nawid - Divides by 255 \n",
        "          rgb_data = rgb_data.permute(0, 3, 1, 2).contiguous() # Nawid - Changes into pytorch ordering\n",
        "          thermal_data = thermal_data.permute(0, 3, 1, 2).contiguous()\n",
        "          yield rgb_data, thermal_data\n",
        "\n",
        "# https://gist.github.com/MFreidank/821cc87b012c53fade03b0c7aba13958\n",
        "class InfiniteDataLoader(DataLoader): \n",
        "  def __init__(self,input_rgb,input_thermal, batch_size=BATCH_SIZE, shuffle=True):\n",
        "    super().__init__(ConcatDataset(input_rgb,input_thermal), batch_size=BATCH_SIZE, shuffle=True) # Nawid - Instantiates the dataloader subclass using a concatenated input\n",
        "\n",
        "    #Initialise an iterator over the dataset\n",
        "    self.dataset_iterator = super().__iter__()\n",
        "\n",
        "  def __iter__(self):\n",
        "    return self\n",
        "\n",
        "  def __next__(self,Missing= False, Missing_modality =None): # Nawid - Added the Missing term here\n",
        "    try:\n",
        "      batch = next(self.dataset_iterator)\n",
        "      \n",
        "    except StopIteration:\n",
        "      # Dataset exhausted, use a new fresh iterator\n",
        "      self.dataset_iterator = super().__iter__()\n",
        "      batch = next(self.dataset_iterator)\n",
        "\n",
        "    rgb_batch, thermal_batch = batch[0], batch[1] # Nawid- Obtains the different values in the batch\n",
        "    rgb_batch = rgb_batch.permute(0, 3, 1, 2).contiguous() # Nawid- Added this to change the channels\n",
        "    thermal_batch = thermal_batch.permute(0, 3, 1, 2).contiguous()\n",
        "    \n",
        "    if Missing:\n",
        "      if Missing_modality == 'Thermal':  \n",
        "        target_modality = thermal_batch\n",
        "        thermal_batch = thermal_batch.new_full((thermal_batch.size()),-1) # Nawid - Missing thermal data\n",
        "      elif Missing_modality == 'RGB':\n",
        "        target_modality = rgb_batch\n",
        "        rgb_batch = rgb_batch.new_full((rgb_batch.size()),-1) # Nawid - Missing RGB data\n",
        "      return rgb_batch.to(device), thermal_batch.to(device), target_modality.to(device) # Nawid - outputs the rgb data, thermal data which is missing and the original thermal data(target)\n",
        "    else:\n",
        "      return rgb_batch.to(device), thermal_batch.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDpfwkbJ6L04",
        "colab_type": "text"
      },
      "source": [
        "# Main - Training and reconstructions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUEtUcYSIwpK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "daa821b5-98e1-40e8-c40d-bb6d94a5449b"
      },
      "source": [
        "'''\n",
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%d%m%Y_%H:%M:%S\")\n",
        "path = 'Data_'+dt_string\n",
        "os.mkdir(path)\n",
        "'''\n",
        "\n",
        "def training_phase(phase_number):\n",
        "  if phase ==1:\n",
        "    VAE_PATH = path + '/' +'vae.pt'\n",
        "    VAE_PATH_SAVE = path + '/' +'vae.pt'\n",
        "    missing = False\n",
        "    missing_modality = None\n",
        "  elif phase ==2:\n",
        "    VAE_PATH = '/content/gdrive/My Drive/vae_cycle1_training.pt'\n",
        "    VAE_PATH_SAVE = path + '/' +'vae.pt'\n",
        "    missing = True\n",
        "    missing_modality = 'Thermal'\n",
        "  elif phase ==3:\n",
        "    VAE_PATH = '/content/gdrive/My Drive/vae_cycle1_training.pt'\n",
        "    VAE_PATH_SAVE = path + '/' +'vae.pt'\n",
        "    missing =True\n",
        "    missing_modality = 'RGB'\n",
        "  elif phase ==4:\n",
        "    VAE_PATH = path + '/' +'vae.pt'\n",
        "    VAE_PATH_SAVE = path + '/' +'vae.pt'\n",
        "    missing = True\n",
        "    missing_modality = 'Thermal'\n",
        "  elif phase ==5:\n",
        "    VAE_PATH = path + '/' +'vae.pt'\n",
        "    VAE_PATH_SAVE = path + '/' +'vae.pt'\n",
        "    missing = True\n",
        "    missing_modality = 'RGB'\n",
        "  return VAE_PATH, VAE_PATH_SAVE, missing, missing_modality\n",
        "\n",
        "def missing_modality_output(modal_input):\n",
        "  target = modal_input\n",
        "  missing_modal_output = modal_input.new_full((modal_input.size()),-1)\n",
        "  return missing_modal_output, target\n",
        "\n",
        "phase = 3\n",
        "\n",
        "def main():\n",
        "  # Nawid - Conditions for the training\n",
        "  VAE_PATH, VAE_PATH_SAVE, missing, missing_modality = training_phase(phase)\n",
        "\n",
        "  model = make_vae()\n",
        "  if os.path.exists(VAE_PATH):\n",
        "    model.load_state_dict(torch.load(VAE_PATH, map_location='cpu'))\n",
        "  model.to(device)\n",
        "  optimizer = optim.Adam(model.parameters(),1e-4) \n",
        "  \n",
        "  # Nawid - Validation iterator\n",
        "  val_loader = InfiniteDataLoader(x_rgb,x)\n",
        "  val_iterator = iter(val_loader) \n",
        "\n",
        "  # Nawid - Initial condition for the iterator\n",
        "  #missing = True # Nawid - Initially set to true\n",
        "  #missing_modality = 'RGB'\n",
        "  missing_threshold = 1.0 if missing is False else 0.0\n",
        "\n",
        "  i = 0\n",
        "  for x_rgb_batch, x_thermal_batch in rgb_thermal_load_images(x_rgb,x): # Nawid - Obtains the minibatch and the thermal target for the case when the modality is missing\n",
        "    x_rgb_batch = x_rgb_batch.to(device)\n",
        "    x_thermal_batch = x_thermal_batch.to(device)\n",
        "    \n",
        "    if missing: # Nawid - If missing, then need to input the missing modality as well as the target value\n",
        "      if missing_modality == \"Thermal\":\n",
        "        x_thermal_batch,target = missing_modality_output(x_thermal_batch)\n",
        "        terms = model(x_rgb_batch, x_thermal_batch,target_thermal = target)\n",
        "      elif missing_modality == \"RGB\":\n",
        "        x_rgb_batch, target = missing_modality_output(x_rgb_batch)\n",
        "        terms = model(x_rgb_batch, x_thermal_batch,target_rgb = target)\n",
        "    else: # Nawid - If the modality is not missing, then only need to input the rgb and thermal images\n",
        "      terms = model(x_rgb_batch, x_thermal_batch)\n",
        "\n",
        "    # Nawid -Sets the value for missing for the next iteration by checking if the random value is above a certain threshold\n",
        "    random_value = random.random()\n",
        "    if random_value > missing_threshold:\n",
        "      missing = True\n",
        "    else:\n",
        "      missing = False\n",
        "    \n",
        "    if rapid_evaluation:\n",
        "      print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    else:\n",
        "      if not i % eval_counter:\n",
        "        print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    \n",
        "    optimizer.zero_grad() #Nawid - I think this makes the gradient become zero\n",
        "    terms['loss'].backward() # Nawid - Backpropagates the total loss term ( which is related to all the different components)\n",
        "    optimizer.step() # Nawid- Updates using optimizer\n",
        "    model.revive_dead_entries()\n",
        "    i +=1\n",
        "    #missing_threshold -=0.01 \n",
        "\n",
        "    if i == 100:\n",
        "      for g in optimizer.param_groups:\n",
        "        g['lr'] = 1e-3\n",
        "\n",
        "    if not i % 50:\n",
        "      torch.save(model.state_dict(), VAE_PATH_SAVE)\n",
        "      \n",
        "      #save_reconstructions(x_rgb_batch, terms['reconstructions'][-1], x_thermal_batch,terms['reconstructions_thermal'][-1])\n",
        "      if missing: # Nawid-  Saves the reconstruction when there is or isn't a modality change.\n",
        "        if missing_modality == 'Thermal':\n",
        "          save_reconstructions(model, x_rgb_batch,x_thermal_batch,target_thermal=target)\n",
        "          val_rgb_batch,val_thermal_batch, val_target = val_iterator.__next__(Missing=missing,Missing_modality = missing_modality)\n",
        "          save_reconstructions(model, val_rgb_batch,val_thermal_batch,target_thermal = val_target, name= 'Val')\n",
        "        elif missing_modality == 'RGB':\n",
        "          save_reconstructions(model, x_rgb_batch,x_thermal_batch, target_rgb = target)\n",
        "          val_rgb_batch,val_thermal_batch, val_target = val_iterator.__next__(Missing=missing, Missing_modality = missing_modality)\n",
        "          save_reconstructions(model, val_rgb_batch,val_thermal_batch,target_rgb = val_target, name= 'Val')\n",
        "      else:\n",
        "        save_reconstructions(model,x_rgb_batch, x_thermal_batch)\n",
        "        '''\n",
        "        #val_rgb_batch,val_thermal_batch = next(val_iterator)\n",
        "        val_rgb_batch, val_thermal_batch = val_iterator.__next__(missing)\n",
        "        val_total_loss, val_reconstruction_loss = validation_loss(model,val_rgb_batch,val_thermal_batch) # Nawid - Calculates the loss in the validation set\n",
        "        save_reconstructions(model,val_rgb_batch, val_thermal_batch, name = 'Val') # Nawid - Need to specify as name as otherwise it would specify target thermal\n",
        "        '''\n",
        "      '''\n",
        "      # Nawid - Updates model only if the validation loss is less\n",
        "      if val_total_loss < minimum_val_total_loss:\n",
        "        previous_val_total_loss = val_total_loss\n",
        "        torch.save(model.state_dict(), VAE_PATH_SAVE)\n",
        "      '''\n",
        "      '''\n",
        "      val_rgb_batch,val_thermal_batch = next(val_iterator)      \n",
        "      if save_data:\n",
        "        val_total_loss, val_reconstruction_loss = validation_loss(model,val_rgb_batch,val_thermal_batch)\n",
        "        tensorboard_saving(i,terms['losses'][-1],val_reconstruction_loss, terms['loss'],val_total_loss)\n",
        "      else:\n",
        "        pass\n",
        "      save_reconstructions(model,val_rgb_batch, val_thermal_batch,'Val')\n",
        "      '''\n",
        "\n",
        "def tensorboard_saving(iteration,recon_loss_train, recon_loss_val, total_loss_train,total_loss_val):\n",
        "  tb.save_value('Reconstruction_loss','Train loss', iteration, recon_loss_train)\n",
        "  tb.save_value('Reconstruction_loss','Validation loss', iteration, recon_loss_val)\n",
        "      \n",
        "  tb.save_value('Total_loss','Train loss', iteration, total_loss_train)\n",
        "  tb.save_value('Total_loss','Validation loss', iteration, total_loss_val)\n",
        " \n",
        "  tb.flush_line('Reconstruction_loss')\n",
        "  tb.flush_line('Total_loss')\n",
        "\n",
        "def validation_loss(vae,val_rgb, val_thermal):\n",
        "  vae.eval() # Nawid - Sets it into evaluation mode ( so dropout and batchnorm have different behaviours)\n",
        "  with torch.no_grad(): # Nawid-  Turns off the autograd engine which speeds up computation\n",
        "    val_terms = vae(val_rgb,val_thermal)\n",
        "    total_loss, reconstruction_loss = val_terms['loss'], val_terms['losses'][-1]\n",
        "    vae.train()\n",
        "    return total_loss, reconstruction_loss\n",
        "\n",
        "def save_reconstructions(vae,rgb_images,thermal_images,target_rgb = None,target_thermal = None, name = 'Train'):\n",
        "  vae.eval()\n",
        "  with torch.no_grad():\n",
        "    recons, recons_thermal = vae.full_reconstructions(rgb_images,thermal_images)\n",
        "    recons = [torch.clamp(x, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x in recons] # Nawid - Clamps all the different elements in recons\n",
        "    recons_thermal = [torch.clamp(x_thermal, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x_thermal in recons_thermal] # Nawid - Clamps all the different elements in recons_thermal\n",
        "    \n",
        "    vae.train() # Nawid - This sets the nn.module into training mode\n",
        "    top_recons, real_recons = recons # Nawid - I believe the top_recons is the reconstruction using only the top latent map, whilst real_recons is using both the top latent map and the bottom latent map\n",
        "    target_rgb = rgb_images if target_rgb is None else target_rgb\n",
        "    target_rgb = target_rgb.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "    #rgb_images = rgb_images.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "    \n",
        "    columns = np.concatenate([top_recons, real_recons, target_rgb], axis=-2)\n",
        "    columns = np.concatenate(columns, axis=0)\n",
        "    Image.fromarray((columns * 255).astype('uint8')).save(path+'/'+name +'_reconstructions_rgb.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "    top_recons_thermal,real_recons_thermal = recons_thermal\n",
        "    \n",
        "    target_thermal = thermal_images if target_thermal is None else target_thermal # Nawid- Sets the value for target_thermal to input_thermal if target_thermal is none. else it is the value that I input\n",
        "    target_thermal = target_thermal.permute(0,2,3,1).detach().cpu().numpy()\n",
        "    target_thermal = target_thermal.reshape(target_thermal.shape[0],target_thermal.shape[1],target_thermal.shape[2])\n",
        "    \n",
        "    #thermal_images = thermal_images.permute(0,2,3,1).detach().cpu().numpy()\n",
        "    #thermal_images = thermal_images.reshape(thermal_images.shape[0],thermal_images.shape[1],thermal_images.shape[2])\n",
        "    #target_thermal = thermal_images if target_thermal is None else target_thermal # Nawid- Sets the value for target_thermal to input_thermal if target_thermal is none. else it is the value that I input\n",
        "    \n",
        "    top_recons_thermal = top_recons_thermal.reshape(top_recons_thermal.shape[0],top_recons_thermal.shape[1],top_recons_thermal.shape[2])\n",
        "    real_recons_thermal = real_recons_thermal.reshape(real_recons_thermal.shape[0],real_recons_thermal.shape[1],real_recons_thermal.shape[2])\n",
        "\n",
        "    columns_thermal = np.concatenate([top_recons_thermal, real_recons_thermal,target_thermal], axis=-1) # Nawid - I need to concatenate along -2 when using rgb and -1 when using grayscale and when using  When using grayscale images, to save the files using PIL, i need to make to remove the channel and so there is one less axis to examine\n",
        "    columns_thermal = np.concatenate(columns_thermal, axis=0)\n",
        "    Image.fromarray((columns_thermal * 255).astype('uint8')).save(path+'/'+ name +'_reconstructions_thermal.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "main()   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0: mse=0.092027 mse_top=1.364489\n",
            "step 50: mse=0.045607 mse_top=0.208173\n",
            "step 100: mse=0.127301 mse_top=0.133889\n",
            "step 150: mse=0.043753 mse_top=0.040358\n",
            "step 200: mse=0.041202 mse_top=0.009111\n",
            "step 250: mse=0.032395 mse_top=0.010733\n",
            "step 300: mse=0.024162 mse_top=0.005491\n",
            "step 350: mse=0.022760 mse_top=0.005113\n",
            "step 400: mse=0.023225 mse_top=0.007922\n",
            "step 450: mse=0.035668 mse_top=0.061134\n",
            "step 500: mse=0.030251 mse_top=0.004966\n",
            "step 550: mse=0.023308 mse_top=0.004631\n",
            "step 600: mse=0.019267 mse_top=0.004495\n",
            "step 650: mse=0.024768 mse_top=0.003552\n",
            "step 700: mse=0.018384 mse_top=0.003775\n",
            "step 750: mse=0.019897 mse_top=0.003887\n",
            "step 800: mse=0.017402 mse_top=0.003744\n",
            "step 850: mse=0.018107 mse_top=0.003766\n",
            "step 900: mse=0.025830 mse_top=0.004703\n",
            "step 950: mse=0.026515 mse_top=0.004610\n",
            "step 1000: mse=0.017731 mse_top=0.003735\n",
            "step 1050: mse=0.017807 mse_top=0.003603\n",
            "step 1100: mse=0.016619 mse_top=0.003727\n",
            "step 1150: mse=0.018054 mse_top=0.004951\n",
            "step 1200: mse=0.020232 mse_top=0.003733\n",
            "step 1250: mse=0.016083 mse_top=0.003482\n",
            "step 1300: mse=0.017449 mse_top=0.003288\n",
            "step 1350: mse=0.019034 mse_top=0.004398\n",
            "step 1400: mse=0.016639 mse_top=0.004083\n",
            "step 1450: mse=0.017039 mse_top=0.003524\n",
            "step 1500: mse=0.017307 mse_top=0.002836\n",
            "step 1550: mse=0.018440 mse_top=0.003533\n",
            "step 1600: mse=0.015559 mse_top=0.003176\n",
            "step 1650: mse=0.016927 mse_top=0.003607\n",
            "step 1700: mse=0.013327 mse_top=0.002804\n",
            "step 1750: mse=0.017867 mse_top=0.003525\n",
            "step 1800: mse=0.013633 mse_top=0.003249\n",
            "step 1850: mse=0.017594 mse_top=0.002390\n",
            "step 1900: mse=0.017520 mse_top=0.003566\n",
            "step 1950: mse=0.016847 mse_top=0.003115\n",
            "step 2000: mse=0.014809 mse_top=0.002722\n",
            "step 2050: mse=0.012934 mse_top=0.002647\n",
            "step 2100: mse=0.015612 mse_top=0.003729\n",
            "step 2150: mse=0.016695 mse_top=0.002332\n",
            "step 2200: mse=0.015079 mse_top=0.002293\n",
            "step 2250: mse=0.017572 mse_top=0.003039\n",
            "step 2300: mse=0.012921 mse_top=0.003264\n",
            "step 2350: mse=0.013420 mse_top=0.002760\n",
            "step 2400: mse=0.014349 mse_top=0.002825\n",
            "step 2450: mse=0.013208 mse_top=0.002438\n",
            "step 2500: mse=0.015902 mse_top=0.002713\n",
            "step 2550: mse=0.013513 mse_top=0.002639\n",
            "step 2600: mse=0.013913 mse_top=0.001993\n",
            "step 2650: mse=0.013152 mse_top=0.002060\n",
            "step 2700: mse=0.013448 mse_top=0.002176\n",
            "step 2750: mse=0.015192 mse_top=0.002502\n",
            "step 2800: mse=0.013556 mse_top=0.002842\n",
            "step 2850: mse=0.015043 mse_top=0.002429\n",
            "step 2900: mse=0.012325 mse_top=0.002616\n",
            "step 2950: mse=0.014147 mse_top=0.002270\n",
            "step 3000: mse=0.013089 mse_top=0.002601\n",
            "step 3050: mse=0.012429 mse_top=0.002460\n",
            "step 3100: mse=0.011830 mse_top=0.002455\n",
            "step 3150: mse=0.011779 mse_top=0.002192\n",
            "step 3200: mse=0.015342 mse_top=0.002545\n",
            "step 3250: mse=0.011812 mse_top=0.002122\n",
            "step 3300: mse=0.012667 mse_top=0.002450\n",
            "step 3350: mse=0.013646 mse_top=0.002446\n",
            "step 3400: mse=0.010996 mse_top=0.002143\n",
            "step 3450: mse=0.011215 mse_top=0.002267\n",
            "step 3500: mse=0.011954 mse_top=0.002028\n",
            "step 3550: mse=0.012225 mse_top=0.002399\n",
            "step 3600: mse=0.011490 mse_top=0.002155\n",
            "step 3650: mse=0.012239 mse_top=0.002270\n",
            "step 3700: mse=0.012932 mse_top=0.002341\n",
            "step 3750: mse=0.012269 mse_top=0.001882\n",
            "step 3800: mse=0.011489 mse_top=0.002034\n",
            "step 3850: mse=0.011527 mse_top=0.002507\n",
            "step 3900: mse=0.010989 mse_top=0.002315\n",
            "step 3950: mse=0.012994 mse_top=0.002188\n",
            "step 4000: mse=0.010523 mse_top=0.002057\n",
            "step 4050: mse=0.010351 mse_top=0.002071\n",
            "step 4100: mse=0.010596 mse_top=0.001933\n",
            "step 4150: mse=0.009273 mse_top=0.002184\n",
            "step 4200: mse=0.010626 mse_top=0.001855\n",
            "step 4250: mse=0.010495 mse_top=0.002003\n",
            "step 4300: mse=0.010193 mse_top=0.002303\n",
            "step 4350: mse=0.011229 mse_top=0.002393\n",
            "step 4400: mse=0.010436 mse_top=0.002102\n",
            "step 4450: mse=0.010261 mse_top=0.001936\n",
            "step 4500: mse=0.011725 mse_top=0.002230\n",
            "step 4550: mse=0.010891 mse_top=0.002065\n",
            "step 4600: mse=0.010917 mse_top=0.002245\n",
            "step 4650: mse=0.014293 mse_top=0.001976\n",
            "step 4700: mse=0.011464 mse_top=0.001675\n",
            "step 4750: mse=0.012214 mse_top=0.001964\n",
            "step 4800: mse=0.010946 mse_top=0.001745\n",
            "step 4850: mse=0.009954 mse_top=0.002152\n",
            "step 4900: mse=0.009916 mse_top=0.002523\n",
            "step 4950: mse=0.012383 mse_top=0.001823\n",
            "step 5000: mse=0.008393 mse_top=0.001865\n",
            "step 5050: mse=0.009347 mse_top=0.001979\n",
            "step 5100: mse=0.008526 mse_top=0.001586\n",
            "step 5150: mse=0.010938 mse_top=0.002075\n",
            "step 5200: mse=0.012194 mse_top=0.002283\n",
            "step 5250: mse=0.008577 mse_top=0.001662\n",
            "step 5300: mse=0.008576 mse_top=0.001630\n",
            "step 5350: mse=0.009406 mse_top=0.002181\n",
            "step 5400: mse=0.010671 mse_top=0.001795\n",
            "step 5450: mse=0.012065 mse_top=0.001872\n",
            "step 5500: mse=0.010972 mse_top=0.002175\n",
            "step 5550: mse=0.009462 mse_top=0.001785\n",
            "step 5600: mse=0.009169 mse_top=0.002061\n",
            "step 5650: mse=0.008386 mse_top=0.002109\n",
            "step 5700: mse=0.009822 mse_top=0.002321\n",
            "step 5750: mse=0.010376 mse_top=0.002182\n",
            "step 5800: mse=0.009111 mse_top=0.002042\n",
            "step 5850: mse=0.010857 mse_top=0.002311\n",
            "step 5900: mse=0.009863 mse_top=0.002384\n",
            "step 5950: mse=0.010163 mse_top=0.001932\n",
            "step 6000: mse=0.013202 mse_top=0.002123\n",
            "step 6050: mse=0.009185 mse_top=0.001999\n",
            "step 6100: mse=0.009472 mse_top=0.001597\n",
            "step 6150: mse=0.009317 mse_top=0.002019\n",
            "step 6200: mse=0.008798 mse_top=0.001783\n",
            "step 6250: mse=0.009947 mse_top=0.001932\n",
            "step 6300: mse=0.009387 mse_top=0.002133\n",
            "step 6350: mse=0.008139 mse_top=0.001823\n",
            "step 6400: mse=0.007956 mse_top=0.001675\n",
            "step 6450: mse=0.009525 mse_top=0.001909\n",
            "step 6500: mse=0.010240 mse_top=0.001752\n",
            "step 6550: mse=0.008241 mse_top=0.001720\n",
            "step 6600: mse=0.009097 mse_top=0.001889\n",
            "step 6650: mse=0.009696 mse_top=0.002007\n",
            "step 6700: mse=0.008342 mse_top=0.001815\n",
            "step 6750: mse=0.009211 mse_top=0.001995\n",
            "step 6800: mse=0.010318 mse_top=0.002142\n",
            "step 6850: mse=0.008717 mse_top=0.001652\n",
            "step 6900: mse=0.009679 mse_top=0.002117\n",
            "step 6950: mse=0.010520 mse_top=0.002131\n",
            "step 7000: mse=0.007859 mse_top=0.001954\n",
            "step 7050: mse=0.009031 mse_top=0.001814\n",
            "step 7100: mse=0.008110 mse_top=0.001588\n",
            "step 7150: mse=0.009509 mse_top=0.002260\n",
            "step 7200: mse=0.008954 mse_top=0.001997\n",
            "step 7250: mse=0.007944 mse_top=0.001593\n",
            "step 7300: mse=0.009150 mse_top=0.001967\n",
            "step 7350: mse=0.009293 mse_top=0.001817\n",
            "step 7400: mse=0.007613 mse_top=0.002024\n",
            "step 7450: mse=0.008607 mse_top=0.002290\n",
            "step 7500: mse=0.007994 mse_top=0.002075\n",
            "step 7550: mse=0.007541 mse_top=0.001969\n",
            "step 7600: mse=0.008404 mse_top=0.002379\n",
            "step 7650: mse=0.007861 mse_top=0.002129\n",
            "step 7700: mse=0.007895 mse_top=0.001950\n",
            "step 7750: mse=0.007294 mse_top=0.001822\n",
            "step 7800: mse=0.008166 mse_top=0.002085\n",
            "step 7850: mse=0.009032 mse_top=0.002107\n",
            "step 7900: mse=0.008270 mse_top=0.002560\n",
            "step 7950: mse=0.007807 mse_top=0.002298\n",
            "step 8000: mse=0.007991 mse_top=0.002210\n",
            "step 8050: mse=0.009177 mse_top=0.002039\n",
            "step 8100: mse=0.007899 mse_top=0.002075\n",
            "step 8150: mse=0.007760 mse_top=0.002336\n",
            "step 8200: mse=0.006452 mse_top=0.001973\n",
            "step 8250: mse=0.008863 mse_top=0.002462\n",
            "step 8300: mse=0.007385 mse_top=0.002624\n",
            "step 8350: mse=0.007898 mse_top=0.002316\n",
            "step 8400: mse=0.006894 mse_top=0.001924\n",
            "step 8450: mse=0.007076 mse_top=0.002126\n",
            "step 8500: mse=0.006944 mse_top=0.002008\n",
            "step 8550: mse=0.008613 mse_top=0.002360\n",
            "step 8600: mse=0.007509 mse_top=0.002388\n",
            "step 8650: mse=0.008296 mse_top=0.002438\n",
            "step 8700: mse=0.007780 mse_top=0.002298\n",
            "step 8750: mse=0.009041 mse_top=0.002500\n",
            "step 8800: mse=0.008403 mse_top=0.002297\n",
            "step 8850: mse=0.007459 mse_top=0.002237\n",
            "step 8900: mse=0.008329 mse_top=0.002260\n",
            "step 8950: mse=0.008113 mse_top=0.002249\n",
            "step 9000: mse=0.007824 mse_top=0.002240\n",
            "step 9050: mse=0.007249 mse_top=0.001805\n",
            "step 9100: mse=0.006906 mse_top=0.002110\n",
            "step 9150: mse=0.009388 mse_top=0.001904\n",
            "step 9200: mse=0.008460 mse_top=0.002452\n",
            "step 9250: mse=0.008842 mse_top=0.001977\n",
            "step 9300: mse=0.009919 mse_top=0.001988\n",
            "step 9350: mse=0.010213 mse_top=0.002148\n",
            "step 9400: mse=0.008110 mse_top=0.001678\n",
            "step 9450: mse=0.008188 mse_top=0.001698\n",
            "step 9500: mse=0.007471 mse_top=0.001527\n",
            "step 9550: mse=0.008547 mse_top=0.002380\n",
            "step 9600: mse=0.008036 mse_top=0.002487\n",
            "step 9650: mse=0.008678 mse_top=0.002112\n",
            "step 9700: mse=0.006575 mse_top=0.001861\n",
            "step 9750: mse=0.006237 mse_top=0.001759\n",
            "step 9800: mse=0.007989 mse_top=0.002515\n",
            "step 9850: mse=0.008255 mse_top=0.002419\n",
            "step 9900: mse=0.007971 mse_top=0.002673\n",
            "step 9950: mse=0.007804 mse_top=0.002462\n",
            "step 10000: mse=0.006701 mse_top=0.001847\n",
            "step 10050: mse=0.007981 mse_top=0.002281\n",
            "step 10100: mse=0.007240 mse_top=0.002341\n",
            "step 10150: mse=0.007679 mse_top=0.002069\n",
            "step 10200: mse=0.008441 mse_top=0.002223\n",
            "step 10250: mse=0.006835 mse_top=0.001993\n",
            "step 10300: mse=0.007476 mse_top=0.002063\n",
            "step 10350: mse=0.007763 mse_top=0.002192\n",
            "step 10400: mse=0.007659 mse_top=0.002406\n",
            "step 10450: mse=0.006936 mse_top=0.002199\n",
            "step 10500: mse=0.006205 mse_top=0.002295\n",
            "step 10550: mse=0.006843 mse_top=0.002063\n",
            "step 10600: mse=0.006644 mse_top=0.002548\n",
            "step 10650: mse=0.009174 mse_top=0.002546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt4XakmprLAC",
        "colab_type": "text"
      },
      "source": [
        "# Saving the zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhrDzcaEnYtv",
        "colab_type": "code",
        "outputId": "c610e7ef-e04f-46cf-beed-b0e9a8c8cb4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Nawid- This allows me to write comments into the file\n",
        "f= open(path +'/'+\"info.txt\",\"w+\")\n",
        "comments = input(\"Learning rate, pretrained or not etc: \") # Nawid - Enables me to input information\n",
        "f.write(comments)\n",
        "f.close()\n",
        "\n",
        "full_path = path + \".zip\"\n",
        "!zip -r $full_path /content/$path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate, pretrained or not etc: lr = 1e-4, pretrained and trained on both missing modality one by one. The first missing modality trained was thermal and then trained on RGB after\n",
            "  adding: content/Data_07012020_20:02:02/ (stored 0%)\n",
            "  adding: content/Data_07012020_20:02:02/Train_reconstructions_rgb.png (deflated 0%)\n",
            "  adding: content/Data_07012020_20:02:02/info.txt (deflated 31%)\n",
            "  adding: content/Data_07012020_20:02:02/vae.pt (deflated 7%)\n",
            "  adding: content/Data_07012020_20:02:02/Val_reconstructions_thermal.png (deflated 0%)\n",
            "  adding: content/Data_07012020_20:02:02/Train_reconstructions_thermal.png (deflated 0%)\n",
            "  adding: content/Data_07012020_20:02:02/Val_reconstructions_rgb.png (deflated 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUJZKVyWvvWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/\" + path+\".zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YPCJUNlTul7E"
      },
      "source": [
        "# Original code - For when the images of the thermal and the RGB data was different"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C69DYwuhhCur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r  file.zip /content/Data_06012020_10:48:28\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9K14q_tjld1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r Data_06012020_10:48:28.zip /content/Data_06012020_10:48:28\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/Data_06012020_10:48:28.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4R-754PW9mu",
        "colab_type": "code",
        "outputId": "b3182d07-2527-4e3b-f4f8-7ca980c546a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "import os\n",
        "path = 'Data_folder'\n",
        "os.mkdir(path)\n",
        "'''\n",
        "import os\n",
        "from datetime import datetime\n",
        "# datetime object containing current date and time\n",
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%d%m%Y_%H:%M:%S\")\n",
        "path = 'Data_folder_'\n",
        "os.mkdir(path+dt_string)\n",
        "'''\n",
        "print(\"now =\", now)\n",
        "# dd/mm/YY H:M:S\n",
        "\n",
        "print(\"date and time =\", dt_string)\t\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(\"now =\", now)\\n# dd/mm/YY H:M:S\\n\\nprint(\"date and time =\", dt_string)\\t\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAOZ3-nTYZXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "  model = make_vae()\n",
        "  if os.path.exists(VAE_PATH):\n",
        "    model.load_state_dict(torch.load(VAE_PATH, map_location='cpu'))\n",
        "  model.to(device)\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  \n",
        "  # Nawid -Define the iterators for the validation data\n",
        "\n",
        "  i = 0\n",
        "  val_loader = InfiniteDataLoader(x_rgb,x)\n",
        "  val_iterator = iter(val_loader) \n",
        "\n",
        "  \n",
        "\n",
        "  for x_rgb_batch, x_thermal_batch in rgb_thermal_load_images(x_rgb,x):\n",
        "    x_rgb_batch = x_rgb_batch.to(device)\n",
        "    x_thermal_batch = x_thermal_batch.to(device)\n",
        "    terms = model(x_rgb_batch, x_thermal_batch)\n",
        "    \n",
        "    if rapid_evaluation:\n",
        "      print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    else:\n",
        "      if not i % eval_counter:\n",
        "        print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    \n",
        "    optimizer.zero_grad() #Nawid - I think this makes the gradient become zero\n",
        "    terms['loss'].backward() # Nawid - Backpropagates the total loss term ( which is related to all the different components)\n",
        "    optimizer.step() # Nawid- Updates using optimizer\n",
        "    model.revive_dead_entries()\n",
        "    i +=1\n",
        "    \n",
        "    if not i % 50:\n",
        "      torch.save(model.state_dict(), VAE_PATH)\n",
        "      #save_reconstructions(x_rgb_batch, terms['reconstructions'][-1], x_thermal_batch,terms['reconstructions_thermal'][-1])\n",
        "      save_reconstructions(model,x_rgb_batch, x_thermal_batch) # Nawid - saves the reconstruction\n",
        "\n",
        "      val_rgb_batch,val_thermal_batch = next(val_iterator)\n",
        "      \n",
        "      if save_data:\n",
        "        val_total_loss, val_reconstruction_loss = validation_loss(model,val_rgb_batch,val_thermal_batch)\n",
        "        tensorboard_saving(i,terms['losses'][-1],val_reconstruction_loss, terms['loss'],val_total_loss)\n",
        "      else:\n",
        "        pass\n",
        "      save_reconstructions(model,val_rgb_batch, val_thermal_batch,'Val')\n",
        "\n",
        "\n",
        "def tensorboard_saving(iteration,recon_loss_train, recon_loss_val, total_loss_train,total_loss_val):\n",
        "  tb.save_value('Reconstruction_loss','Train loss', iteration, recon_loss_train)\n",
        "  tb.save_value('Reconstruction_loss','Validation loss', iteration, recon_loss_val)\n",
        "      \n",
        "  tb.save_value('Total_loss','Train loss', iteration, total_loss_train)\n",
        "  tb.save_value('Total_loss','Validation loss', iteration, total_loss_val)\n",
        " \n",
        "  tb.flush_line('Reconstruction_loss')\n",
        "  tb.flush_line('Total_loss')\n",
        "\n",
        "\n",
        "def validation_loss(vae,val_rgb, val_thermal):\n",
        "  vae.eval() # Nawid - Sets it into evaluation mode ( so dropout and batchnorm have different behaviours)\n",
        "  with torch.no_grad(): # Nawid-  Turns off the autograd engine which speeds up computation\n",
        "    val_terms = vae(val_rgb,val_thermal)\n",
        "    total_loss, reconstruction_loss = val_terms['loss'], val_terms['losses'][-1]\n",
        "    vae.train()\n",
        "    return total_loss, reconstruction_loss\n",
        "\n",
        "\n",
        "def save_reconstructions(vae,rgb_images, thermal_images,name = 'Train'):\n",
        "  vae.eval()\n",
        "  with torch.no_grad():\n",
        "    recons, recons_thermal = vae.full_reconstructions(rgb_images,thermal_images)\n",
        "    recons = [torch.clamp(x, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x in recons] # Nawid - Clamps all the different elements in recons\n",
        "    recons_thermal = [torch.clamp(x_thermal, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x_thermal in recons_thermal] # Nawid - Clamps all the different elements in recons_thermal\n",
        "    \n",
        "    vae.train() # Nawid - This sets the nn.module into training mode\n",
        "    top_recons, real_recons = recons # Nawid - I believe the top_recons is the reconstruction using only the top latent map, whilst real_recons is using both the top latent map and the bottom latent map\n",
        "    rgb_images = rgb_images.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "    columns = np.concatenate([top_recons, real_recons, rgb_images], axis=-2)\n",
        "    columns = np.concatenate(columns, axis=0)\n",
        "    Image.fromarray((columns * 255).astype('uint8')).save(name +'_reconstructions_rgb.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "    top_recons_thermal,real_recons_thermal = recons_thermal\n",
        "    thermal_images = thermal_images.permute(0,2,3,1).detach().cpu().numpy()\n",
        "    thermal_images = thermal_images.reshape(thermal_images.shape[0],thermal_images.shape[1],thermal_images.shape[2])\n",
        "\n",
        "    top_recons_thermal = top_recons_thermal.reshape(top_recons_thermal.shape[0],top_recons_thermal.shape[1],top_recons_thermal.shape[2])\n",
        "    real_recons_thermal = real_recons_thermal.reshape(real_recons_thermal.shape[0],real_recons_thermal.shape[1],real_recons_thermal.shape[2])\n",
        "\n",
        "    columns_thermal = np.concatenate([top_recons_thermal, real_recons_thermal,thermal_images], axis=-1) # Nawid - I need to concatenate along -2 when using rgb and -1 when using grayscale and when using  When using grayscale images, to save the files using PIL, i need to make to remove the channel and so there is one less axis to examine\n",
        "    columns_thermal = np.concatenate(columns_thermal, axis=0)\n",
        "    Image.fromarray((columns_thermal * 255).astype('uint8')).save(name +'_reconstructions_thermal.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s6ivYJFBuj7S",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "  model = make_vae()\n",
        "  if os.path.exists(VAE_PATH):\n",
        "    model.load_state_dict(torch.load(VAE_PATH, map_location='cpu'))\n",
        "  model.to(device)\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  \n",
        "  # Nawid -Define the iterators for the validation data\n",
        "  val_rgb_loader = InfiniteDataLoader(val_x_rgb)\n",
        "  val_rgb_iterator = iter(val_rgb_loader)\n",
        "\n",
        "  val_thermal_loader = InfiniteDataLoader(val_x)\n",
        "  val_thermal_iterator = iter(val_thermal_loader)\n",
        "\n",
        "  i = 0\n",
        "  for x_rgb_batch, x_thermal_batch in zip(load_images(x_rgb), load_images(x)):\n",
        "    x_rgb_batch= x_rgb_batch.to(device)\n",
        "    x_thermal_batch =  x_thermal_batch.to(device)\n",
        "    terms = model(x_rgb_batch, x_thermal_batch)\n",
        "    \n",
        "    if rapid_evaluation:\n",
        "      print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    else:\n",
        "      if not i % eval_counter:\n",
        "        print('step %d: mse=%f mse_top=%f' %\n",
        "            (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
        "    \n",
        "    optimizer.zero_grad() #Nawid - I think this makes the gradient become zero\n",
        "    terms['loss'].backward() # Nawid - Backpropagates the total loss term ( which is related to all the different components)\n",
        "    optimizer.step() # Nawid- Updates using optimizer\n",
        "    model.revive_dead_entries()\n",
        "    i +=1\n",
        "    if not i % 50:\n",
        "      torch.save(model.state_dict(), VAE_PATH)\n",
        "      #save_reconstructions(x_rgb_batch, terms['reconstructions'][-1], x_thermal_batch,terms['reconstructions_thermal'][-1])\n",
        "      save_reconstructions(model,x_rgb_batch, x_thermal_batch) # Nawid - saves the reconstruction\n",
        "\n",
        "      val_rgb_batch = next(val_rgb_iterator)\n",
        "      val_thermal_batch = next(val_thermal_iterator)\n",
        "      val_total_loss, val_reconstruction_loss = validation_loss(model,val_rgb_batch,val_thermal_batch)\n",
        "      \n",
        "      tensorboard_saving(i,terms['losses'][-1],val_reconstruction_loss, terms['loss'],val_total_loss)\n",
        "      save_reconstructions(model,val_rgb_batch, val_thermal_batch,'Val')\n",
        "\n",
        "      '''\n",
        "      tb.save_value('Reconstruction_loss','Train loss', i, terms['losses'][-1])\n",
        "      tb.save_value('Reconstruction_loss','Validation loss', i, val_reconstruction_loss)\n",
        "      \n",
        "      tb.save_value('Total_loss','Train loss', i, terms['loss'])\n",
        "      tb.save_value('Total_loss','Validation loss', i, val_total_loss)\n",
        "      tb.flush_line('Reconstruction_loss')\n",
        "      tb.flush_line('Total_loss')\n",
        "      '''\n",
        "      \n",
        "\n",
        "def tensorboard_saving(iteration,recon_loss_train, recon_loss_val, total_loss_train,total_loss_val):\n",
        "  tb.save_value('Reconstruction_loss','Train loss', iteration, recon_loss_train)\n",
        "  tb.save_value('Reconstruction_loss','Validation loss', iteration, recon_loss_val)\n",
        "      \n",
        "  tb.save_value('Total_loss','Train loss', iteration, total_loss_train)\n",
        "  tb.save_value('Total_loss','Validation loss', iteration, total_loss_val)\n",
        " \n",
        "  tb.flush_line('Reconstruction_loss')\n",
        "  tb.flush_line('Total_loss')\n",
        "\n",
        "\n",
        "def validation_loss(vae,val_rgb, val_thermal):\n",
        "  vae.eval() # Nawid - Sets it into evaluation mode ( so dropout and batchnorm have different behaviours)\n",
        "  with torch.no_grad(): # Nawid-  Turns off the autograd engine which speeds up computation\n",
        "    val_terms = vae(val_rgb,val_thermal)\n",
        "    total_loss, reconstruction_loss = val_terms['loss'], val_terms['losses'][-1]\n",
        "    return total_loss, reconstruction_loss\n",
        "\n",
        "\n",
        "def save_reconstructions(vae,rgb_images, thermal_images,name = 'Train'):\n",
        "  vae.eval()\n",
        "  with torch.no_grad():\n",
        "    recons, recons_thermal = vae.full_reconstructions(rgb_images,thermal_images)\n",
        "    recons = [torch.clamp(x, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x in recons] # Nawid - Clamps all the different elements in recons\n",
        "    recons_thermal = [torch.clamp(x_thermal, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "                  for x_thermal in recons_thermal] # Nawid - Clamps all the different elements in recons_thermal\n",
        "    \n",
        "    vae.train() # Nawid - This sets the nn.module into training mode\n",
        "    top_recons, real_recons = recons # Nawid - I believe the top_recons is the reconstruction using only the top latent map, whilst real_recons is using both the top latent map and the bottom latent map\n",
        "    rgb_images = rgb_images.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "    columns = np.concatenate([top_recons, real_recons, rgb_images], axis=-2)\n",
        "    columns = np.concatenate(columns, axis=0)\n",
        "    Image.fromarray((columns * 255).astype('uint8')).save(name +'_reconstructions_rgb.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "    top_recons_thermal,real_recons_thermal = recons_thermal\n",
        "    thermal_images = thermal_images.permute(0,2,3,1).detach().cpu().numpy()\n",
        "    thermal_images = thermal_images.reshape(thermal_images.shape[0],thermal_images.shape[1],thermal_images.shape[2])\n",
        "\n",
        "    top_recons_thermal = top_recons_thermal.reshape(top_recons_thermal.shape[0],top_recons_thermal.shape[1],top_recons_thermal.shape[2])\n",
        "    real_recons_thermal = real_recons_thermal.reshape(real_recons_thermal.shape[0],real_recons_thermal.shape[1],real_recons_thermal.shape[2])\n",
        "\n",
        "    columns_thermal = np.concatenate([top_recons_thermal, real_recons_thermal,thermal_images], axis=-1) # Nawid - I need to concatenate along -2 when using rgb and -1 when using grayscale and when using  When using grayscale images, to save the files using PIL, i need to make to remove the channel and so there is one less axis to examine\n",
        "    columns_thermal = np.concatenate(columns_thermal, axis=0)\n",
        "    Image.fromarray((columns_thermal * 255).astype('uint8')).save(name +'_reconstructions_thermal.png') # Nawid - Changes the valeus back to 255 and integers and save the reconstructions\n",
        "\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z8n9DfbZujVk",
        "colab": {}
      },
      "source": [
        "def load_images(input_x): # Nawid - Loads images\n",
        "    while True:\n",
        "        for data in create_data_loader(input_x):\n",
        "          #data = data.float()/255 # Nawid - Divides by 255 \n",
        "          data = data.permute(0, 3, 1, 2).contiguous() # Nawid - Changes into pytorch ordering\n",
        "          yield data\n",
        "       \n",
        "def create_data_loader(input_x): # Nawid - Creates a dataloader object\n",
        "    return torch.utils.data.DataLoader(input_x, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# https://gist.github.com/MFreidank/821cc87b012c53fade03b0c7aba13958\n",
        "class InfiniteDataLoader(DataLoader): \n",
        "  def __init__(self,input_x, batch_size=BATCH_SIZE, shuffle=True):\n",
        "    super().__init__(input_x, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    #Initialise an iterator over the dataset\n",
        "    self.dataset_iterator = super().__iter__()\n",
        "\n",
        "  def __iter__(self):\n",
        "    return self\n",
        "\n",
        "  def __next__(self):\n",
        "    try:\n",
        "      batch = next(self.dataset_iterator)\n",
        "\n",
        "    except StopIteration:\n",
        "      # Dataset exhausted, use a new fresh iterator\n",
        "      self.dataset_iterator = super().__iter__()\n",
        "      batch = next(self.dataset_iterator)\n",
        "    batch = batch.permute(0, 3, 1, 2).contiguous() # Nawid- Added this to change the channels\n",
        "    return batch.to(device) # Nawid - Add to the device directly\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}